2018-12-26 14:53:33 [ INFO ] - [ com.zqg.StreamKafka.KafkaSparkStreamingWithZookeeperoffset.main(KafkaSparkStreamingWithZookeeperoffset.java:21) ] 
java.lang.Exception: asdfas
	at com.zqg.StreamKafka.KafkaSparkStreamingWithZookeeperoffset.main(KafkaSparkStreamingWithZookeeperoffset.java:21)
2018-12-26 14:53:34 [ INFO ] - [ org.apache.curator.framework.imps.CuratorFrameworkImpl.start(CuratorFrameworkImpl.java:223) ] Starting
2018-12-26 14:53:34 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT
2018-12-26 14:53:34 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:host.name=windows10.microdone.cn
2018-12-26 14:53:34 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.version=1.8.0_171
2018-12-26 14:53:34 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.vendor=Oracle Corporation
2018-12-26 14:53:34 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.home=C:\Program Files\Java\jdk1.8.0_171\jre
2018-12-26 14:53:34 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.class.path=C:\Program Files\Java\jdk1.8.0_171\jre\lib\charsets.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\deploy.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\access-bridge-64.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\cldrdata.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\dnsns.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\jaccess.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\jfxrt.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\localedata.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\nashorn.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunec.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunjce_provider.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunmscapi.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunpkcs11.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\zipfs.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\javaws.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jce.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jfr.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jfxswt.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jsse.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\management-agent.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\plugin.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\resources.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\rt.jar;D:\springbootworkspace\spark\target\classes;D:\Repository\org\scala-lang\scala-library\2.11.8\scala-library-2.11.8.jar;D:\Repository\org\apache\spark\spark-core_2.11\2.1.0\spark-core_2.11-2.1.0.jar;D:\Repository\org\apache\avro\avro-mapred\1.7.7\avro-mapred-1.7.7-hadoop2.jar;D:\Repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7.jar;D:\Repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7-tests.jar;D:\Repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;D:\Repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;D:\Repository\com\twitter\chill_2.11\0.8.0\chill_2.11-0.8.0.jar;D:\Repository\com\esotericsoftware\kryo-shaded\3.0.3\kryo-shaded-3.0.3.jar;D:\Repository\com\esotericsoftware\minlog\1.3.0\minlog-1.3.0.jar;D:\Repository\org\objenesis\objenesis\2.1\objenesis-2.1.jar;D:\Repository\com\twitter\chill-java\0.8.0\chill-java-0.8.0.jar;D:\Repository\org\apache\xbean\xbean-asm5-shaded\4.4\xbean-asm5-shaded-4.4.jar;D:\Repository\org\apache\spark\spark-launcher_2.11\2.1.0\spark-launcher_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-network-common_2.11\2.1.0\spark-network-common_2.11-2.1.0.jar;D:\Repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;D:\Repository\com\fasterxml\jackson\core\jackson-annotations\2.6.5\jackson-annotations-2.6.5.jar;D:\Repository\org\apache\spark\spark-network-shuffle_2.11\2.1.0\spark-network-shuffle_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-unsafe_2.11\2.1.0\spark-unsafe_2.11-2.1.0.jar;D:\Repository\net\java\dev\jets3t\jets3t\0.7.1\jets3t-0.7.1.jar;D:\Repository\commons-codec\commons-codec\1.3\commons-codec-1.3.jar;D:\Repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;D:\Repository\org\apache\curator\curator-recipes\2.4.0\curator-recipes-2.4.0.jar;D:\Repository\org\apache\curator\curator-framework\2.4.0\curator-framework-2.4.0.jar;D:\Repository\com\google\guava\guava\14.0.1\guava-14.0.1.jar;D:\Repository\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;D:\Repository\org\apache\commons\commons-lang3\3.5\commons-lang3-3.5.jar;D:\Repository\org\apache\commons\commons-math3\3.4.1\commons-math3-3.4.1.jar;D:\Repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;D:\Repository\org\slf4j\slf4j-api\1.7.16\slf4j-api-1.7.16.jar;D:\Repository\org\slf4j\jul-to-slf4j\1.7.16\jul-to-slf4j-1.7.16.jar;D:\Repository\org\slf4j\jcl-over-slf4j\1.7.16\jcl-over-slf4j-1.7.16.jar;D:\Repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;D:\Repository\org\slf4j\slf4j-log4j12\1.7.16\slf4j-log4j12-1.7.16.jar;D:\Repository\com\ning\compress-lzf\1.0.3\compress-lzf-1.0.3.jar;D:\Repository\org\xerial\snappy\snappy-java\1.1.2.6\snappy-java-1.1.2.6.jar;D:\Repository\net\jpountz\lz4\lz4\1.3.0\lz4-1.3.0.jar;D:\Repository\org\roaringbitmap\RoaringBitmap\0.5.11\RoaringBitmap-0.5.11.jar;D:\Repository\commons-net\commons-net\2.2\commons-net-2.2.jar;D:\Repository\org\json4s\json4s-jackson_2.11\3.2.11\json4s-jackson_2.11-3.2.11.jar;D:\Repository\org\json4s\json4s-core_2.11\3.2.11\json4s-core_2.11-3.2.11.jar;D:\Repository\org\json4s\json4s-ast_2.11\3.2.11\json4s-ast_2.11-3.2.11.jar;D:\Repository\com\thoughtworks\paranamer\paranamer\2.6\paranamer-2.6.jar;D:\Repository\org\scala-lang\scalap\2.11.0\scalap-2.11.0.jar;D:\Repository\org\scala-lang\scala-compiler\2.11.0\scala-compiler-2.11.0.jar;D:\Repository\org\glassfish\jersey\core\jersey-client\2.22.2\jersey-client-2.22.2.jar;D:\Repository\javax\ws\rs\javax.ws.rs-api\2.0.1\javax.ws.rs-api-2.0.1.jar;D:\Repository\org\glassfish\hk2\hk2-api\2.4.0-b34\hk2-api-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\hk2-utils\2.4.0-b34\hk2-utils-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\external\aopalliance-repackaged\2.4.0-b34\aopalliance-repackaged-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\external\javax.inject\2.4.0-b34\javax.inject-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\hk2-locator\2.4.0-b34\hk2-locator-2.4.0-b34.jar;D:\Repository\org\javassist\javassist\3.18.1-GA\javassist-3.18.1-GA.jar;D:\Repository\org\glassfish\jersey\core\jersey-common\2.22.2\jersey-common-2.22.2.jar;D:\Repository\javax\annotation\javax.annotation-api\1.2\javax.annotation-api-1.2.jar;D:\Repository\org\glassfish\jersey\bundles\repackaged\jersey-guava\2.22.2\jersey-guava-2.22.2.jar;D:\Repository\org\glassfish\hk2\osgi-resource-locator\1.0.1\osgi-resource-locator-1.0.1.jar;D:\Repository\org\glassfish\jersey\core\jersey-server\2.22.2\jersey-server-2.22.2.jar;D:\Repository\org\glassfish\jersey\media\jersey-media-jaxb\2.22.2\jersey-media-jaxb-2.22.2.jar;D:\Repository\javax\validation\validation-api\1.1.0.Final\validation-api-1.1.0.Final.jar;D:\Repository\org\glassfish\jersey\containers\jersey-container-servlet\2.22.2\jersey-container-servlet-2.22.2.jar;D:\Repository\org\glassfish\jersey\containers\jersey-container-servlet-core\2.22.2\jersey-container-servlet-core-2.22.2.jar;D:\Repository\io\netty\netty-all\4.0.42.Final\netty-all-4.0.42.Final.jar;D:\Repository\io\netty\netty\3.8.0.Final\netty-3.8.0.Final.jar;D:\Repository\com\clearspring\analytics\stream\2.7.0\stream-2.7.0.jar;D:\Repository\io\dropwizard\metrics\metrics-core\3.1.2\metrics-core-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-jvm\3.1.2\metrics-jvm-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-json\3.1.2\metrics-json-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-graphite\3.1.2\metrics-graphite-3.1.2.jar;D:\Repository\com\fasterxml\jackson\core\jackson-databind\2.6.5\jackson-databind-2.6.5.jar;D:\Repository\com\fasterxml\jackson\core\jackson-core\2.6.5\jackson-core-2.6.5.jar;D:\Repository\com\fasterxml\jackson\module\jackson-module-scala_2.11\2.6.5\jackson-module-scala_2.11-2.6.5.jar;D:\Repository\org\scala-lang\scala-reflect\2.11.7\scala-reflect-2.11.7.jar;D:\Repository\com\fasterxml\jackson\module\jackson-module-paranamer\2.6.5\jackson-module-paranamer-2.6.5.jar;D:\Repository\org\apache\ivy\ivy\2.4.0\ivy-2.4.0.jar;D:\Repository\oro\oro\2.0.8\oro-2.0.8.jar;D:\Repository\net\razorvine\pyrolite\4.13\pyrolite-4.13.jar;D:\Repository\net\sf\py4j\py4j\0.10.4\py4j-0.10.4.jar;D:\Repository\org\apache\spark\spark-tags_2.11\2.1.0\spark-tags_2.11-2.1.0.jar;D:\Repository\org\scalatest\scalatest_2.11\2.2.6\scalatest_2.11-2.2.6.jar;D:\Repository\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;D:\Repository\org\spark-project\spark\unused\1.0.0\unused-1.0.0.jar;D:\Repository\org\apache\spark\spark-streaming_2.11\2.1.0\spark-streaming_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-sql_2.11\2.1.0\spark-sql_2.11-2.1.0.jar;D:\Repository\com\univocity\univocity-parsers\2.2.1\univocity-parsers-2.2.1.jar;D:\Repository\org\apache\spark\spark-sketch_2.11\2.1.0\spark-sketch_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-catalyst_2.11\2.1.0\spark-catalyst_2.11-2.1.0.jar;D:\Repository\org\codehaus\janino\janino\3.0.0\janino-3.0.0.jar;D:\Repository\org\codehaus\janino\commons-compiler\3.0.0\commons-compiler-3.0.0.jar;D:\Repository\org\antlr\antlr4-runtime\4.5.3\antlr4-runtime-4.5.3.jar;D:\Repository\org\apache\parquet\parquet-column\1.8.1\parquet-column-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-common\1.8.1\parquet-common-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-encoding\1.8.1\parquet-encoding-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-hadoop\1.8.1\parquet-hadoop-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-format\2.3.0-incubating\parquet-format-2.3.0-incubating.jar;D:\Repository\org\apache\parquet\parquet-jackson\1.8.1\parquet-jackson-1.8.1.jar;D:\Repository\org\apache\hadoop\hadoop-client\2.6.5\hadoop-client-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-common\2.6.5\hadoop-common-2.6.5.jar;D:\Repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;D:\Repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;D:\Repository\commons-io\commons-io\2.4\commons-io-2.4.jar;D:\Repository\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;D:\Repository\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;D:\Repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\Repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;D:\Repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;D:\Repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;D:\Repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;D:\Repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;D:\Repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;D:\Repository\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;D:\Repository\org\apache\hadoop\hadoop-auth\2.6.5\hadoop-auth-2.6.5.jar;D:\Repository\org\apache\httpcomponents\httpclient\4.2.5\httpclient-4.2.5.jar;D:\Repository\org\apache\httpcomponents\httpcore\4.2.4\httpcore-4.2.4.jar;D:\Repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;D:\Repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;D:\Repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;D:\Repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;D:\Repository\org\apache\curator\curator-client\2.6.0\curator-client-2.6.0.jar;D:\Repository\org\htrace\htrace-core\3.0.4\htrace-core-3.0.4.jar;D:\Repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;D:\Repository\org\tukaani\xz\1.0\xz-1.0.jar;D:\Repository\org\apache\hadoop\hadoop-hdfs\2.6.5\hadoop-hdfs-2.6.5.jar;D:\Repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;D:\Repository\xerces\xercesImpl\2.9.1\xercesImpl-2.9.1.jar;D:\Repository\xml-apis\xml-apis\1.3.04\xml-apis-1.3.04.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.6.5\hadoop-mapreduce-client-app-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.6.5\hadoop-mapreduce-client-common-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-client\2.6.5\hadoop-yarn-client-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-server-common\2.6.5\hadoop-yarn-server-common-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.6.5\hadoop-mapreduce-client-shuffle-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-api\2.6.5\hadoop-yarn-api-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.6.5\hadoop-mapreduce-client-core-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-common\2.6.5\hadoop-yarn-common-2.6.5.jar;D:\Repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;D:\Repository\javax\xml\stream\stax-api\1.0-2\stax-api-1.0-2.jar;D:\Repository\javax\activation\activation\1.1\activation-1.1.jar;D:\Repository\javax\servlet\servlet-api\2.5\servlet-api-2.5.jar;D:\Repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;D:\Repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;D:\Repository\org\codehaus\jackson\jackson-jaxrs\1.9.13\jackson-jaxrs-1.9.13.jar;D:\Repository\org\codehaus\jackson\jackson-xc\1.9.13\jackson-xc-1.9.13.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.6.5\hadoop-mapreduce-client-jobclient-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-annotations\2.6.5\hadoop-annotations-2.6.5.jar;D:\Repository\org\apache\kafka\kafka-clients\0.8.2.2\kafka-clients-0.8.2.2.jar;D:\Repository\org\apache\kafka\kafka_2.11\0.8.2.2\kafka_2.11-0.8.2.2.jar;D:\Repository\org\scala-lang\modules\scala-xml_2.11\1.0.2\scala-xml_2.11-1.0.2.jar;D:\Repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;D:\Repository\net\sf\jopt-simple\jopt-simple\3.2\jopt-simple-3.2.jar;D:\Repository\org\scala-lang\modules\scala-parser-combinators_2.11\1.0.2\scala-parser-combinators_2.11-1.0.2.jar;D:\Repository\com\101tec\zkclient\0.3\zkclient-0.3.jar;D:\Repository\mysql\mysql-connector-java\5.1.38\mysql-connector-java-5.1.38.jar;D:\Repository\org\apache\spark\spark-streaming-kafka-0-8_2.11\2.1.0\spark-streaming-kafka-0-8_2.11-2.1.0.jar;D:\Repository\org\apache\zookeeper\zookeeper\3.4.10\zookeeper-3.4.10.jar;D:\Repository\jline\jline\0.9.94\jline-0.9.94.jar;D:\developTools\IntelliJ IDEA 2018.2.3\lib\idea_rt.jar
2018-12-26 14:53:34 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_171\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;D:\developTools\Git\cmd;D:\developTools\svn\bin;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\scala\bin;C:\Users\junmei02\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk1.8.0_171\bin;D:\developTools\apache-maven-3.5.2\bin;D:\developTools\mysql-5.6.27-winx64\bin;D:\developTools\Git\cmd;D:\hadoop\hadoop-common-2.2.0-bin-master\bin;D:\hadoop\hbase-1.2.6\bin;C:\Program Files (x86)\scala\bin;D:\bigdata\zookeeper-3.4.10\bin;;.
2018-12-26 14:53:34 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.io.tmpdir=C:\Users\junmei02\AppData\Local\Temp\
2018-12-26 14:53:34 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.compiler=<NA>
2018-12-26 14:53:34 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.name=Windows 10
2018-12-26 14:53:34 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.arch=amd64
2018-12-26 14:53:34 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.version=10.0
2018-12-26 14:53:34 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.name=junmei02
2018-12-26 14:53:34 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.home=C:\Users\junmei02
2018-12-26 14:53:34 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.dir=D:\springbootworkspace\spark
2018-12-26 14:53:34 [ INFO ] - [ org.apache.zookeeper.ZooKeeper.<init>(ZooKeeper.java:438) ] Initiating client connection, connectString=127.0.0.1:2181 sessionTimeout=10000 watcher=org.apache.curator.ConnectionState@7ef82753
2018-12-26 14:53:35 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:1032) ] Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2018-12-26 14:53:35 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$SendThread.primeConnection(ClientCnxn.java:876) ] Socket connection established to 127.0.0.1/127.0.0.1:2181, initiating session
2018-12-26 14:53:35 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$SendThread.onConnected(ClientCnxn.java:1299) ] Session establishment complete on server 127.0.0.1/127.0.0.1:2181, sessionid = 0x167e901f2f50005, negotiated timeout = 10000
2018-12-26 14:53:35 [ INFO ] - [ org.apache.curator.framework.state.ConnectionStateManager.postState(ConnectionStateManager.java:194) ] State change: CONNECTED
2018-12-26 14:53:35 [ WARN ] - [ org.apache.curator.framework.state.ConnectionStateManager.processEvents(ConnectionStateManager.java:212) ] There are no ConnectionStateListeners registered.
2018-12-26 14:53:36 [ INFO ] - [ org.apache.zookeeper.ZooKeeper.close(ZooKeeper.java:684) ] Session: 0x167e901f2f50005 closed
2018-12-26 14:53:36 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:519) ] EventThread shut down for session: 0x167e901f2f50005
2018-12-26 14:53:37 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Running Spark version 2.1.0
2018-12-26 14:53:38 [ ERROR ] - [ org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:396) ] Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2373)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2373)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2373)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:837)
	at org.apache.spark.streaming.StreamingContext.<init>(StreamingContext.scala:84)
	at org.apache.spark.streaming.api.java.JavaStreamingContext.<init>(JavaStreamingContext.scala:138)
	at com.zqg.StreamKafka.SparkStreamingDirect.getStreamingContext(SparkStreamingDirect.java:38)
	at com.zqg.StreamKafka.KafkaSparkStreamingWithZookeeperoffset.main(KafkaSparkStreamingWithZookeeperoffset.java:55)
2018-12-26 14:53:38 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing view acls to: junmei02
2018-12-26 14:53:38 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing modify acls to: junmei02
2018-12-26 14:53:38 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing view acls groups to: 
2018-12-26 14:53:38 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing modify acls groups to: 
2018-12-26 14:53:38 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(junmei02); groups with view permissions: Set(); users  with modify permissions: Set(junmei02); groups with modify permissions: Set()
2018-12-26 14:53:39 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'sparkDriver' on port 52522.
2018-12-26 14:53:39 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering MapOutputTracker
2018-12-26 14:53:39 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering BlockManagerMaster
2018-12-26 14:53:39 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-26 14:53:39 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] BlockManagerMasterEndpoint up
2018-12-26 14:53:39 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Created local directory at C:\Users\junmei02\AppData\Local\Temp\blockmgr-a95f0b72-bedb-4c38-84dd-470d706f2967
2018-12-26 14:53:39 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] MemoryStore started with capacity 900.6 MB
2018-12-26 14:53:39 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering OutputCommitCoordinator
2018-12-26 14:53:39 [ INFO ] - [ org.spark_project.jetty.util.log.Log.initialized(Log.java:186) ] Logging initialized @6396ms
2018-12-26 14:53:39 [ INFO ] - [ org.spark_project.jetty.server.Server.doStart(Server.java:327) ] jetty-9.2.z-SNAPSHOT
2018-12-26 14:53:39 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@6c8a68c1{/jobs,null,AVAILABLE}
2018-12-26 14:53:39 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@56193c7d{/jobs/json,null,AVAILABLE}
2018-12-26 14:53:39 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@28c88600{/jobs/job,null,AVAILABLE}
2018-12-26 14:53:39 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@5f8890c2{/jobs/job/json,null,AVAILABLE}
2018-12-26 14:53:39 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@607b2792{/stages,null,AVAILABLE}
2018-12-26 14:53:39 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@7f9e1534{/stages/json,null,AVAILABLE}
2018-12-26 14:53:39 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@138a7441{/stages/stage,null,AVAILABLE}
2018-12-26 14:53:39 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@81ff872{/stages/stage/json,null,AVAILABLE}
2018-12-26 14:53:39 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@31611954{/stages/pool,null,AVAILABLE}
2018-12-26 14:53:39 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@3e598df9{/stages/pool/json,null,AVAILABLE}
2018-12-26 14:53:39 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@7e31ce0f{/storage,null,AVAILABLE}
2018-12-26 14:53:39 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@99a65d3{/storage/json,null,AVAILABLE}
2018-12-26 14:53:39 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@3088660d{/storage/rdd,null,AVAILABLE}
2018-12-26 14:53:39 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@42cc13a0{/storage/rdd/json,null,AVAILABLE}
2018-12-26 14:53:39 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@32fdec40{/environment,null,AVAILABLE}
2018-12-26 14:53:39 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@6813a331{/environment/json,null,AVAILABLE}
2018-12-26 14:53:39 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@1bd81830{/executors,null,AVAILABLE}
2018-12-26 14:53:39 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@39ab59f8{/executors/json,null,AVAILABLE}
2018-12-26 14:53:39 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@64e92d61{/executors/threadDump,null,AVAILABLE}
2018-12-26 14:53:39 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@111610e6{/executors/threadDump/json,null,AVAILABLE}
2018-12-26 14:53:39 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@4ad4936c{/static,null,AVAILABLE}
2018-12-26 14:53:39 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@29d37757{/,null,AVAILABLE}
2018-12-26 14:53:39 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@4fcc529{/api,null,AVAILABLE}
2018-12-26 14:53:39 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@25cc7470{/jobs/job/kill,null,AVAILABLE}
2018-12-26 14:53:39 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@4beddc56{/stages/stage/kill,null,AVAILABLE}
2018-12-26 14:53:39 [ INFO ] - [ org.spark_project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:266) ] Started ServerConnector@72be135f{HTTP/1.1}{0.0.0.0:4040}
2018-12-26 14:53:39 [ INFO ] - [ org.spark_project.jetty.server.Server.doStart(Server.java:379) ] Started @6555ms
2018-12-26 14:53:39 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'SparkUI' on port 4040.
2018-12-26 14:53:39 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Bound SparkUI to 0.0.0.0, and started at http://192.168.0.112:4040
2018-12-26 14:53:39 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Starting executor ID driver on host localhost
2018-12-26 14:53:39 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52544.
2018-12-26 14:53:39 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Server created on 192.168.0.112:52544
2018-12-26 14:53:39 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-26 14:53:39 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering BlockManager BlockManagerId(driver, 192.168.0.112, 52544, None)
2018-12-26 14:53:39 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering block manager 192.168.0.112:52544 with 900.6 MB RAM, BlockManagerId(driver, 192.168.0.112, 52544, None)
2018-12-26 14:53:39 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registered BlockManager BlockManagerId(driver, 192.168.0.112, 52544, None)
2018-12-26 14:53:39 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Initialized BlockManager: BlockManagerId(driver, 192.168.0.112, 52544, None)
2018-12-26 14:53:39 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@4e38d975{/metrics/json,null,AVAILABLE}
2018-12-26 14:53:40 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Slide time = 5000 ms
2018-12-26 14:53:40 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Storage level = Serialized 1x Replicated
2018-12-26 14:53:40 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Checkpoint interval = null
2018-12-26 14:53:40 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Remember interval = 5000 ms
2018-12-26 14:53:40 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Initialized and validated org.apache.spark.streaming.kafka.DirectKafkaInputDStream@16e2af56
2018-12-26 14:53:40 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Slide time = 5000 ms
2018-12-26 14:53:40 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Storage level = Serialized 1x Replicated
2018-12-26 14:53:40 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Checkpoint interval = null
2018-12-26 14:53:40 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Remember interval = 5000 ms
2018-12-26 14:53:40 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@7f197c5a
2018-12-26 14:53:40 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Slide time = 5000 ms
2018-12-26 14:53:40 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Storage level = Serialized 1x Replicated
2018-12-26 14:53:40 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Checkpoint interval = null
2018-12-26 14:53:40 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Remember interval = 5000 ms
2018-12-26 14:53:40 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Initialized and validated org.apache.spark.streaming.kafka.DirectKafkaInputDStream@16e2af56
2018-12-26 14:53:40 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Slide time = 5000 ms
2018-12-26 14:53:40 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Storage level = Serialized 1x Replicated
2018-12-26 14:53:40 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Checkpoint interval = null
2018-12-26 14:53:40 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Remember interval = 5000 ms
2018-12-26 14:53:40 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Initialized and validated org.apache.spark.streaming.dstream.TransformedDStream@5e86a9ac
2018-12-26 14:53:40 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Slide time = 5000 ms
2018-12-26 14:53:40 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Storage level = Serialized 1x Replicated
2018-12-26 14:53:40 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Checkpoint interval = null
2018-12-26 14:53:40 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Remember interval = 5000 ms
2018-12-26 14:53:40 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@39c1e68
2018-12-26 14:53:40 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Started timer for JobGenerator at time 1545807225000
2018-12-26 14:53:40 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Started JobGenerator at 1545807225000 ms
2018-12-26 14:53:40 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Started JobScheduler
2018-12-26 14:53:40 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@7bc6d27a{/streaming,null,AVAILABLE}
2018-12-26 14:53:40 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@6869a3b3{/streaming/json,null,AVAILABLE}
2018-12-26 14:53:40 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@cb03411{/streaming/batch,null,AVAILABLE}
2018-12-26 14:53:40 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@58ec7116{/streaming/batch/json,null,AVAILABLE}
2018-12-26 14:53:40 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@56078cea{/static/streaming,null,AVAILABLE}
2018-12-26 14:53:40 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] StreamingContext started
2018-12-26 14:53:45 [ INFO ] - [ kafka.utils.Logging$class.info(Logging.scala:68) ] Verifying properties
2018-12-26 14:53:45 [ INFO ] - [ kafka.utils.Logging$class.info(Logging.scala:68) ] Property group.id is overridden to 
2018-12-26 14:53:45 [ INFO ] - [ kafka.utils.Logging$class.info(Logging.scala:68) ] Property zookeeper.connect is overridden to 
2018-12-26 14:54:20 [ INFO ] - [ com.zqg.StreamKafka.KafkaSparkStreamingWithZookeeperoffset.main(KafkaSparkStreamingWithZookeeperoffset.java:21) ] 
java.lang.Exception: asdfas
	at com.zqg.StreamKafka.KafkaSparkStreamingWithZookeeperoffset.main(KafkaSparkStreamingWithZookeeperoffset.java:21)
2018-12-26 14:54:20 [ INFO ] - [ org.apache.curator.framework.imps.CuratorFrameworkImpl.start(CuratorFrameworkImpl.java:223) ] Starting
2018-12-26 14:54:20 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT
2018-12-26 14:54:20 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:host.name=windows10.microdone.cn
2018-12-26 14:54:20 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.version=1.8.0_171
2018-12-26 14:54:20 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.vendor=Oracle Corporation
2018-12-26 14:54:20 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.home=C:\Program Files\Java\jdk1.8.0_171\jre
2018-12-26 14:54:20 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.class.path=C:\Program Files\Java\jdk1.8.0_171\jre\lib\charsets.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\deploy.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\access-bridge-64.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\cldrdata.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\dnsns.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\jaccess.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\jfxrt.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\localedata.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\nashorn.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunec.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunjce_provider.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunmscapi.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunpkcs11.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\zipfs.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\javaws.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jce.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jfr.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jfxswt.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jsse.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\management-agent.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\plugin.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\resources.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\rt.jar;D:\springbootworkspace\spark\target\classes;D:\Repository\org\scala-lang\scala-library\2.11.8\scala-library-2.11.8.jar;D:\Repository\org\apache\spark\spark-core_2.11\2.1.0\spark-core_2.11-2.1.0.jar;D:\Repository\org\apache\avro\avro-mapred\1.7.7\avro-mapred-1.7.7-hadoop2.jar;D:\Repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7.jar;D:\Repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7-tests.jar;D:\Repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;D:\Repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;D:\Repository\com\twitter\chill_2.11\0.8.0\chill_2.11-0.8.0.jar;D:\Repository\com\esotericsoftware\kryo-shaded\3.0.3\kryo-shaded-3.0.3.jar;D:\Repository\com\esotericsoftware\minlog\1.3.0\minlog-1.3.0.jar;D:\Repository\org\objenesis\objenesis\2.1\objenesis-2.1.jar;D:\Repository\com\twitter\chill-java\0.8.0\chill-java-0.8.0.jar;D:\Repository\org\apache\xbean\xbean-asm5-shaded\4.4\xbean-asm5-shaded-4.4.jar;D:\Repository\org\apache\spark\spark-launcher_2.11\2.1.0\spark-launcher_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-network-common_2.11\2.1.0\spark-network-common_2.11-2.1.0.jar;D:\Repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;D:\Repository\com\fasterxml\jackson\core\jackson-annotations\2.6.5\jackson-annotations-2.6.5.jar;D:\Repository\org\apache\spark\spark-network-shuffle_2.11\2.1.0\spark-network-shuffle_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-unsafe_2.11\2.1.0\spark-unsafe_2.11-2.1.0.jar;D:\Repository\net\java\dev\jets3t\jets3t\0.7.1\jets3t-0.7.1.jar;D:\Repository\commons-codec\commons-codec\1.3\commons-codec-1.3.jar;D:\Repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;D:\Repository\org\apache\curator\curator-recipes\2.4.0\curator-recipes-2.4.0.jar;D:\Repository\org\apache\curator\curator-framework\2.4.0\curator-framework-2.4.0.jar;D:\Repository\com\google\guava\guava\14.0.1\guava-14.0.1.jar;D:\Repository\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;D:\Repository\org\apache\commons\commons-lang3\3.5\commons-lang3-3.5.jar;D:\Repository\org\apache\commons\commons-math3\3.4.1\commons-math3-3.4.1.jar;D:\Repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;D:\Repository\org\slf4j\slf4j-api\1.7.16\slf4j-api-1.7.16.jar;D:\Repository\org\slf4j\jul-to-slf4j\1.7.16\jul-to-slf4j-1.7.16.jar;D:\Repository\org\slf4j\jcl-over-slf4j\1.7.16\jcl-over-slf4j-1.7.16.jar;D:\Repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;D:\Repository\org\slf4j\slf4j-log4j12\1.7.16\slf4j-log4j12-1.7.16.jar;D:\Repository\com\ning\compress-lzf\1.0.3\compress-lzf-1.0.3.jar;D:\Repository\org\xerial\snappy\snappy-java\1.1.2.6\snappy-java-1.1.2.6.jar;D:\Repository\net\jpountz\lz4\lz4\1.3.0\lz4-1.3.0.jar;D:\Repository\org\roaringbitmap\RoaringBitmap\0.5.11\RoaringBitmap-0.5.11.jar;D:\Repository\commons-net\commons-net\2.2\commons-net-2.2.jar;D:\Repository\org\json4s\json4s-jackson_2.11\3.2.11\json4s-jackson_2.11-3.2.11.jar;D:\Repository\org\json4s\json4s-core_2.11\3.2.11\json4s-core_2.11-3.2.11.jar;D:\Repository\org\json4s\json4s-ast_2.11\3.2.11\json4s-ast_2.11-3.2.11.jar;D:\Repository\com\thoughtworks\paranamer\paranamer\2.6\paranamer-2.6.jar;D:\Repository\org\scala-lang\scalap\2.11.0\scalap-2.11.0.jar;D:\Repository\org\scala-lang\scala-compiler\2.11.0\scala-compiler-2.11.0.jar;D:\Repository\org\glassfish\jersey\core\jersey-client\2.22.2\jersey-client-2.22.2.jar;D:\Repository\javax\ws\rs\javax.ws.rs-api\2.0.1\javax.ws.rs-api-2.0.1.jar;D:\Repository\org\glassfish\hk2\hk2-api\2.4.0-b34\hk2-api-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\hk2-utils\2.4.0-b34\hk2-utils-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\external\aopalliance-repackaged\2.4.0-b34\aopalliance-repackaged-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\external\javax.inject\2.4.0-b34\javax.inject-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\hk2-locator\2.4.0-b34\hk2-locator-2.4.0-b34.jar;D:\Repository\org\javassist\javassist\3.18.1-GA\javassist-3.18.1-GA.jar;D:\Repository\org\glassfish\jersey\core\jersey-common\2.22.2\jersey-common-2.22.2.jar;D:\Repository\javax\annotation\javax.annotation-api\1.2\javax.annotation-api-1.2.jar;D:\Repository\org\glassfish\jersey\bundles\repackaged\jersey-guava\2.22.2\jersey-guava-2.22.2.jar;D:\Repository\org\glassfish\hk2\osgi-resource-locator\1.0.1\osgi-resource-locator-1.0.1.jar;D:\Repository\org\glassfish\jersey\core\jersey-server\2.22.2\jersey-server-2.22.2.jar;D:\Repository\org\glassfish\jersey\media\jersey-media-jaxb\2.22.2\jersey-media-jaxb-2.22.2.jar;D:\Repository\javax\validation\validation-api\1.1.0.Final\validation-api-1.1.0.Final.jar;D:\Repository\org\glassfish\jersey\containers\jersey-container-servlet\2.22.2\jersey-container-servlet-2.22.2.jar;D:\Repository\org\glassfish\jersey\containers\jersey-container-servlet-core\2.22.2\jersey-container-servlet-core-2.22.2.jar;D:\Repository\io\netty\netty-all\4.0.42.Final\netty-all-4.0.42.Final.jar;D:\Repository\io\netty\netty\3.8.0.Final\netty-3.8.0.Final.jar;D:\Repository\com\clearspring\analytics\stream\2.7.0\stream-2.7.0.jar;D:\Repository\io\dropwizard\metrics\metrics-core\3.1.2\metrics-core-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-jvm\3.1.2\metrics-jvm-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-json\3.1.2\metrics-json-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-graphite\3.1.2\metrics-graphite-3.1.2.jar;D:\Repository\com\fasterxml\jackson\core\jackson-databind\2.6.5\jackson-databind-2.6.5.jar;D:\Repository\com\fasterxml\jackson\core\jackson-core\2.6.5\jackson-core-2.6.5.jar;D:\Repository\com\fasterxml\jackson\module\jackson-module-scala_2.11\2.6.5\jackson-module-scala_2.11-2.6.5.jar;D:\Repository\org\scala-lang\scala-reflect\2.11.7\scala-reflect-2.11.7.jar;D:\Repository\com\fasterxml\jackson\module\jackson-module-paranamer\2.6.5\jackson-module-paranamer-2.6.5.jar;D:\Repository\org\apache\ivy\ivy\2.4.0\ivy-2.4.0.jar;D:\Repository\oro\oro\2.0.8\oro-2.0.8.jar;D:\Repository\net\razorvine\pyrolite\4.13\pyrolite-4.13.jar;D:\Repository\net\sf\py4j\py4j\0.10.4\py4j-0.10.4.jar;D:\Repository\org\apache\spark\spark-tags_2.11\2.1.0\spark-tags_2.11-2.1.0.jar;D:\Repository\org\scalatest\scalatest_2.11\2.2.6\scalatest_2.11-2.2.6.jar;D:\Repository\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;D:\Repository\org\spark-project\spark\unused\1.0.0\unused-1.0.0.jar;D:\Repository\org\apache\spark\spark-streaming_2.11\2.1.0\spark-streaming_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-sql_2.11\2.1.0\spark-sql_2.11-2.1.0.jar;D:\Repository\com\univocity\univocity-parsers\2.2.1\univocity-parsers-2.2.1.jar;D:\Repository\org\apache\spark\spark-sketch_2.11\2.1.0\spark-sketch_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-catalyst_2.11\2.1.0\spark-catalyst_2.11-2.1.0.jar;D:\Repository\org\codehaus\janino\janino\3.0.0\janino-3.0.0.jar;D:\Repository\org\codehaus\janino\commons-compiler\3.0.0\commons-compiler-3.0.0.jar;D:\Repository\org\antlr\antlr4-runtime\4.5.3\antlr4-runtime-4.5.3.jar;D:\Repository\org\apache\parquet\parquet-column\1.8.1\parquet-column-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-common\1.8.1\parquet-common-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-encoding\1.8.1\parquet-encoding-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-hadoop\1.8.1\parquet-hadoop-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-format\2.3.0-incubating\parquet-format-2.3.0-incubating.jar;D:\Repository\org\apache\parquet\parquet-jackson\1.8.1\parquet-jackson-1.8.1.jar;D:\Repository\org\apache\hadoop\hadoop-client\2.6.5\hadoop-client-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-common\2.6.5\hadoop-common-2.6.5.jar;D:\Repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;D:\Repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;D:\Repository\commons-io\commons-io\2.4\commons-io-2.4.jar;D:\Repository\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;D:\Repository\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;D:\Repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\Repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;D:\Repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;D:\Repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;D:\Repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;D:\Repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;D:\Repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;D:\Repository\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;D:\Repository\org\apache\hadoop\hadoop-auth\2.6.5\hadoop-auth-2.6.5.jar;D:\Repository\org\apache\httpcomponents\httpclient\4.2.5\httpclient-4.2.5.jar;D:\Repository\org\apache\httpcomponents\httpcore\4.2.4\httpcore-4.2.4.jar;D:\Repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;D:\Repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;D:\Repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;D:\Repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;D:\Repository\org\apache\curator\curator-client\2.6.0\curator-client-2.6.0.jar;D:\Repository\org\htrace\htrace-core\3.0.4\htrace-core-3.0.4.jar;D:\Repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;D:\Repository\org\tukaani\xz\1.0\xz-1.0.jar;D:\Repository\org\apache\hadoop\hadoop-hdfs\2.6.5\hadoop-hdfs-2.6.5.jar;D:\Repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;D:\Repository\xerces\xercesImpl\2.9.1\xercesImpl-2.9.1.jar;D:\Repository\xml-apis\xml-apis\1.3.04\xml-apis-1.3.04.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.6.5\hadoop-mapreduce-client-app-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.6.5\hadoop-mapreduce-client-common-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-client\2.6.5\hadoop-yarn-client-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-server-common\2.6.5\hadoop-yarn-server-common-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.6.5\hadoop-mapreduce-client-shuffle-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-api\2.6.5\hadoop-yarn-api-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.6.5\hadoop-mapreduce-client-core-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-common\2.6.5\hadoop-yarn-common-2.6.5.jar;D:\Repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;D:\Repository\javax\xml\stream\stax-api\1.0-2\stax-api-1.0-2.jar;D:\Repository\javax\activation\activation\1.1\activation-1.1.jar;D:\Repository\javax\servlet\servlet-api\2.5\servlet-api-2.5.jar;D:\Repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;D:\Repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;D:\Repository\org\codehaus\jackson\jackson-jaxrs\1.9.13\jackson-jaxrs-1.9.13.jar;D:\Repository\org\codehaus\jackson\jackson-xc\1.9.13\jackson-xc-1.9.13.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.6.5\hadoop-mapreduce-client-jobclient-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-annotations\2.6.5\hadoop-annotations-2.6.5.jar;D:\Repository\org\apache\kafka\kafka-clients\0.8.2.2\kafka-clients-0.8.2.2.jar;D:\Repository\org\apache\kafka\kafka_2.11\0.8.2.2\kafka_2.11-0.8.2.2.jar;D:\Repository\org\scala-lang\modules\scala-xml_2.11\1.0.2\scala-xml_2.11-1.0.2.jar;D:\Repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;D:\Repository\net\sf\jopt-simple\jopt-simple\3.2\jopt-simple-3.2.jar;D:\Repository\org\scala-lang\modules\scala-parser-combinators_2.11\1.0.2\scala-parser-combinators_2.11-1.0.2.jar;D:\Repository\com\101tec\zkclient\0.3\zkclient-0.3.jar;D:\Repository\mysql\mysql-connector-java\5.1.38\mysql-connector-java-5.1.38.jar;D:\Repository\org\apache\spark\spark-streaming-kafka-0-8_2.11\2.1.0\spark-streaming-kafka-0-8_2.11-2.1.0.jar;D:\Repository\org\apache\zookeeper\zookeeper\3.4.10\zookeeper-3.4.10.jar;D:\Repository\jline\jline\0.9.94\jline-0.9.94.jar;D:\developTools\IntelliJ IDEA 2018.2.3\lib\idea_rt.jar
2018-12-26 14:54:20 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_171\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;D:\developTools\Git\cmd;D:\developTools\svn\bin;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\scala\bin;C:\Users\junmei02\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk1.8.0_171\bin;D:\developTools\apache-maven-3.5.2\bin;D:\developTools\mysql-5.6.27-winx64\bin;D:\developTools\Git\cmd;D:\hadoop\hadoop-common-2.2.0-bin-master\bin;D:\hadoop\hbase-1.2.6\bin;C:\Program Files (x86)\scala\bin;D:\bigdata\zookeeper-3.4.10\bin;;.
2018-12-26 14:54:20 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.io.tmpdir=C:\Users\junmei02\AppData\Local\Temp\
2018-12-26 14:54:20 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.compiler=<NA>
2018-12-26 14:54:20 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.name=Windows 10
2018-12-26 14:54:20 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.arch=amd64
2018-12-26 14:54:20 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.version=10.0
2018-12-26 14:54:20 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.name=junmei02
2018-12-26 14:54:20 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.home=C:\Users\junmei02
2018-12-26 14:54:20 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.dir=D:\springbootworkspace\spark
2018-12-26 14:54:20 [ INFO ] - [ org.apache.zookeeper.ZooKeeper.<init>(ZooKeeper.java:438) ] Initiating client connection, connectString=127.0.0.1:2181 sessionTimeout=10000 watcher=org.apache.curator.ConnectionState@7ef82753
2018-12-26 14:54:21 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:1032) ] Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2018-12-26 14:54:21 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$SendThread.primeConnection(ClientCnxn.java:876) ] Socket connection established to 127.0.0.1/127.0.0.1:2181, initiating session
2018-12-26 14:54:21 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$SendThread.onConnected(ClientCnxn.java:1299) ] Session establishment complete on server 127.0.0.1/127.0.0.1:2181, sessionid = 0x167e901f2f50006, negotiated timeout = 10000
2018-12-26 14:54:21 [ INFO ] - [ org.apache.curator.framework.state.ConnectionStateManager.postState(ConnectionStateManager.java:194) ] State change: CONNECTED
2018-12-26 14:54:21 [ WARN ] - [ org.apache.curator.framework.state.ConnectionStateManager.processEvents(ConnectionStateManager.java:212) ] There are no ConnectionStateListeners registered.
2018-12-26 14:54:22 [ INFO ] - [ org.apache.zookeeper.ZooKeeper.close(ZooKeeper.java:684) ] Session: 0x167e901f2f50006 closed
2018-12-26 14:54:22 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:519) ] EventThread shut down for session: 0x167e901f2f50006
2018-12-26 14:54:23 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Running Spark version 2.1.0
2018-12-26 14:54:23 [ ERROR ] - [ org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:396) ] Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2373)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2373)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2373)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:837)
	at org.apache.spark.streaming.StreamingContext.<init>(StreamingContext.scala:84)
	at org.apache.spark.streaming.api.java.JavaStreamingContext.<init>(JavaStreamingContext.scala:138)
	at com.zqg.StreamKafka.SparkStreamingDirect.getStreamingContext(SparkStreamingDirect.java:38)
	at com.zqg.StreamKafka.KafkaSparkStreamingWithZookeeperoffset.main(KafkaSparkStreamingWithZookeeperoffset.java:55)
2018-12-26 14:54:23 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing view acls to: junmei02
2018-12-26 14:54:23 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing modify acls to: junmei02
2018-12-26 14:54:23 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing view acls groups to: 
2018-12-26 14:54:23 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing modify acls groups to: 
2018-12-26 14:54:23 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(junmei02); groups with view permissions: Set(); users  with modify permissions: Set(junmei02); groups with modify permissions: Set()
2018-12-26 14:54:23 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'sparkDriver' on port 52577.
2018-12-26 14:54:23 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering MapOutputTracker
2018-12-26 14:54:23 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering BlockManagerMaster
2018-12-26 14:54:23 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-26 14:54:23 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] BlockManagerMasterEndpoint up
2018-12-26 14:54:23 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Created local directory at C:\Users\junmei02\AppData\Local\Temp\blockmgr-61dc9850-011f-45fa-98df-457eb2cad34e
2018-12-26 14:54:23 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] MemoryStore started with capacity 900.6 MB
2018-12-26 14:54:23 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering OutputCommitCoordinator
2018-12-26 14:54:24 [ INFO ] - [ org.spark_project.jetty.util.log.Log.initialized(Log.java:186) ] Logging initialized @4419ms
2018-12-26 14:54:24 [ INFO ] - [ org.spark_project.jetty.server.Server.doStart(Server.java:327) ] jetty-9.2.z-SNAPSHOT
2018-12-26 14:54:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@1e411d81{/jobs,null,AVAILABLE}
2018-12-26 14:54:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@53b98ff6{/jobs/json,null,AVAILABLE}
2018-12-26 14:54:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@3e6fd0b9{/jobs/job,null,AVAILABLE}
2018-12-26 14:54:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@7fcff1b9{/jobs/job/json,null,AVAILABLE}
2018-12-26 14:54:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@697446d4{/stages,null,AVAILABLE}
2018-12-26 14:54:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@76adb233{/stages/json,null,AVAILABLE}
2018-12-26 14:54:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@36074e47{/stages/stage,null,AVAILABLE}
2018-12-26 14:54:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@36453307{/stages/stage/json,null,AVAILABLE}
2018-12-26 14:54:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@7dcc91fd{/stages/pool,null,AVAILABLE}
2018-12-26 14:54:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@66eb985d{/stages/pool/json,null,AVAILABLE}
2018-12-26 14:54:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@6a9287b1{/storage,null,AVAILABLE}
2018-12-26 14:54:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@75504cef{/storage/json,null,AVAILABLE}
2018-12-26 14:54:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@6c8a68c1{/storage/rdd,null,AVAILABLE}
2018-12-26 14:54:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@56193c7d{/storage/rdd/json,null,AVAILABLE}
2018-12-26 14:54:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@28c88600{/environment,null,AVAILABLE}
2018-12-26 14:54:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@5f8890c2{/environment/json,null,AVAILABLE}
2018-12-26 14:54:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@607b2792{/executors,null,AVAILABLE}
2018-12-26 14:54:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@7f9e1534{/executors/json,null,AVAILABLE}
2018-12-26 14:54:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@138a7441{/executors/threadDump,null,AVAILABLE}
2018-12-26 14:54:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@81ff872{/executors/threadDump/json,null,AVAILABLE}
2018-12-26 14:54:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@31611954{/static,null,AVAILABLE}
2018-12-26 14:54:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@3e598df9{/,null,AVAILABLE}
2018-12-26 14:54:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@7e31ce0f{/api,null,AVAILABLE}
2018-12-26 14:54:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@99a65d3{/jobs/job/kill,null,AVAILABLE}
2018-12-26 14:54:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@3088660d{/stages/stage/kill,null,AVAILABLE}
2018-12-26 14:54:24 [ INFO ] - [ org.spark_project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:266) ] Started ServerConnector@46a439aa{HTTP/1.1}{0.0.0.0:4040}
2018-12-26 14:54:24 [ INFO ] - [ org.spark_project.jetty.server.Server.doStart(Server.java:379) ] Started @4569ms
2018-12-26 14:54:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'SparkUI' on port 4040.
2018-12-26 14:54:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Bound SparkUI to 0.0.0.0, and started at http://192.168.0.112:4040
2018-12-26 14:54:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Starting executor ID driver on host localhost
2018-12-26 14:54:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52598.
2018-12-26 14:54:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Server created on 192.168.0.112:52598
2018-12-26 14:54:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-26 14:54:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering BlockManager BlockManagerId(driver, 192.168.0.112, 52598, None)
2018-12-26 14:54:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering block manager 192.168.0.112:52598 with 900.6 MB RAM, BlockManagerId(driver, 192.168.0.112, 52598, None)
2018-12-26 14:54:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registered BlockManager BlockManagerId(driver, 192.168.0.112, 52598, None)
2018-12-26 14:54:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Initialized BlockManager: BlockManagerId(driver, 192.168.0.112, 52598, None)
2018-12-26 14:54:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@29314cc9{/metrics/json,null,AVAILABLE}
2018-12-26 14:56:37 [ ERROR ] - [ org.apache.spark.internal.Logging$class.logError(Logging.scala:70) ] ArrayBuffer(java.nio.channels.ClosedChannelException, java.nio.channels.ClosedChannelException, java.nio.channels.ClosedChannelException)
2018-12-26 14:57:30 [ INFO ] - [ com.zqg.StreamKafka.KafkaSparkStreamingWithZookeeperoffset.main(KafkaSparkStreamingWithZookeeperoffset.java:21) ] 
java.lang.Exception: asdfas
	at com.zqg.StreamKafka.KafkaSparkStreamingWithZookeeperoffset.main(KafkaSparkStreamingWithZookeeperoffset.java:21)
2018-12-26 15:18:59 [ INFO ] - [ org.apache.curator.framework.imps.CuratorFrameworkImpl.start(CuratorFrameworkImpl.java:223) ] Starting
2018-12-26 15:18:59 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT
2018-12-26 15:18:59 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:host.name=windows10.microdone.cn
2018-12-26 15:18:59 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.version=1.8.0_171
2018-12-26 15:18:59 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.vendor=Oracle Corporation
2018-12-26 15:18:59 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.home=C:\Program Files\Java\jdk1.8.0_171\jre
2018-12-26 15:18:59 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.class.path=C:\Program Files\Java\jdk1.8.0_171\jre\lib\charsets.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\deploy.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\access-bridge-64.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\cldrdata.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\dnsns.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\jaccess.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\jfxrt.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\localedata.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\nashorn.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunec.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunjce_provider.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunmscapi.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunpkcs11.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\zipfs.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\javaws.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jce.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jfr.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jfxswt.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jsse.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\management-agent.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\plugin.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\resources.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\rt.jar;D:\springbootworkspace\spark\target\classes;D:\Repository\org\scala-lang\scala-library\2.11.8\scala-library-2.11.8.jar;D:\Repository\org\apache\spark\spark-core_2.11\2.1.0\spark-core_2.11-2.1.0.jar;D:\Repository\org\apache\avro\avro-mapred\1.7.7\avro-mapred-1.7.7-hadoop2.jar;D:\Repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7.jar;D:\Repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7-tests.jar;D:\Repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;D:\Repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;D:\Repository\com\twitter\chill_2.11\0.8.0\chill_2.11-0.8.0.jar;D:\Repository\com\esotericsoftware\kryo-shaded\3.0.3\kryo-shaded-3.0.3.jar;D:\Repository\com\esotericsoftware\minlog\1.3.0\minlog-1.3.0.jar;D:\Repository\org\objenesis\objenesis\2.1\objenesis-2.1.jar;D:\Repository\com\twitter\chill-java\0.8.0\chill-java-0.8.0.jar;D:\Repository\org\apache\xbean\xbean-asm5-shaded\4.4\xbean-asm5-shaded-4.4.jar;D:\Repository\org\apache\spark\spark-launcher_2.11\2.1.0\spark-launcher_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-network-common_2.11\2.1.0\spark-network-common_2.11-2.1.0.jar;D:\Repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;D:\Repository\com\fasterxml\jackson\core\jackson-annotations\2.6.5\jackson-annotations-2.6.5.jar;D:\Repository\org\apache\spark\spark-network-shuffle_2.11\2.1.0\spark-network-shuffle_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-unsafe_2.11\2.1.0\spark-unsafe_2.11-2.1.0.jar;D:\Repository\net\java\dev\jets3t\jets3t\0.7.1\jets3t-0.7.1.jar;D:\Repository\commons-codec\commons-codec\1.3\commons-codec-1.3.jar;D:\Repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;D:\Repository\org\apache\curator\curator-recipes\2.4.0\curator-recipes-2.4.0.jar;D:\Repository\org\apache\curator\curator-framework\2.4.0\curator-framework-2.4.0.jar;D:\Repository\com\google\guava\guava\14.0.1\guava-14.0.1.jar;D:\Repository\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;D:\Repository\org\apache\commons\commons-lang3\3.5\commons-lang3-3.5.jar;D:\Repository\org\apache\commons\commons-math3\3.4.1\commons-math3-3.4.1.jar;D:\Repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;D:\Repository\org\slf4j\slf4j-api\1.7.16\slf4j-api-1.7.16.jar;D:\Repository\org\slf4j\jul-to-slf4j\1.7.16\jul-to-slf4j-1.7.16.jar;D:\Repository\org\slf4j\jcl-over-slf4j\1.7.16\jcl-over-slf4j-1.7.16.jar;D:\Repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;D:\Repository\org\slf4j\slf4j-log4j12\1.7.16\slf4j-log4j12-1.7.16.jar;D:\Repository\com\ning\compress-lzf\1.0.3\compress-lzf-1.0.3.jar;D:\Repository\org\xerial\snappy\snappy-java\1.1.2.6\snappy-java-1.1.2.6.jar;D:\Repository\net\jpountz\lz4\lz4\1.3.0\lz4-1.3.0.jar;D:\Repository\org\roaringbitmap\RoaringBitmap\0.5.11\RoaringBitmap-0.5.11.jar;D:\Repository\commons-net\commons-net\2.2\commons-net-2.2.jar;D:\Repository\org\json4s\json4s-jackson_2.11\3.2.11\json4s-jackson_2.11-3.2.11.jar;D:\Repository\org\json4s\json4s-core_2.11\3.2.11\json4s-core_2.11-3.2.11.jar;D:\Repository\org\json4s\json4s-ast_2.11\3.2.11\json4s-ast_2.11-3.2.11.jar;D:\Repository\com\thoughtworks\paranamer\paranamer\2.6\paranamer-2.6.jar;D:\Repository\org\scala-lang\scalap\2.11.0\scalap-2.11.0.jar;D:\Repository\org\scala-lang\scala-compiler\2.11.0\scala-compiler-2.11.0.jar;D:\Repository\org\glassfish\jersey\core\jersey-client\2.22.2\jersey-client-2.22.2.jar;D:\Repository\javax\ws\rs\javax.ws.rs-api\2.0.1\javax.ws.rs-api-2.0.1.jar;D:\Repository\org\glassfish\hk2\hk2-api\2.4.0-b34\hk2-api-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\hk2-utils\2.4.0-b34\hk2-utils-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\external\aopalliance-repackaged\2.4.0-b34\aopalliance-repackaged-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\external\javax.inject\2.4.0-b34\javax.inject-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\hk2-locator\2.4.0-b34\hk2-locator-2.4.0-b34.jar;D:\Repository\org\javassist\javassist\3.18.1-GA\javassist-3.18.1-GA.jar;D:\Repository\org\glassfish\jersey\core\jersey-common\2.22.2\jersey-common-2.22.2.jar;D:\Repository\javax\annotation\javax.annotation-api\1.2\javax.annotation-api-1.2.jar;D:\Repository\org\glassfish\jersey\bundles\repackaged\jersey-guava\2.22.2\jersey-guava-2.22.2.jar;D:\Repository\org\glassfish\hk2\osgi-resource-locator\1.0.1\osgi-resource-locator-1.0.1.jar;D:\Repository\org\glassfish\jersey\core\jersey-server\2.22.2\jersey-server-2.22.2.jar;D:\Repository\org\glassfish\jersey\media\jersey-media-jaxb\2.22.2\jersey-media-jaxb-2.22.2.jar;D:\Repository\javax\validation\validation-api\1.1.0.Final\validation-api-1.1.0.Final.jar;D:\Repository\org\glassfish\jersey\containers\jersey-container-servlet\2.22.2\jersey-container-servlet-2.22.2.jar;D:\Repository\org\glassfish\jersey\containers\jersey-container-servlet-core\2.22.2\jersey-container-servlet-core-2.22.2.jar;D:\Repository\io\netty\netty-all\4.0.42.Final\netty-all-4.0.42.Final.jar;D:\Repository\io\netty\netty\3.8.0.Final\netty-3.8.0.Final.jar;D:\Repository\com\clearspring\analytics\stream\2.7.0\stream-2.7.0.jar;D:\Repository\io\dropwizard\metrics\metrics-core\3.1.2\metrics-core-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-jvm\3.1.2\metrics-jvm-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-json\3.1.2\metrics-json-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-graphite\3.1.2\metrics-graphite-3.1.2.jar;D:\Repository\com\fasterxml\jackson\core\jackson-databind\2.6.5\jackson-databind-2.6.5.jar;D:\Repository\com\fasterxml\jackson\core\jackson-core\2.6.5\jackson-core-2.6.5.jar;D:\Repository\com\fasterxml\jackson\module\jackson-module-scala_2.11\2.6.5\jackson-module-scala_2.11-2.6.5.jar;D:\Repository\org\scala-lang\scala-reflect\2.11.7\scala-reflect-2.11.7.jar;D:\Repository\com\fasterxml\jackson\module\jackson-module-paranamer\2.6.5\jackson-module-paranamer-2.6.5.jar;D:\Repository\org\apache\ivy\ivy\2.4.0\ivy-2.4.0.jar;D:\Repository\oro\oro\2.0.8\oro-2.0.8.jar;D:\Repository\net\razorvine\pyrolite\4.13\pyrolite-4.13.jar;D:\Repository\net\sf\py4j\py4j\0.10.4\py4j-0.10.4.jar;D:\Repository\org\apache\spark\spark-tags_2.11\2.1.0\spark-tags_2.11-2.1.0.jar;D:\Repository\org\scalatest\scalatest_2.11\2.2.6\scalatest_2.11-2.2.6.jar;D:\Repository\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;D:\Repository\org\spark-project\spark\unused\1.0.0\unused-1.0.0.jar;D:\Repository\org\apache\spark\spark-streaming_2.11\2.1.0\spark-streaming_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-sql_2.11\2.1.0\spark-sql_2.11-2.1.0.jar;D:\Repository\com\univocity\univocity-parsers\2.2.1\univocity-parsers-2.2.1.jar;D:\Repository\org\apache\spark\spark-sketch_2.11\2.1.0\spark-sketch_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-catalyst_2.11\2.1.0\spark-catalyst_2.11-2.1.0.jar;D:\Repository\org\codehaus\janino\janino\3.0.0\janino-3.0.0.jar;D:\Repository\org\codehaus\janino\commons-compiler\3.0.0\commons-compiler-3.0.0.jar;D:\Repository\org\antlr\antlr4-runtime\4.5.3\antlr4-runtime-4.5.3.jar;D:\Repository\org\apache\parquet\parquet-column\1.8.1\parquet-column-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-common\1.8.1\parquet-common-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-encoding\1.8.1\parquet-encoding-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-hadoop\1.8.1\parquet-hadoop-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-format\2.3.0-incubating\parquet-format-2.3.0-incubating.jar;D:\Repository\org\apache\parquet\parquet-jackson\1.8.1\parquet-jackson-1.8.1.jar;D:\Repository\org\apache\hadoop\hadoop-client\2.6.5\hadoop-client-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-common\2.6.5\hadoop-common-2.6.5.jar;D:\Repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;D:\Repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;D:\Repository\commons-io\commons-io\2.4\commons-io-2.4.jar;D:\Repository\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;D:\Repository\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;D:\Repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\Repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;D:\Repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;D:\Repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;D:\Repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;D:\Repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;D:\Repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;D:\Repository\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;D:\Repository\org\apache\hadoop\hadoop-auth\2.6.5\hadoop-auth-2.6.5.jar;D:\Repository\org\apache\httpcomponents\httpclient\4.2.5\httpclient-4.2.5.jar;D:\Repository\org\apache\httpcomponents\httpcore\4.2.4\httpcore-4.2.4.jar;D:\Repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;D:\Repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;D:\Repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;D:\Repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;D:\Repository\org\apache\curator\curator-client\2.6.0\curator-client-2.6.0.jar;D:\Repository\org\htrace\htrace-core\3.0.4\htrace-core-3.0.4.jar;D:\Repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;D:\Repository\org\tukaani\xz\1.0\xz-1.0.jar;D:\Repository\org\apache\hadoop\hadoop-hdfs\2.6.5\hadoop-hdfs-2.6.5.jar;D:\Repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;D:\Repository\xerces\xercesImpl\2.9.1\xercesImpl-2.9.1.jar;D:\Repository\xml-apis\xml-apis\1.3.04\xml-apis-1.3.04.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.6.5\hadoop-mapreduce-client-app-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.6.5\hadoop-mapreduce-client-common-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-client\2.6.5\hadoop-yarn-client-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-server-common\2.6.5\hadoop-yarn-server-common-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.6.5\hadoop-mapreduce-client-shuffle-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-api\2.6.5\hadoop-yarn-api-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.6.5\hadoop-mapreduce-client-core-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-common\2.6.5\hadoop-yarn-common-2.6.5.jar;D:\Repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;D:\Repository\javax\xml\stream\stax-api\1.0-2\stax-api-1.0-2.jar;D:\Repository\javax\activation\activation\1.1\activation-1.1.jar;D:\Repository\javax\servlet\servlet-api\2.5\servlet-api-2.5.jar;D:\Repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;D:\Repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;D:\Repository\org\codehaus\jackson\jackson-jaxrs\1.9.13\jackson-jaxrs-1.9.13.jar;D:\Repository\org\codehaus\jackson\jackson-xc\1.9.13\jackson-xc-1.9.13.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.6.5\hadoop-mapreduce-client-jobclient-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-annotations\2.6.5\hadoop-annotations-2.6.5.jar;D:\Repository\org\apache\kafka\kafka-clients\0.8.2.2\kafka-clients-0.8.2.2.jar;D:\Repository\org\apache\kafka\kafka_2.11\0.8.2.2\kafka_2.11-0.8.2.2.jar;D:\Repository\org\scala-lang\modules\scala-xml_2.11\1.0.2\scala-xml_2.11-1.0.2.jar;D:\Repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;D:\Repository\net\sf\jopt-simple\jopt-simple\3.2\jopt-simple-3.2.jar;D:\Repository\org\scala-lang\modules\scala-parser-combinators_2.11\1.0.2\scala-parser-combinators_2.11-1.0.2.jar;D:\Repository\com\101tec\zkclient\0.3\zkclient-0.3.jar;D:\Repository\mysql\mysql-connector-java\5.1.38\mysql-connector-java-5.1.38.jar;D:\Repository\org\apache\spark\spark-streaming-kafka-0-8_2.11\2.1.0\spark-streaming-kafka-0-8_2.11-2.1.0.jar;D:\Repository\org\apache\zookeeper\zookeeper\3.4.10\zookeeper-3.4.10.jar;D:\Repository\jline\jline\0.9.94\jline-0.9.94.jar;D:\developTools\IntelliJ IDEA 2018.2.3\lib\idea_rt.jar
2018-12-26 15:18:59 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_171\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;D:\developTools\Git\cmd;D:\developTools\svn\bin;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\scala\bin;C:\Users\junmei02\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk1.8.0_171\bin;D:\developTools\apache-maven-3.5.2\bin;D:\developTools\mysql-5.6.27-winx64\bin;D:\developTools\Git\cmd;D:\hadoop\hadoop-common-2.2.0-bin-master\bin;D:\hadoop\hbase-1.2.6\bin;C:\Program Files (x86)\scala\bin;D:\bigdata\zookeeper-3.4.10\bin;;.
2018-12-26 15:18:59 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.io.tmpdir=C:\Users\junmei02\AppData\Local\Temp\
2018-12-26 15:18:59 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.compiler=<NA>
2018-12-26 15:18:59 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.name=Windows 10
2018-12-26 15:18:59 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.arch=amd64
2018-12-26 15:18:59 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.version=10.0
2018-12-26 15:18:59 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.name=junmei02
2018-12-26 15:18:59 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.home=C:\Users\junmei02
2018-12-26 15:18:59 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.dir=D:\springbootworkspace\spark
2018-12-26 15:18:59 [ INFO ] - [ org.apache.zookeeper.ZooKeeper.<init>(ZooKeeper.java:438) ] Initiating client connection, connectString=127.0.0.1:2181 sessionTimeout=10000 watcher=org.apache.curator.ConnectionState@793f29ff
2018-12-26 15:18:59 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:1032) ] Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2018-12-26 15:18:59 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$SendThread.primeConnection(ClientCnxn.java:876) ] Socket connection established to 127.0.0.1/127.0.0.1:2181, initiating session
2018-12-26 15:18:59 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$SendThread.onConnected(ClientCnxn.java:1299) ] Session establishment complete on server 127.0.0.1/127.0.0.1:2181, sessionid = 0x167e951e94d0001, negotiated timeout = 10000
2018-12-26 15:18:59 [ INFO ] - [ org.apache.curator.framework.state.ConnectionStateManager.postState(ConnectionStateManager.java:194) ] State change: CONNECTED
2018-12-26 15:18:59 [ WARN ] - [ org.apache.curator.framework.state.ConnectionStateManager.processEvents(ConnectionStateManager.java:212) ] There are no ConnectionStateListeners registered.
2018-12-26 15:19:00 [ INFO ] - [ org.apache.zookeeper.ZooKeeper.close(ZooKeeper.java:684) ] Session: 0x167e951e94d0001 closed
2018-12-26 15:19:00 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:519) ] EventThread shut down for session: 0x167e951e94d0001
2018-12-26 15:19:01 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Running Spark version 2.1.0
2018-12-26 15:19:01 [ ERROR ] - [ org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:396) ] Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2373)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2373)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2373)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:837)
	at org.apache.spark.streaming.StreamingContext.<init>(StreamingContext.scala:84)
	at org.apache.spark.streaming.api.java.JavaStreamingContext.<init>(JavaStreamingContext.scala:138)
	at com.zqg.StreamKafka.SparkStreamingDirect.getStreamingContext(SparkStreamingDirect.java:38)
	at com.zqg.StreamKafka.KafkaSparkStreamingWithZookeeperoffset.main(KafkaSparkStreamingWithZookeeperoffset.java:55)
2018-12-26 15:19:01 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing view acls to: junmei02
2018-12-26 15:19:01 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing modify acls to: junmei02
2018-12-26 15:19:01 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing view acls groups to: 
2018-12-26 15:19:01 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing modify acls groups to: 
2018-12-26 15:19:01 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(junmei02); groups with view permissions: Set(); users  with modify permissions: Set(junmei02); groups with modify permissions: Set()
2018-12-26 15:19:02 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'sparkDriver' on port 53210.
2018-12-26 15:19:02 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering MapOutputTracker
2018-12-26 15:19:02 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering BlockManagerMaster
2018-12-26 15:19:02 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-26 15:19:02 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] BlockManagerMasterEndpoint up
2018-12-26 15:19:02 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Created local directory at C:\Users\junmei02\AppData\Local\Temp\blockmgr-c265bcd8-a68d-49c5-94ac-8e227bbdb502
2018-12-26 15:19:02 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] MemoryStore started with capacity 900.6 MB
2018-12-26 15:19:02 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering OutputCommitCoordinator
2018-12-26 15:19:02 [ INFO ] - [ org.spark_project.jetty.util.log.Log.initialized(Log.java:186) ] Logging initialized @4437ms
2018-12-26 15:19:02 [ INFO ] - [ org.spark_project.jetty.server.Server.doStart(Server.java:327) ] jetty-9.2.z-SNAPSHOT
2018-12-26 15:19:02 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@75504cef{/jobs,null,AVAILABLE}
2018-12-26 15:19:02 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@6c8a68c1{/jobs/json,null,AVAILABLE}
2018-12-26 15:19:02 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@56193c7d{/jobs/job,null,AVAILABLE}
2018-12-26 15:19:02 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@28c88600{/jobs/job/json,null,AVAILABLE}
2018-12-26 15:19:02 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@5f8890c2{/stages,null,AVAILABLE}
2018-12-26 15:19:02 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@607b2792{/stages/json,null,AVAILABLE}
2018-12-26 15:19:02 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@7f9e1534{/stages/stage,null,AVAILABLE}
2018-12-26 15:19:02 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@138a7441{/stages/stage/json,null,AVAILABLE}
2018-12-26 15:19:02 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@81ff872{/stages/pool,null,AVAILABLE}
2018-12-26 15:19:02 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@31611954{/stages/pool/json,null,AVAILABLE}
2018-12-26 15:19:02 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@3e598df9{/storage,null,AVAILABLE}
2018-12-26 15:19:02 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@7e31ce0f{/storage/json,null,AVAILABLE}
2018-12-26 15:19:02 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@99a65d3{/storage/rdd,null,AVAILABLE}
2018-12-26 15:19:02 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@3088660d{/storage/rdd/json,null,AVAILABLE}
2018-12-26 15:19:02 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@42cc13a0{/environment,null,AVAILABLE}
2018-12-26 15:19:02 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@32fdec40{/environment/json,null,AVAILABLE}
2018-12-26 15:19:02 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@6813a331{/executors,null,AVAILABLE}
2018-12-26 15:19:02 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@1bd81830{/executors/json,null,AVAILABLE}
2018-12-26 15:19:02 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@39ab59f8{/executors/threadDump,null,AVAILABLE}
2018-12-26 15:19:02 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@64e92d61{/executors/threadDump/json,null,AVAILABLE}
2018-12-26 15:19:02 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@111610e6{/static,null,AVAILABLE}
2018-12-26 15:19:02 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@4ad4936c{/,null,AVAILABLE}
2018-12-26 15:19:02 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@29d37757{/api,null,AVAILABLE}
2018-12-26 15:19:02 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@4fcc529{/jobs/job/kill,null,AVAILABLE}
2018-12-26 15:19:02 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@25cc7470{/stages/stage/kill,null,AVAILABLE}
2018-12-26 15:19:02 [ INFO ] - [ org.spark_project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:266) ] Started ServerConnector@75b21c3b{HTTP/1.1}{0.0.0.0:4040}
2018-12-26 15:19:02 [ INFO ] - [ org.spark_project.jetty.server.Server.doStart(Server.java:379) ] Started @4591ms
2018-12-26 15:19:02 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'SparkUI' on port 4040.
2018-12-26 15:19:02 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Bound SparkUI to 0.0.0.0, and started at http://192.168.0.112:4040
2018-12-26 15:19:02 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Starting executor ID driver on host localhost
2018-12-26 15:19:02 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53231.
2018-12-26 15:19:02 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Server created on 192.168.0.112:53231
2018-12-26 15:19:02 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-26 15:19:02 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering BlockManager BlockManagerId(driver, 192.168.0.112, 53231, None)
2018-12-26 15:19:02 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering block manager 192.168.0.112:53231 with 900.6 MB RAM, BlockManagerId(driver, 192.168.0.112, 53231, None)
2018-12-26 15:19:02 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registered BlockManager BlockManagerId(driver, 192.168.0.112, 53231, None)
2018-12-26 15:19:02 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Initialized BlockManager: BlockManagerId(driver, 192.168.0.112, 53231, None)
2018-12-26 15:19:02 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@29314cc9{/metrics/json,null,AVAILABLE}
2018-12-26 15:20:54 [ INFO ] - [ org.apache.curator.framework.imps.CuratorFrameworkImpl.start(CuratorFrameworkImpl.java:223) ] Starting
2018-12-26 15:20:54 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT
2018-12-26 15:20:54 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:host.name=windows10.microdone.cn
2018-12-26 15:20:54 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.version=1.8.0_171
2018-12-26 15:20:54 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.vendor=Oracle Corporation
2018-12-26 15:20:54 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.home=C:\Program Files\Java\jdk1.8.0_171\jre
2018-12-26 15:20:54 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.class.path=C:\Program Files\Java\jdk1.8.0_171\jre\lib\charsets.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\deploy.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\access-bridge-64.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\cldrdata.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\dnsns.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\jaccess.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\jfxrt.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\localedata.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\nashorn.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunec.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunjce_provider.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunmscapi.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunpkcs11.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\zipfs.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\javaws.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jce.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jfr.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jfxswt.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jsse.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\management-agent.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\plugin.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\resources.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\rt.jar;D:\springbootworkspace\spark\target\classes;D:\Repository\org\scala-lang\scala-library\2.11.8\scala-library-2.11.8.jar;D:\Repository\org\apache\spark\spark-core_2.11\2.1.0\spark-core_2.11-2.1.0.jar;D:\Repository\org\apache\avro\avro-mapred\1.7.7\avro-mapred-1.7.7-hadoop2.jar;D:\Repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7.jar;D:\Repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7-tests.jar;D:\Repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;D:\Repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;D:\Repository\com\twitter\chill_2.11\0.8.0\chill_2.11-0.8.0.jar;D:\Repository\com\esotericsoftware\kryo-shaded\3.0.3\kryo-shaded-3.0.3.jar;D:\Repository\com\esotericsoftware\minlog\1.3.0\minlog-1.3.0.jar;D:\Repository\org\objenesis\objenesis\2.1\objenesis-2.1.jar;D:\Repository\com\twitter\chill-java\0.8.0\chill-java-0.8.0.jar;D:\Repository\org\apache\xbean\xbean-asm5-shaded\4.4\xbean-asm5-shaded-4.4.jar;D:\Repository\org\apache\spark\spark-launcher_2.11\2.1.0\spark-launcher_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-network-common_2.11\2.1.0\spark-network-common_2.11-2.1.0.jar;D:\Repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;D:\Repository\com\fasterxml\jackson\core\jackson-annotations\2.6.5\jackson-annotations-2.6.5.jar;D:\Repository\org\apache\spark\spark-network-shuffle_2.11\2.1.0\spark-network-shuffle_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-unsafe_2.11\2.1.0\spark-unsafe_2.11-2.1.0.jar;D:\Repository\net\java\dev\jets3t\jets3t\0.7.1\jets3t-0.7.1.jar;D:\Repository\commons-codec\commons-codec\1.3\commons-codec-1.3.jar;D:\Repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;D:\Repository\org\apache\curator\curator-recipes\2.4.0\curator-recipes-2.4.0.jar;D:\Repository\org\apache\curator\curator-framework\2.4.0\curator-framework-2.4.0.jar;D:\Repository\com\google\guava\guava\14.0.1\guava-14.0.1.jar;D:\Repository\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;D:\Repository\org\apache\commons\commons-lang3\3.5\commons-lang3-3.5.jar;D:\Repository\org\apache\commons\commons-math3\3.4.1\commons-math3-3.4.1.jar;D:\Repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;D:\Repository\org\slf4j\slf4j-api\1.7.16\slf4j-api-1.7.16.jar;D:\Repository\org\slf4j\jul-to-slf4j\1.7.16\jul-to-slf4j-1.7.16.jar;D:\Repository\org\slf4j\jcl-over-slf4j\1.7.16\jcl-over-slf4j-1.7.16.jar;D:\Repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;D:\Repository\org\slf4j\slf4j-log4j12\1.7.16\slf4j-log4j12-1.7.16.jar;D:\Repository\com\ning\compress-lzf\1.0.3\compress-lzf-1.0.3.jar;D:\Repository\org\xerial\snappy\snappy-java\1.1.2.6\snappy-java-1.1.2.6.jar;D:\Repository\net\jpountz\lz4\lz4\1.3.0\lz4-1.3.0.jar;D:\Repository\org\roaringbitmap\RoaringBitmap\0.5.11\RoaringBitmap-0.5.11.jar;D:\Repository\commons-net\commons-net\2.2\commons-net-2.2.jar;D:\Repository\org\json4s\json4s-jackson_2.11\3.2.11\json4s-jackson_2.11-3.2.11.jar;D:\Repository\org\json4s\json4s-core_2.11\3.2.11\json4s-core_2.11-3.2.11.jar;D:\Repository\org\json4s\json4s-ast_2.11\3.2.11\json4s-ast_2.11-3.2.11.jar;D:\Repository\com\thoughtworks\paranamer\paranamer\2.6\paranamer-2.6.jar;D:\Repository\org\scala-lang\scalap\2.11.0\scalap-2.11.0.jar;D:\Repository\org\scala-lang\scala-compiler\2.11.0\scala-compiler-2.11.0.jar;D:\Repository\org\glassfish\jersey\core\jersey-client\2.22.2\jersey-client-2.22.2.jar;D:\Repository\javax\ws\rs\javax.ws.rs-api\2.0.1\javax.ws.rs-api-2.0.1.jar;D:\Repository\org\glassfish\hk2\hk2-api\2.4.0-b34\hk2-api-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\hk2-utils\2.4.0-b34\hk2-utils-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\external\aopalliance-repackaged\2.4.0-b34\aopalliance-repackaged-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\external\javax.inject\2.4.0-b34\javax.inject-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\hk2-locator\2.4.0-b34\hk2-locator-2.4.0-b34.jar;D:\Repository\org\javassist\javassist\3.18.1-GA\javassist-3.18.1-GA.jar;D:\Repository\org\glassfish\jersey\core\jersey-common\2.22.2\jersey-common-2.22.2.jar;D:\Repository\javax\annotation\javax.annotation-api\1.2\javax.annotation-api-1.2.jar;D:\Repository\org\glassfish\jersey\bundles\repackaged\jersey-guava\2.22.2\jersey-guava-2.22.2.jar;D:\Repository\org\glassfish\hk2\osgi-resource-locator\1.0.1\osgi-resource-locator-1.0.1.jar;D:\Repository\org\glassfish\jersey\core\jersey-server\2.22.2\jersey-server-2.22.2.jar;D:\Repository\org\glassfish\jersey\media\jersey-media-jaxb\2.22.2\jersey-media-jaxb-2.22.2.jar;D:\Repository\javax\validation\validation-api\1.1.0.Final\validation-api-1.1.0.Final.jar;D:\Repository\org\glassfish\jersey\containers\jersey-container-servlet\2.22.2\jersey-container-servlet-2.22.2.jar;D:\Repository\org\glassfish\jersey\containers\jersey-container-servlet-core\2.22.2\jersey-container-servlet-core-2.22.2.jar;D:\Repository\io\netty\netty-all\4.0.42.Final\netty-all-4.0.42.Final.jar;D:\Repository\io\netty\netty\3.8.0.Final\netty-3.8.0.Final.jar;D:\Repository\com\clearspring\analytics\stream\2.7.0\stream-2.7.0.jar;D:\Repository\io\dropwizard\metrics\metrics-core\3.1.2\metrics-core-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-jvm\3.1.2\metrics-jvm-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-json\3.1.2\metrics-json-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-graphite\3.1.2\metrics-graphite-3.1.2.jar;D:\Repository\com\fasterxml\jackson\core\jackson-databind\2.6.5\jackson-databind-2.6.5.jar;D:\Repository\com\fasterxml\jackson\core\jackson-core\2.6.5\jackson-core-2.6.5.jar;D:\Repository\com\fasterxml\jackson\module\jackson-module-scala_2.11\2.6.5\jackson-module-scala_2.11-2.6.5.jar;D:\Repository\org\scala-lang\scala-reflect\2.11.7\scala-reflect-2.11.7.jar;D:\Repository\com\fasterxml\jackson\module\jackson-module-paranamer\2.6.5\jackson-module-paranamer-2.6.5.jar;D:\Repository\org\apache\ivy\ivy\2.4.0\ivy-2.4.0.jar;D:\Repository\oro\oro\2.0.8\oro-2.0.8.jar;D:\Repository\net\razorvine\pyrolite\4.13\pyrolite-4.13.jar;D:\Repository\net\sf\py4j\py4j\0.10.4\py4j-0.10.4.jar;D:\Repository\org\apache\spark\spark-tags_2.11\2.1.0\spark-tags_2.11-2.1.0.jar;D:\Repository\org\scalatest\scalatest_2.11\2.2.6\scalatest_2.11-2.2.6.jar;D:\Repository\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;D:\Repository\org\spark-project\spark\unused\1.0.0\unused-1.0.0.jar;D:\Repository\org\apache\spark\spark-streaming_2.11\2.1.0\spark-streaming_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-sql_2.11\2.1.0\spark-sql_2.11-2.1.0.jar;D:\Repository\com\univocity\univocity-parsers\2.2.1\univocity-parsers-2.2.1.jar;D:\Repository\org\apache\spark\spark-sketch_2.11\2.1.0\spark-sketch_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-catalyst_2.11\2.1.0\spark-catalyst_2.11-2.1.0.jar;D:\Repository\org\codehaus\janino\janino\3.0.0\janino-3.0.0.jar;D:\Repository\org\codehaus\janino\commons-compiler\3.0.0\commons-compiler-3.0.0.jar;D:\Repository\org\antlr\antlr4-runtime\4.5.3\antlr4-runtime-4.5.3.jar;D:\Repository\org\apache\parquet\parquet-column\1.8.1\parquet-column-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-common\1.8.1\parquet-common-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-encoding\1.8.1\parquet-encoding-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-hadoop\1.8.1\parquet-hadoop-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-format\2.3.0-incubating\parquet-format-2.3.0-incubating.jar;D:\Repository\org\apache\parquet\parquet-jackson\1.8.1\parquet-jackson-1.8.1.jar;D:\Repository\org\apache\hadoop\hadoop-client\2.6.5\hadoop-client-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-common\2.6.5\hadoop-common-2.6.5.jar;D:\Repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;D:\Repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;D:\Repository\commons-io\commons-io\2.4\commons-io-2.4.jar;D:\Repository\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;D:\Repository\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;D:\Repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\Repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;D:\Repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;D:\Repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;D:\Repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;D:\Repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;D:\Repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;D:\Repository\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;D:\Repository\org\apache\hadoop\hadoop-auth\2.6.5\hadoop-auth-2.6.5.jar;D:\Repository\org\apache\httpcomponents\httpclient\4.2.5\httpclient-4.2.5.jar;D:\Repository\org\apache\httpcomponents\httpcore\4.2.4\httpcore-4.2.4.jar;D:\Repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;D:\Repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;D:\Repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;D:\Repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;D:\Repository\org\apache\curator\curator-client\2.6.0\curator-client-2.6.0.jar;D:\Repository\org\htrace\htrace-core\3.0.4\htrace-core-3.0.4.jar;D:\Repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;D:\Repository\org\tukaani\xz\1.0\xz-1.0.jar;D:\Repository\org\apache\hadoop\hadoop-hdfs\2.6.5\hadoop-hdfs-2.6.5.jar;D:\Repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;D:\Repository\xerces\xercesImpl\2.9.1\xercesImpl-2.9.1.jar;D:\Repository\xml-apis\xml-apis\1.3.04\xml-apis-1.3.04.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.6.5\hadoop-mapreduce-client-app-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.6.5\hadoop-mapreduce-client-common-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-client\2.6.5\hadoop-yarn-client-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-server-common\2.6.5\hadoop-yarn-server-common-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.6.5\hadoop-mapreduce-client-shuffle-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-api\2.6.5\hadoop-yarn-api-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.6.5\hadoop-mapreduce-client-core-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-common\2.6.5\hadoop-yarn-common-2.6.5.jar;D:\Repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;D:\Repository\javax\xml\stream\stax-api\1.0-2\stax-api-1.0-2.jar;D:\Repository\javax\activation\activation\1.1\activation-1.1.jar;D:\Repository\javax\servlet\servlet-api\2.5\servlet-api-2.5.jar;D:\Repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;D:\Repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;D:\Repository\org\codehaus\jackson\jackson-jaxrs\1.9.13\jackson-jaxrs-1.9.13.jar;D:\Repository\org\codehaus\jackson\jackson-xc\1.9.13\jackson-xc-1.9.13.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.6.5\hadoop-mapreduce-client-jobclient-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-annotations\2.6.5\hadoop-annotations-2.6.5.jar;D:\Repository\org\apache\kafka\kafka-clients\0.8.2.2\kafka-clients-0.8.2.2.jar;D:\Repository\org\apache\kafka\kafka_2.11\0.8.2.2\kafka_2.11-0.8.2.2.jar;D:\Repository\org\scala-lang\modules\scala-xml_2.11\1.0.2\scala-xml_2.11-1.0.2.jar;D:\Repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;D:\Repository\net\sf\jopt-simple\jopt-simple\3.2\jopt-simple-3.2.jar;D:\Repository\org\scala-lang\modules\scala-parser-combinators_2.11\1.0.2\scala-parser-combinators_2.11-1.0.2.jar;D:\Repository\com\101tec\zkclient\0.3\zkclient-0.3.jar;D:\Repository\mysql\mysql-connector-java\5.1.38\mysql-connector-java-5.1.38.jar;D:\Repository\org\apache\spark\spark-streaming-kafka-0-8_2.11\2.1.0\spark-streaming-kafka-0-8_2.11-2.1.0.jar;D:\Repository\org\apache\zookeeper\zookeeper\3.4.10\zookeeper-3.4.10.jar;D:\Repository\jline\jline\0.9.94\jline-0.9.94.jar;D:\developTools\IntelliJ IDEA 2018.2.3\lib\idea_rt.jar
2018-12-26 15:20:54 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_171\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;D:\developTools\Git\cmd;D:\developTools\svn\bin;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\scala\bin;C:\Users\junmei02\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk1.8.0_171\bin;D:\developTools\apache-maven-3.5.2\bin;D:\developTools\mysql-5.6.27-winx64\bin;D:\developTools\Git\cmd;D:\hadoop\hadoop-common-2.2.0-bin-master\bin;D:\hadoop\hbase-1.2.6\bin;C:\Program Files (x86)\scala\bin;D:\bigdata\zookeeper-3.4.10\bin;;.
2018-12-26 15:20:54 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.io.tmpdir=C:\Users\junmei02\AppData\Local\Temp\
2018-12-26 15:20:54 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.compiler=<NA>
2018-12-26 15:20:54 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.name=Windows 10
2018-12-26 15:20:54 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.arch=amd64
2018-12-26 15:20:54 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.version=10.0
2018-12-26 15:20:54 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.name=junmei02
2018-12-26 15:20:54 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.home=C:\Users\junmei02
2018-12-26 15:20:54 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.dir=D:\springbootworkspace\spark
2018-12-26 15:20:54 [ INFO ] - [ org.apache.zookeeper.ZooKeeper.<init>(ZooKeeper.java:438) ] Initiating client connection, connectString=127.0.0.1:2181 sessionTimeout=10000 watcher=org.apache.curator.ConnectionState@1ca3b418
2018-12-26 15:20:54 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:1032) ] Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2018-12-26 15:20:54 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$SendThread.primeConnection(ClientCnxn.java:876) ] Socket connection established to 127.0.0.1/127.0.0.1:2181, initiating session
2018-12-26 15:20:54 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$SendThread.onConnected(ClientCnxn.java:1299) ] Session establishment complete on server 127.0.0.1/127.0.0.1:2181, sessionid = 0x167e951e94d0002, negotiated timeout = 10000
2018-12-26 15:20:54 [ INFO ] - [ org.apache.curator.framework.state.ConnectionStateManager.postState(ConnectionStateManager.java:194) ] State change: CONNECTED
2018-12-26 15:20:54 [ WARN ] - [ org.apache.curator.framework.state.ConnectionStateManager.processEvents(ConnectionStateManager.java:212) ] There are no ConnectionStateListeners registered.
2018-12-26 15:20:55 [ INFO ] - [ org.apache.zookeeper.ZooKeeper.close(ZooKeeper.java:684) ] Session: 0x167e951e94d0002 closed
2018-12-26 15:20:55 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:519) ] EventThread shut down for session: 0x167e951e94d0002
2018-12-26 15:20:56 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Running Spark version 2.1.0
2018-12-26 15:20:57 [ ERROR ] - [ org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:396) ] Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2373)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2373)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2373)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:837)
	at org.apache.spark.streaming.StreamingContext.<init>(StreamingContext.scala:84)
	at org.apache.spark.streaming.api.java.JavaStreamingContext.<init>(JavaStreamingContext.scala:138)
	at com.zqg.StreamKafka.SparkStreamingDirect.getStreamingContext(SparkStreamingDirect.java:38)
	at com.zqg.StreamKafka.KafkaSparkStreamingWithZookeeperoffset.main(KafkaSparkStreamingWithZookeeperoffset.java:62)
2018-12-26 15:20:57 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing view acls to: junmei02
2018-12-26 15:20:57 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing modify acls to: junmei02
2018-12-26 15:20:57 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing view acls groups to: 
2018-12-26 15:20:57 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing modify acls groups to: 
2018-12-26 15:20:57 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(junmei02); groups with view permissions: Set(); users  with modify permissions: Set(junmei02); groups with modify permissions: Set()
2018-12-26 15:20:57 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'sparkDriver' on port 53286.
2018-12-26 15:20:57 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering MapOutputTracker
2018-12-26 15:20:57 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering BlockManagerMaster
2018-12-26 15:20:57 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-26 15:20:57 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] BlockManagerMasterEndpoint up
2018-12-26 15:20:57 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Created local directory at C:\Users\junmei02\AppData\Local\Temp\blockmgr-5555eec4-1c45-4bf5-8dbe-1adf055e051f
2018-12-26 15:20:57 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] MemoryStore started with capacity 900.6 MB
2018-12-26 15:20:57 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering OutputCommitCoordinator
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.util.log.Log.initialized(Log.java:186) ] Logging initialized @4457ms
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.Server.doStart(Server.java:327) ] jetty-9.2.z-SNAPSHOT
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@7f9e1534{/jobs,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@138a7441{/jobs/json,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@81ff872{/jobs/job,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@31611954{/jobs/job/json,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@3e598df9{/stages,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@7e31ce0f{/stages/json,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@99a65d3{/stages/stage,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@3088660d{/stages/stage/json,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@42cc13a0{/stages/pool,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@32fdec40{/stages/pool/json,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@6813a331{/storage,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@1bd81830{/storage/json,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@39ab59f8{/storage/rdd,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@64e92d61{/storage/rdd/json,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@111610e6{/environment,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@4ad4936c{/environment/json,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@29d37757{/executors,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@4fcc529{/executors/json,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@25cc7470{/executors/threadDump,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@4beddc56{/executors/threadDump/json,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@79b663b3{/static,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@1b812421{/,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@5d28bcd5{/api,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@7882c44a{/jobs/job/kill,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@32639b12{/stages/stage/kill,null,AVAILABLE}
2018-12-26 15:20:57 [ WARN ] - [ org.spark_project.jetty.util.component.AbstractLifeCycle.setFailed(AbstractLifeCycle.java:212) ] FAILED ServerConnector@6622a690{HTTP/1.1}{0.0.0.0:4040}: java.net.BindException: Address already in use: bind
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:349)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:359)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:359)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2195)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2186)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:359)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:140)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:460)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:460)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:460)
	at org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:837)
	at org.apache.spark.streaming.StreamingContext.<init>(StreamingContext.scala:84)
	at org.apache.spark.streaming.api.java.JavaStreamingContext.<init>(JavaStreamingContext.scala:138)
	at com.zqg.StreamKafka.SparkStreamingDirect.getStreamingContext(SparkStreamingDirect.java:38)
	at com.zqg.StreamKafka.KafkaSparkStreamingWithZookeeperoffset.main(KafkaSparkStreamingWithZookeeperoffset.java:62)
2018-12-26 15:20:57 [ WARN ] - [ org.spark_project.jetty.util.component.AbstractLifeCycle.setFailed(AbstractLifeCycle.java:212) ] FAILED org.spark_project.jetty.server.Server@497570fb: java.net.BindException: Address already in use: bind
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:349)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:359)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:359)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2195)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2186)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:359)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:140)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:460)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:460)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:460)
	at org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:837)
	at org.apache.spark.streaming.StreamingContext.<init>(StreamingContext.scala:84)
	at org.apache.spark.streaming.api.java.JavaStreamingContext.<init>(JavaStreamingContext.scala:138)
	at com.zqg.StreamKafka.SparkStreamingDirect.getStreamingContext(SparkStreamingDirect.java:38)
	at com.zqg.StreamKafka.KafkaSparkStreamingWithZookeeperoffset.main(KafkaSparkStreamingWithZookeeperoffset.java:62)
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.AbstractConnector.doStop(AbstractConnector.java:306) ] Stopped ServerConnector@6622a690{HTTP/1.1}{0.0.0.0:4040}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@32639b12{/stages/stage/kill,null,UNAVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@7882c44a{/jobs/job/kill,null,UNAVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@5d28bcd5{/api,null,UNAVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@1b812421{/,null,UNAVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@79b663b3{/static,null,UNAVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@4beddc56{/executors/threadDump/json,null,UNAVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@25cc7470{/executors/threadDump,null,UNAVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@4fcc529{/executors/json,null,UNAVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@29d37757{/executors,null,UNAVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@4ad4936c{/environment/json,null,UNAVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@111610e6{/environment,null,UNAVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@64e92d61{/storage/rdd/json,null,UNAVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@39ab59f8{/storage/rdd,null,UNAVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@1bd81830{/storage/json,null,UNAVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@6813a331{/storage,null,UNAVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@32fdec40{/stages/pool/json,null,UNAVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@42cc13a0{/stages/pool,null,UNAVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@3088660d{/stages/stage/json,null,UNAVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@99a65d3{/stages/stage,null,UNAVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@7e31ce0f{/stages/json,null,UNAVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@3e598df9{/stages,null,UNAVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@31611954{/jobs/job/json,null,UNAVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@81ff872{/jobs/job,null,UNAVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@138a7441{/jobs/json,null,UNAVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@7f9e1534{/jobs,null,UNAVAILABLE}
2018-12-26 15:20:57 [ WARN ] - [ org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66) ] Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.Server.doStart(Server.java:327) ] jetty-9.2.z-SNAPSHOT
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@7f9e1534{/jobs,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@138a7441{/jobs/json,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@81ff872{/jobs/job,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@31611954{/jobs/job/json,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@3e598df9{/stages,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@7e31ce0f{/stages/json,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@99a65d3{/stages/stage,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@3088660d{/stages/stage/json,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@42cc13a0{/stages/pool,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@32fdec40{/stages/pool/json,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@6813a331{/storage,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@1bd81830{/storage/json,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@39ab59f8{/storage/rdd,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@64e92d61{/storage/rdd/json,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@111610e6{/environment,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@4ad4936c{/environment/json,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@29d37757{/executors,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@4fcc529{/executors/json,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@25cc7470{/executors/threadDump,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@4beddc56{/executors/threadDump/json,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@79b663b3{/static,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@1b812421{/,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@5d28bcd5{/api,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@7882c44a{/jobs/job/kill,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@32639b12{/stages/stage/kill,null,AVAILABLE}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:266) ] Started ServerConnector@f2c488{HTTP/1.1}{0.0.0.0:4041}
2018-12-26 15:20:57 [ INFO ] - [ org.spark_project.jetty.server.Server.doStart(Server.java:379) ] Started @4646ms
2018-12-26 15:20:57 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'SparkUI' on port 4041.
2018-12-26 15:20:57 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Bound SparkUI to 0.0.0.0, and started at http://192.168.0.112:4041
2018-12-26 15:20:58 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Starting executor ID driver on host localhost
2018-12-26 15:20:58 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53307.
2018-12-26 15:20:58 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Server created on 192.168.0.112:53307
2018-12-26 15:20:58 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-26 15:20:58 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering BlockManager BlockManagerId(driver, 192.168.0.112, 53307, None)
2018-12-26 15:20:58 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering block manager 192.168.0.112:53307 with 900.6 MB RAM, BlockManagerId(driver, 192.168.0.112, 53307, None)
2018-12-26 15:20:58 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registered BlockManager BlockManagerId(driver, 192.168.0.112, 53307, None)
2018-12-26 15:20:58 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Initialized BlockManager: BlockManagerId(driver, 192.168.0.112, 53307, None)
2018-12-26 15:20:58 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@4c9e38{/metrics/json,null,AVAILABLE}
2018-12-26 15:20:58 [ INFO ] - [ kafka.utils.Logging$class.info(Logging.scala:68) ] Verifying properties
2018-12-26 15:20:58 [ INFO ] - [ kafka.utils.Logging$class.info(Logging.scala:68) ] Property group.id is overridden to 
2018-12-26 15:20:58 [ INFO ] - [ kafka.utils.Logging$class.info(Logging.scala:68) ] Property zookeeper.connect is overridden to 
2018-12-26 15:21:17 [ ERROR ] - [ org.apache.spark.internal.Logging$class.logError(Logging.scala:70) ] ArrayBuffer(java.nio.channels.ClosedChannelException, java.nio.channels.ClosedChannelException, java.nio.channels.ClosedChannelException)
2018-12-26 15:41:45 [ INFO ] - [ org.apache.curator.framework.imps.CuratorFrameworkImpl.start(CuratorFrameworkImpl.java:223) ] Starting
2018-12-26 15:41:45 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT
2018-12-26 15:41:45 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:host.name=windows10.microdone.cn
2018-12-26 15:41:45 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.version=1.8.0_171
2018-12-26 15:41:45 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.vendor=Oracle Corporation
2018-12-26 15:41:45 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.home=C:\Program Files\Java\jdk1.8.0_171\jre
2018-12-26 15:41:45 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.class.path=C:\Program Files\Java\jdk1.8.0_171\jre\lib\charsets.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\deploy.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\access-bridge-64.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\cldrdata.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\dnsns.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\jaccess.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\jfxrt.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\localedata.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\nashorn.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunec.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunjce_provider.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunmscapi.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunpkcs11.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\zipfs.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\javaws.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jce.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jfr.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jfxswt.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jsse.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\management-agent.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\plugin.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\resources.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\rt.jar;D:\springbootworkspace\spark\target\classes;D:\Repository\org\scala-lang\scala-library\2.11.8\scala-library-2.11.8.jar;D:\Repository\org\apache\spark\spark-core_2.11\2.1.0\spark-core_2.11-2.1.0.jar;D:\Repository\org\apache\avro\avro-mapred\1.7.7\avro-mapred-1.7.7-hadoop2.jar;D:\Repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7.jar;D:\Repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7-tests.jar;D:\Repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;D:\Repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;D:\Repository\com\twitter\chill_2.11\0.8.0\chill_2.11-0.8.0.jar;D:\Repository\com\esotericsoftware\kryo-shaded\3.0.3\kryo-shaded-3.0.3.jar;D:\Repository\com\esotericsoftware\minlog\1.3.0\minlog-1.3.0.jar;D:\Repository\org\objenesis\objenesis\2.1\objenesis-2.1.jar;D:\Repository\com\twitter\chill-java\0.8.0\chill-java-0.8.0.jar;D:\Repository\org\apache\xbean\xbean-asm5-shaded\4.4\xbean-asm5-shaded-4.4.jar;D:\Repository\org\apache\spark\spark-launcher_2.11\2.1.0\spark-launcher_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-network-common_2.11\2.1.0\spark-network-common_2.11-2.1.0.jar;D:\Repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;D:\Repository\com\fasterxml\jackson\core\jackson-annotations\2.6.5\jackson-annotations-2.6.5.jar;D:\Repository\org\apache\spark\spark-network-shuffle_2.11\2.1.0\spark-network-shuffle_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-unsafe_2.11\2.1.0\spark-unsafe_2.11-2.1.0.jar;D:\Repository\net\java\dev\jets3t\jets3t\0.7.1\jets3t-0.7.1.jar;D:\Repository\commons-codec\commons-codec\1.3\commons-codec-1.3.jar;D:\Repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;D:\Repository\org\apache\curator\curator-recipes\2.4.0\curator-recipes-2.4.0.jar;D:\Repository\org\apache\curator\curator-framework\2.4.0\curator-framework-2.4.0.jar;D:\Repository\com\google\guava\guava\14.0.1\guava-14.0.1.jar;D:\Repository\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;D:\Repository\org\apache\commons\commons-lang3\3.5\commons-lang3-3.5.jar;D:\Repository\org\apache\commons\commons-math3\3.4.1\commons-math3-3.4.1.jar;D:\Repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;D:\Repository\org\slf4j\slf4j-api\1.7.16\slf4j-api-1.7.16.jar;D:\Repository\org\slf4j\jul-to-slf4j\1.7.16\jul-to-slf4j-1.7.16.jar;D:\Repository\org\slf4j\jcl-over-slf4j\1.7.16\jcl-over-slf4j-1.7.16.jar;D:\Repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;D:\Repository\org\slf4j\slf4j-log4j12\1.7.16\slf4j-log4j12-1.7.16.jar;D:\Repository\com\ning\compress-lzf\1.0.3\compress-lzf-1.0.3.jar;D:\Repository\org\xerial\snappy\snappy-java\1.1.2.6\snappy-java-1.1.2.6.jar;D:\Repository\net\jpountz\lz4\lz4\1.3.0\lz4-1.3.0.jar;D:\Repository\org\roaringbitmap\RoaringBitmap\0.5.11\RoaringBitmap-0.5.11.jar;D:\Repository\commons-net\commons-net\2.2\commons-net-2.2.jar;D:\Repository\org\json4s\json4s-jackson_2.11\3.2.11\json4s-jackson_2.11-3.2.11.jar;D:\Repository\org\json4s\json4s-core_2.11\3.2.11\json4s-core_2.11-3.2.11.jar;D:\Repository\org\json4s\json4s-ast_2.11\3.2.11\json4s-ast_2.11-3.2.11.jar;D:\Repository\com\thoughtworks\paranamer\paranamer\2.6\paranamer-2.6.jar;D:\Repository\org\scala-lang\scalap\2.11.0\scalap-2.11.0.jar;D:\Repository\org\scala-lang\scala-compiler\2.11.0\scala-compiler-2.11.0.jar;D:\Repository\org\glassfish\jersey\core\jersey-client\2.22.2\jersey-client-2.22.2.jar;D:\Repository\javax\ws\rs\javax.ws.rs-api\2.0.1\javax.ws.rs-api-2.0.1.jar;D:\Repository\org\glassfish\hk2\hk2-api\2.4.0-b34\hk2-api-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\hk2-utils\2.4.0-b34\hk2-utils-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\external\aopalliance-repackaged\2.4.0-b34\aopalliance-repackaged-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\external\javax.inject\2.4.0-b34\javax.inject-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\hk2-locator\2.4.0-b34\hk2-locator-2.4.0-b34.jar;D:\Repository\org\javassist\javassist\3.18.1-GA\javassist-3.18.1-GA.jar;D:\Repository\org\glassfish\jersey\core\jersey-common\2.22.2\jersey-common-2.22.2.jar;D:\Repository\javax\annotation\javax.annotation-api\1.2\javax.annotation-api-1.2.jar;D:\Repository\org\glassfish\jersey\bundles\repackaged\jersey-guava\2.22.2\jersey-guava-2.22.2.jar;D:\Repository\org\glassfish\hk2\osgi-resource-locator\1.0.1\osgi-resource-locator-1.0.1.jar;D:\Repository\org\glassfish\jersey\core\jersey-server\2.22.2\jersey-server-2.22.2.jar;D:\Repository\org\glassfish\jersey\media\jersey-media-jaxb\2.22.2\jersey-media-jaxb-2.22.2.jar;D:\Repository\javax\validation\validation-api\1.1.0.Final\validation-api-1.1.0.Final.jar;D:\Repository\org\glassfish\jersey\containers\jersey-container-servlet\2.22.2\jersey-container-servlet-2.22.2.jar;D:\Repository\org\glassfish\jersey\containers\jersey-container-servlet-core\2.22.2\jersey-container-servlet-core-2.22.2.jar;D:\Repository\io\netty\netty-all\4.0.42.Final\netty-all-4.0.42.Final.jar;D:\Repository\io\netty\netty\3.8.0.Final\netty-3.8.0.Final.jar;D:\Repository\com\clearspring\analytics\stream\2.7.0\stream-2.7.0.jar;D:\Repository\io\dropwizard\metrics\metrics-core\3.1.2\metrics-core-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-jvm\3.1.2\metrics-jvm-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-json\3.1.2\metrics-json-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-graphite\3.1.2\metrics-graphite-3.1.2.jar;D:\Repository\com\fasterxml\jackson\core\jackson-databind\2.6.5\jackson-databind-2.6.5.jar;D:\Repository\com\fasterxml\jackson\core\jackson-core\2.6.5\jackson-core-2.6.5.jar;D:\Repository\com\fasterxml\jackson\module\jackson-module-scala_2.11\2.6.5\jackson-module-scala_2.11-2.6.5.jar;D:\Repository\org\scala-lang\scala-reflect\2.11.7\scala-reflect-2.11.7.jar;D:\Repository\com\fasterxml\jackson\module\jackson-module-paranamer\2.6.5\jackson-module-paranamer-2.6.5.jar;D:\Repository\org\apache\ivy\ivy\2.4.0\ivy-2.4.0.jar;D:\Repository\oro\oro\2.0.8\oro-2.0.8.jar;D:\Repository\net\razorvine\pyrolite\4.13\pyrolite-4.13.jar;D:\Repository\net\sf\py4j\py4j\0.10.4\py4j-0.10.4.jar;D:\Repository\org\apache\spark\spark-tags_2.11\2.1.0\spark-tags_2.11-2.1.0.jar;D:\Repository\org\scalatest\scalatest_2.11\2.2.6\scalatest_2.11-2.2.6.jar;D:\Repository\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;D:\Repository\org\spark-project\spark\unused\1.0.0\unused-1.0.0.jar;D:\Repository\org\apache\spark\spark-streaming_2.11\2.1.0\spark-streaming_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-sql_2.11\2.1.0\spark-sql_2.11-2.1.0.jar;D:\Repository\com\univocity\univocity-parsers\2.2.1\univocity-parsers-2.2.1.jar;D:\Repository\org\apache\spark\spark-sketch_2.11\2.1.0\spark-sketch_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-catalyst_2.11\2.1.0\spark-catalyst_2.11-2.1.0.jar;D:\Repository\org\codehaus\janino\janino\3.0.0\janino-3.0.0.jar;D:\Repository\org\codehaus\janino\commons-compiler\3.0.0\commons-compiler-3.0.0.jar;D:\Repository\org\antlr\antlr4-runtime\4.5.3\antlr4-runtime-4.5.3.jar;D:\Repository\org\apache\parquet\parquet-column\1.8.1\parquet-column-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-common\1.8.1\parquet-common-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-encoding\1.8.1\parquet-encoding-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-hadoop\1.8.1\parquet-hadoop-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-format\2.3.0-incubating\parquet-format-2.3.0-incubating.jar;D:\Repository\org\apache\parquet\parquet-jackson\1.8.1\parquet-jackson-1.8.1.jar;D:\Repository\org\apache\hadoop\hadoop-client\2.6.5\hadoop-client-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-common\2.6.5\hadoop-common-2.6.5.jar;D:\Repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;D:\Repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;D:\Repository\commons-io\commons-io\2.4\commons-io-2.4.jar;D:\Repository\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;D:\Repository\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;D:\Repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\Repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;D:\Repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;D:\Repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;D:\Repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;D:\Repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;D:\Repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;D:\Repository\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;D:\Repository\org\apache\hadoop\hadoop-auth\2.6.5\hadoop-auth-2.6.5.jar;D:\Repository\org\apache\httpcomponents\httpclient\4.2.5\httpclient-4.2.5.jar;D:\Repository\org\apache\httpcomponents\httpcore\4.2.4\httpcore-4.2.4.jar;D:\Repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;D:\Repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;D:\Repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;D:\Repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;D:\Repository\org\apache\curator\curator-client\2.6.0\curator-client-2.6.0.jar;D:\Repository\org\htrace\htrace-core\3.0.4\htrace-core-3.0.4.jar;D:\Repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;D:\Repository\org\tukaani\xz\1.0\xz-1.0.jar;D:\Repository\org\apache\hadoop\hadoop-hdfs\2.6.5\hadoop-hdfs-2.6.5.jar;D:\Repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;D:\Repository\xerces\xercesImpl\2.9.1\xercesImpl-2.9.1.jar;D:\Repository\xml-apis\xml-apis\1.3.04\xml-apis-1.3.04.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.6.5\hadoop-mapreduce-client-app-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.6.5\hadoop-mapreduce-client-common-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-client\2.6.5\hadoop-yarn-client-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-server-common\2.6.5\hadoop-yarn-server-common-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.6.5\hadoop-mapreduce-client-shuffle-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-api\2.6.5\hadoop-yarn-api-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.6.5\hadoop-mapreduce-client-core-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-common\2.6.5\hadoop-yarn-common-2.6.5.jar;D:\Repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;D:\Repository\javax\xml\stream\stax-api\1.0-2\stax-api-1.0-2.jar;D:\Repository\javax\activation\activation\1.1\activation-1.1.jar;D:\Repository\javax\servlet\servlet-api\2.5\servlet-api-2.5.jar;D:\Repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;D:\Repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;D:\Repository\org\codehaus\jackson\jackson-jaxrs\1.9.13\jackson-jaxrs-1.9.13.jar;D:\Repository\org\codehaus\jackson\jackson-xc\1.9.13\jackson-xc-1.9.13.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.6.5\hadoop-mapreduce-client-jobclient-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-annotations\2.6.5\hadoop-annotations-2.6.5.jar;D:\Repository\org\apache\kafka\kafka-clients\0.8.2.2\kafka-clients-0.8.2.2.jar;D:\Repository\org\apache\kafka\kafka_2.11\0.8.2.2\kafka_2.11-0.8.2.2.jar;D:\Repository\org\scala-lang\modules\scala-xml_2.11\1.0.2\scala-xml_2.11-1.0.2.jar;D:\Repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;D:\Repository\net\sf\jopt-simple\jopt-simple\3.2\jopt-simple-3.2.jar;D:\Repository\org\scala-lang\modules\scala-parser-combinators_2.11\1.0.2\scala-parser-combinators_2.11-1.0.2.jar;D:\Repository\com\101tec\zkclient\0.3\zkclient-0.3.jar;D:\Repository\mysql\mysql-connector-java\5.1.38\mysql-connector-java-5.1.38.jar;D:\Repository\org\apache\spark\spark-streaming-kafka-0-8_2.11\2.1.0\spark-streaming-kafka-0-8_2.11-2.1.0.jar;D:\Repository\org\apache\zookeeper\zookeeper\3.4.10\zookeeper-3.4.10.jar;D:\Repository\jline\jline\0.9.94\jline-0.9.94.jar;D:\developTools\IntelliJ IDEA 2018.2.3\lib\idea_rt.jar
2018-12-26 15:41:45 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_171\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;D:\developTools\Git\cmd;D:\developTools\svn\bin;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\scala\bin;C:\Users\junmei02\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk1.8.0_171\bin;D:\developTools\apache-maven-3.5.2\bin;D:\developTools\mysql-5.6.27-winx64\bin;D:\developTools\Git\cmd;D:\hadoop\hadoop-common-2.2.0-bin-master\bin;D:\hadoop\hbase-1.2.6\bin;C:\Program Files (x86)\scala\bin;D:\bigdata\zookeeper-3.4.10\bin;;.
2018-12-26 15:41:45 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.io.tmpdir=C:\Users\junmei02\AppData\Local\Temp\
2018-12-26 15:41:45 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.compiler=<NA>
2018-12-26 15:41:45 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.name=Windows 10
2018-12-26 15:41:45 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.arch=amd64
2018-12-26 15:41:45 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.version=10.0
2018-12-26 15:41:45 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.name=junmei02
2018-12-26 15:41:45 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.home=C:\Users\junmei02
2018-12-26 15:41:45 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.dir=D:\springbootworkspace\spark
2018-12-26 15:41:45 [ INFO ] - [ org.apache.zookeeper.ZooKeeper.<init>(ZooKeeper.java:438) ] Initiating client connection, connectString=127.0.0.1:2181 sessionTimeout=10000 watcher=org.apache.curator.ConnectionState@7ef82753
2018-12-26 15:41:45 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:1032) ] Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2018-12-26 15:41:45 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$SendThread.primeConnection(ClientCnxn.java:876) ] Socket connection established to 127.0.0.1/127.0.0.1:2181, initiating session
2018-12-26 15:41:45 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$SendThread.onConnected(ClientCnxn.java:1299) ] Session establishment complete on server 127.0.0.1/127.0.0.1:2181, sessionid = 0x167e951e94d0003, negotiated timeout = 10000
2018-12-26 15:41:46 [ INFO ] - [ org.apache.curator.framework.state.ConnectionStateManager.postState(ConnectionStateManager.java:194) ] State change: CONNECTED
2018-12-26 15:41:46 [ WARN ] - [ org.apache.curator.framework.state.ConnectionStateManager.processEvents(ConnectionStateManager.java:212) ] There are no ConnectionStateListeners registered.
2018-12-26 15:41:47 [ INFO ] - [ org.apache.zookeeper.ZooKeeper.close(ZooKeeper.java:684) ] Session: 0x167e951e94d0003 closed
2018-12-26 15:41:47 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:519) ] EventThread shut down for session: 0x167e951e94d0003
2018-12-26 15:41:48 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Running Spark version 2.1.0
2018-12-26 15:41:48 [ ERROR ] - [ org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:396) ] Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2373)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2373)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2373)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:837)
	at org.apache.spark.streaming.StreamingContext.<init>(StreamingContext.scala:84)
	at org.apache.spark.streaming.api.java.JavaStreamingContext.<init>(JavaStreamingContext.scala:138)
	at com.zqg.StreamKafka.KafkaSparkStreamingWithZookeeperoffset.main(KafkaSparkStreamingWithZookeeperoffset.java:70)
2018-12-26 15:41:48 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing view acls to: junmei02
2018-12-26 15:41:48 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing modify acls to: junmei02
2018-12-26 15:41:48 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing view acls groups to: 
2018-12-26 15:41:48 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing modify acls groups to: 
2018-12-26 15:41:48 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(junmei02); groups with view permissions: Set(); users  with modify permissions: Set(junmei02); groups with modify permissions: Set()
2018-12-26 15:41:48 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'sparkDriver' on port 53541.
2018-12-26 15:41:48 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering MapOutputTracker
2018-12-26 15:41:48 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering BlockManagerMaster
2018-12-26 15:41:48 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-26 15:41:48 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] BlockManagerMasterEndpoint up
2018-12-26 15:41:48 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Created local directory at C:\Users\junmei02\AppData\Local\Temp\blockmgr-0e92450e-35c6-4ec7-ada9-4a83913d17f5
2018-12-26 15:41:48 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] MemoryStore started with capacity 900.6 MB
2018-12-26 15:41:48 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering OutputCommitCoordinator
2018-12-26 15:41:49 [ INFO ] - [ org.spark_project.jetty.util.log.Log.initialized(Log.java:186) ] Logging initialized @4504ms
2018-12-26 15:41:49 [ INFO ] - [ org.spark_project.jetty.server.Server.doStart(Server.java:327) ] jetty-9.2.z-SNAPSHOT
2018-12-26 15:41:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@66d57c1b{/jobs,null,AVAILABLE}
2018-12-26 15:41:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@27494e46{/jobs/json,null,AVAILABLE}
2018-12-26 15:41:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@d59970a{/jobs/job,null,AVAILABLE}
2018-12-26 15:41:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@1e411d81{/jobs/job/json,null,AVAILABLE}
2018-12-26 15:41:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@53b98ff6{/stages,null,AVAILABLE}
2018-12-26 15:41:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@3e6fd0b9{/stages/json,null,AVAILABLE}
2018-12-26 15:41:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@7fcff1b9{/stages/stage,null,AVAILABLE}
2018-12-26 15:41:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@697446d4{/stages/stage/json,null,AVAILABLE}
2018-12-26 15:41:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@76adb233{/stages/pool,null,AVAILABLE}
2018-12-26 15:41:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@36074e47{/stages/pool/json,null,AVAILABLE}
2018-12-26 15:41:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@36453307{/storage,null,AVAILABLE}
2018-12-26 15:41:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@7dcc91fd{/storage/json,null,AVAILABLE}
2018-12-26 15:41:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@66eb985d{/storage/rdd,null,AVAILABLE}
2018-12-26 15:41:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@6a9287b1{/storage/rdd/json,null,AVAILABLE}
2018-12-26 15:41:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@75504cef{/environment,null,AVAILABLE}
2018-12-26 15:41:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@6c8a68c1{/environment/json,null,AVAILABLE}
2018-12-26 15:41:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@56193c7d{/executors,null,AVAILABLE}
2018-12-26 15:41:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@28c88600{/executors/json,null,AVAILABLE}
2018-12-26 15:41:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@5f8890c2{/executors/threadDump,null,AVAILABLE}
2018-12-26 15:41:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@607b2792{/executors/threadDump/json,null,AVAILABLE}
2018-12-26 15:41:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@7f9e1534{/static,null,AVAILABLE}
2018-12-26 15:41:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@138a7441{/,null,AVAILABLE}
2018-12-26 15:41:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@81ff872{/api,null,AVAILABLE}
2018-12-26 15:41:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@31611954{/jobs/job/kill,null,AVAILABLE}
2018-12-26 15:41:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@3e598df9{/stages/stage/kill,null,AVAILABLE}
2018-12-26 15:41:49 [ INFO ] - [ org.spark_project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:266) ] Started ServerConnector@4a60ee36{HTTP/1.1}{0.0.0.0:4040}
2018-12-26 15:41:49 [ INFO ] - [ org.spark_project.jetty.server.Server.doStart(Server.java:379) ] Started @4640ms
2018-12-26 15:41:49 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'SparkUI' on port 4040.
2018-12-26 15:41:49 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Bound SparkUI to 0.0.0.0, and started at http://192.168.0.112:4040
2018-12-26 15:41:49 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Starting executor ID driver on host localhost
2018-12-26 15:41:49 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53562.
2018-12-26 15:41:49 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Server created on 192.168.0.112:53562
2018-12-26 15:41:49 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-26 15:41:49 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering BlockManager BlockManagerId(driver, 192.168.0.112, 53562, None)
2018-12-26 15:41:49 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering block manager 192.168.0.112:53562 with 900.6 MB RAM, BlockManagerId(driver, 192.168.0.112, 53562, None)
2018-12-26 15:41:49 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registered BlockManager BlockManagerId(driver, 192.168.0.112, 53562, None)
2018-12-26 15:41:49 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Initialized BlockManager: BlockManagerId(driver, 192.168.0.112, 53562, None)
2018-12-26 15:41:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@2d6aca33{/metrics/json,null,AVAILABLE}
2018-12-26 15:41:49 [ ERROR ] - [ org.apache.spark.internal.Logging$class.logError(Logging.scala:91) ] Error starting the context, marking it as stopped
java.lang.IllegalArgumentException: requirement failed: No output operations registered, so nothing to execute
	at scala.Predef$.require(Predef.scala:224)
	at org.apache.spark.streaming.DStreamGraph.validate(DStreamGraph.scala:163)
	at org.apache.spark.streaming.StreamingContext.validate(StreamingContext.scala:513)
	at org.apache.spark.streaming.StreamingContext.liftedTree1$1(StreamingContext.scala:573)
	at org.apache.spark.streaming.StreamingContext.start(StreamingContext.scala:572)
	at org.apache.spark.streaming.api.java.JavaStreamingContext.start(JavaStreamingContext.scala:556)
	at com.zqg.StreamKafka.KafkaSparkStreamingWithZookeeperoffset.main(KafkaSparkStreamingWithZookeeperoffset.java:140)
2018-12-26 15:42:12 [ INFO ] - [ org.apache.curator.framework.imps.CuratorFrameworkImpl.start(CuratorFrameworkImpl.java:223) ] Starting
2018-12-26 15:42:12 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT
2018-12-26 15:42:12 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:host.name=windows10.microdone.cn
2018-12-26 15:42:12 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.version=1.8.0_171
2018-12-26 15:42:12 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.vendor=Oracle Corporation
2018-12-26 15:42:12 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.home=C:\Program Files\Java\jdk1.8.0_171\jre
2018-12-26 15:42:12 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.class.path=C:\Program Files\Java\jdk1.8.0_171\jre\lib\charsets.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\deploy.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\access-bridge-64.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\cldrdata.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\dnsns.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\jaccess.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\jfxrt.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\localedata.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\nashorn.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunec.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunjce_provider.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunmscapi.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunpkcs11.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\zipfs.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\javaws.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jce.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jfr.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jfxswt.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jsse.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\management-agent.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\plugin.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\resources.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\rt.jar;D:\springbootworkspace\spark\target\classes;D:\Repository\org\scala-lang\scala-library\2.11.8\scala-library-2.11.8.jar;D:\Repository\org\apache\spark\spark-core_2.11\2.1.0\spark-core_2.11-2.1.0.jar;D:\Repository\org\apache\avro\avro-mapred\1.7.7\avro-mapred-1.7.7-hadoop2.jar;D:\Repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7.jar;D:\Repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7-tests.jar;D:\Repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;D:\Repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;D:\Repository\com\twitter\chill_2.11\0.8.0\chill_2.11-0.8.0.jar;D:\Repository\com\esotericsoftware\kryo-shaded\3.0.3\kryo-shaded-3.0.3.jar;D:\Repository\com\esotericsoftware\minlog\1.3.0\minlog-1.3.0.jar;D:\Repository\org\objenesis\objenesis\2.1\objenesis-2.1.jar;D:\Repository\com\twitter\chill-java\0.8.0\chill-java-0.8.0.jar;D:\Repository\org\apache\xbean\xbean-asm5-shaded\4.4\xbean-asm5-shaded-4.4.jar;D:\Repository\org\apache\spark\spark-launcher_2.11\2.1.0\spark-launcher_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-network-common_2.11\2.1.0\spark-network-common_2.11-2.1.0.jar;D:\Repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;D:\Repository\com\fasterxml\jackson\core\jackson-annotations\2.6.5\jackson-annotations-2.6.5.jar;D:\Repository\org\apache\spark\spark-network-shuffle_2.11\2.1.0\spark-network-shuffle_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-unsafe_2.11\2.1.0\spark-unsafe_2.11-2.1.0.jar;D:\Repository\net\java\dev\jets3t\jets3t\0.7.1\jets3t-0.7.1.jar;D:\Repository\commons-codec\commons-codec\1.3\commons-codec-1.3.jar;D:\Repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;D:\Repository\org\apache\curator\curator-recipes\2.4.0\curator-recipes-2.4.0.jar;D:\Repository\org\apache\curator\curator-framework\2.4.0\curator-framework-2.4.0.jar;D:\Repository\com\google\guava\guava\14.0.1\guava-14.0.1.jar;D:\Repository\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;D:\Repository\org\apache\commons\commons-lang3\3.5\commons-lang3-3.5.jar;D:\Repository\org\apache\commons\commons-math3\3.4.1\commons-math3-3.4.1.jar;D:\Repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;D:\Repository\org\slf4j\slf4j-api\1.7.16\slf4j-api-1.7.16.jar;D:\Repository\org\slf4j\jul-to-slf4j\1.7.16\jul-to-slf4j-1.7.16.jar;D:\Repository\org\slf4j\jcl-over-slf4j\1.7.16\jcl-over-slf4j-1.7.16.jar;D:\Repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;D:\Repository\org\slf4j\slf4j-log4j12\1.7.16\slf4j-log4j12-1.7.16.jar;D:\Repository\com\ning\compress-lzf\1.0.3\compress-lzf-1.0.3.jar;D:\Repository\org\xerial\snappy\snappy-java\1.1.2.6\snappy-java-1.1.2.6.jar;D:\Repository\net\jpountz\lz4\lz4\1.3.0\lz4-1.3.0.jar;D:\Repository\org\roaringbitmap\RoaringBitmap\0.5.11\RoaringBitmap-0.5.11.jar;D:\Repository\commons-net\commons-net\2.2\commons-net-2.2.jar;D:\Repository\org\json4s\json4s-jackson_2.11\3.2.11\json4s-jackson_2.11-3.2.11.jar;D:\Repository\org\json4s\json4s-core_2.11\3.2.11\json4s-core_2.11-3.2.11.jar;D:\Repository\org\json4s\json4s-ast_2.11\3.2.11\json4s-ast_2.11-3.2.11.jar;D:\Repository\com\thoughtworks\paranamer\paranamer\2.6\paranamer-2.6.jar;D:\Repository\org\scala-lang\scalap\2.11.0\scalap-2.11.0.jar;D:\Repository\org\scala-lang\scala-compiler\2.11.0\scala-compiler-2.11.0.jar;D:\Repository\org\glassfish\jersey\core\jersey-client\2.22.2\jersey-client-2.22.2.jar;D:\Repository\javax\ws\rs\javax.ws.rs-api\2.0.1\javax.ws.rs-api-2.0.1.jar;D:\Repository\org\glassfish\hk2\hk2-api\2.4.0-b34\hk2-api-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\hk2-utils\2.4.0-b34\hk2-utils-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\external\aopalliance-repackaged\2.4.0-b34\aopalliance-repackaged-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\external\javax.inject\2.4.0-b34\javax.inject-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\hk2-locator\2.4.0-b34\hk2-locator-2.4.0-b34.jar;D:\Repository\org\javassist\javassist\3.18.1-GA\javassist-3.18.1-GA.jar;D:\Repository\org\glassfish\jersey\core\jersey-common\2.22.2\jersey-common-2.22.2.jar;D:\Repository\javax\annotation\javax.annotation-api\1.2\javax.annotation-api-1.2.jar;D:\Repository\org\glassfish\jersey\bundles\repackaged\jersey-guava\2.22.2\jersey-guava-2.22.2.jar;D:\Repository\org\glassfish\hk2\osgi-resource-locator\1.0.1\osgi-resource-locator-1.0.1.jar;D:\Repository\org\glassfish\jersey\core\jersey-server\2.22.2\jersey-server-2.22.2.jar;D:\Repository\org\glassfish\jersey\media\jersey-media-jaxb\2.22.2\jersey-media-jaxb-2.22.2.jar;D:\Repository\javax\validation\validation-api\1.1.0.Final\validation-api-1.1.0.Final.jar;D:\Repository\org\glassfish\jersey\containers\jersey-container-servlet\2.22.2\jersey-container-servlet-2.22.2.jar;D:\Repository\org\glassfish\jersey\containers\jersey-container-servlet-core\2.22.2\jersey-container-servlet-core-2.22.2.jar;D:\Repository\io\netty\netty-all\4.0.42.Final\netty-all-4.0.42.Final.jar;D:\Repository\io\netty\netty\3.8.0.Final\netty-3.8.0.Final.jar;D:\Repository\com\clearspring\analytics\stream\2.7.0\stream-2.7.0.jar;D:\Repository\io\dropwizard\metrics\metrics-core\3.1.2\metrics-core-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-jvm\3.1.2\metrics-jvm-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-json\3.1.2\metrics-json-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-graphite\3.1.2\metrics-graphite-3.1.2.jar;D:\Repository\com\fasterxml\jackson\core\jackson-databind\2.6.5\jackson-databind-2.6.5.jar;D:\Repository\com\fasterxml\jackson\core\jackson-core\2.6.5\jackson-core-2.6.5.jar;D:\Repository\com\fasterxml\jackson\module\jackson-module-scala_2.11\2.6.5\jackson-module-scala_2.11-2.6.5.jar;D:\Repository\org\scala-lang\scala-reflect\2.11.7\scala-reflect-2.11.7.jar;D:\Repository\com\fasterxml\jackson\module\jackson-module-paranamer\2.6.5\jackson-module-paranamer-2.6.5.jar;D:\Repository\org\apache\ivy\ivy\2.4.0\ivy-2.4.0.jar;D:\Repository\oro\oro\2.0.8\oro-2.0.8.jar;D:\Repository\net\razorvine\pyrolite\4.13\pyrolite-4.13.jar;D:\Repository\net\sf\py4j\py4j\0.10.4\py4j-0.10.4.jar;D:\Repository\org\apache\spark\spark-tags_2.11\2.1.0\spark-tags_2.11-2.1.0.jar;D:\Repository\org\scalatest\scalatest_2.11\2.2.6\scalatest_2.11-2.2.6.jar;D:\Repository\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;D:\Repository\org\spark-project\spark\unused\1.0.0\unused-1.0.0.jar;D:\Repository\org\apache\spark\spark-streaming_2.11\2.1.0\spark-streaming_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-sql_2.11\2.1.0\spark-sql_2.11-2.1.0.jar;D:\Repository\com\univocity\univocity-parsers\2.2.1\univocity-parsers-2.2.1.jar;D:\Repository\org\apache\spark\spark-sketch_2.11\2.1.0\spark-sketch_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-catalyst_2.11\2.1.0\spark-catalyst_2.11-2.1.0.jar;D:\Repository\org\codehaus\janino\janino\3.0.0\janino-3.0.0.jar;D:\Repository\org\codehaus\janino\commons-compiler\3.0.0\commons-compiler-3.0.0.jar;D:\Repository\org\antlr\antlr4-runtime\4.5.3\antlr4-runtime-4.5.3.jar;D:\Repository\org\apache\parquet\parquet-column\1.8.1\parquet-column-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-common\1.8.1\parquet-common-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-encoding\1.8.1\parquet-encoding-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-hadoop\1.8.1\parquet-hadoop-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-format\2.3.0-incubating\parquet-format-2.3.0-incubating.jar;D:\Repository\org\apache\parquet\parquet-jackson\1.8.1\parquet-jackson-1.8.1.jar;D:\Repository\org\apache\hadoop\hadoop-client\2.6.5\hadoop-client-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-common\2.6.5\hadoop-common-2.6.5.jar;D:\Repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;D:\Repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;D:\Repository\commons-io\commons-io\2.4\commons-io-2.4.jar;D:\Repository\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;D:\Repository\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;D:\Repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\Repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;D:\Repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;D:\Repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;D:\Repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;D:\Repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;D:\Repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;D:\Repository\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;D:\Repository\org\apache\hadoop\hadoop-auth\2.6.5\hadoop-auth-2.6.5.jar;D:\Repository\org\apache\httpcomponents\httpclient\4.2.5\httpclient-4.2.5.jar;D:\Repository\org\apache\httpcomponents\httpcore\4.2.4\httpcore-4.2.4.jar;D:\Repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;D:\Repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;D:\Repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;D:\Repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;D:\Repository\org\apache\curator\curator-client\2.6.0\curator-client-2.6.0.jar;D:\Repository\org\htrace\htrace-core\3.0.4\htrace-core-3.0.4.jar;D:\Repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;D:\Repository\org\tukaani\xz\1.0\xz-1.0.jar;D:\Repository\org\apache\hadoop\hadoop-hdfs\2.6.5\hadoop-hdfs-2.6.5.jar;D:\Repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;D:\Repository\xerces\xercesImpl\2.9.1\xercesImpl-2.9.1.jar;D:\Repository\xml-apis\xml-apis\1.3.04\xml-apis-1.3.04.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.6.5\hadoop-mapreduce-client-app-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.6.5\hadoop-mapreduce-client-common-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-client\2.6.5\hadoop-yarn-client-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-server-common\2.6.5\hadoop-yarn-server-common-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.6.5\hadoop-mapreduce-client-shuffle-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-api\2.6.5\hadoop-yarn-api-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.6.5\hadoop-mapreduce-client-core-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-common\2.6.5\hadoop-yarn-common-2.6.5.jar;D:\Repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;D:\Repository\javax\xml\stream\stax-api\1.0-2\stax-api-1.0-2.jar;D:\Repository\javax\activation\activation\1.1\activation-1.1.jar;D:\Repository\javax\servlet\servlet-api\2.5\servlet-api-2.5.jar;D:\Repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;D:\Repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;D:\Repository\org\codehaus\jackson\jackson-jaxrs\1.9.13\jackson-jaxrs-1.9.13.jar;D:\Repository\org\codehaus\jackson\jackson-xc\1.9.13\jackson-xc-1.9.13.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.6.5\hadoop-mapreduce-client-jobclient-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-annotations\2.6.5\hadoop-annotations-2.6.5.jar;D:\Repository\org\apache\kafka\kafka-clients\0.8.2.2\kafka-clients-0.8.2.2.jar;D:\Repository\org\apache\kafka\kafka_2.11\0.8.2.2\kafka_2.11-0.8.2.2.jar;D:\Repository\org\scala-lang\modules\scala-xml_2.11\1.0.2\scala-xml_2.11-1.0.2.jar;D:\Repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;D:\Repository\net\sf\jopt-simple\jopt-simple\3.2\jopt-simple-3.2.jar;D:\Repository\org\scala-lang\modules\scala-parser-combinators_2.11\1.0.2\scala-parser-combinators_2.11-1.0.2.jar;D:\Repository\com\101tec\zkclient\0.3\zkclient-0.3.jar;D:\Repository\mysql\mysql-connector-java\5.1.38\mysql-connector-java-5.1.38.jar;D:\Repository\org\apache\spark\spark-streaming-kafka-0-8_2.11\2.1.0\spark-streaming-kafka-0-8_2.11-2.1.0.jar;D:\Repository\org\apache\zookeeper\zookeeper\3.4.10\zookeeper-3.4.10.jar;D:\Repository\jline\jline\0.9.94\jline-0.9.94.jar;D:\developTools\IntelliJ IDEA 2018.2.3\lib\idea_rt.jar
2018-12-26 15:42:12 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_171\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;D:\developTools\Git\cmd;D:\developTools\svn\bin;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\scala\bin;C:\Users\junmei02\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk1.8.0_171\bin;D:\developTools\apache-maven-3.5.2\bin;D:\developTools\mysql-5.6.27-winx64\bin;D:\developTools\Git\cmd;D:\hadoop\hadoop-common-2.2.0-bin-master\bin;D:\hadoop\hbase-1.2.6\bin;C:\Program Files (x86)\scala\bin;D:\bigdata\zookeeper-3.4.10\bin;;.
2018-12-26 15:42:12 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.io.tmpdir=C:\Users\junmei02\AppData\Local\Temp\
2018-12-26 15:42:12 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.compiler=<NA>
2018-12-26 15:42:12 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.name=Windows 10
2018-12-26 15:42:12 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.arch=amd64
2018-12-26 15:42:12 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.version=10.0
2018-12-26 15:42:12 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.name=junmei02
2018-12-26 15:42:12 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.home=C:\Users\junmei02
2018-12-26 15:42:12 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.dir=D:\springbootworkspace\spark
2018-12-26 15:42:12 [ INFO ] - [ org.apache.zookeeper.ZooKeeper.<init>(ZooKeeper.java:438) ] Initiating client connection, connectString=127.0.0.1:2181 sessionTimeout=10000 watcher=org.apache.curator.ConnectionState@7ef82753
2018-12-26 15:42:13 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:1032) ] Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2018-12-26 15:42:13 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$SendThread.primeConnection(ClientCnxn.java:876) ] Socket connection established to 127.0.0.1/127.0.0.1:2181, initiating session
2018-12-26 15:42:13 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$SendThread.onConnected(ClientCnxn.java:1299) ] Session establishment complete on server 127.0.0.1/127.0.0.1:2181, sessionid = 0x167e951e94d0004, negotiated timeout = 10000
2018-12-26 15:42:13 [ INFO ] - [ org.apache.curator.framework.state.ConnectionStateManager.postState(ConnectionStateManager.java:194) ] State change: CONNECTED
2018-12-26 15:42:13 [ WARN ] - [ org.apache.curator.framework.state.ConnectionStateManager.processEvents(ConnectionStateManager.java:212) ] There are no ConnectionStateListeners registered.
2018-12-26 15:42:14 [ INFO ] - [ org.apache.zookeeper.ZooKeeper.close(ZooKeeper.java:684) ] Session: 0x167e951e94d0004 closed
2018-12-26 15:42:14 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:519) ] EventThread shut down for session: 0x167e951e94d0004
2018-12-26 15:42:15 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Running Spark version 2.1.0
2018-12-26 15:42:15 [ ERROR ] - [ org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:396) ] Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2373)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2373)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2373)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:837)
	at org.apache.spark.streaming.StreamingContext.<init>(StreamingContext.scala:84)
	at org.apache.spark.streaming.api.java.JavaStreamingContext.<init>(JavaStreamingContext.scala:138)
	at com.zqg.StreamKafka.KafkaSparkStreamingWithZookeeperoffset.main(KafkaSparkStreamingWithZookeeperoffset.java:70)
2018-12-26 15:42:15 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing view acls to: junmei02
2018-12-26 15:42:15 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing modify acls to: junmei02
2018-12-26 15:42:15 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing view acls groups to: 
2018-12-26 15:42:15 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing modify acls groups to: 
2018-12-26 15:42:15 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(junmei02); groups with view permissions: Set(); users  with modify permissions: Set(junmei02); groups with modify permissions: Set()
2018-12-26 15:42:16 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'sparkDriver' on port 53595.
2018-12-26 15:42:16 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering MapOutputTracker
2018-12-26 15:42:16 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering BlockManagerMaster
2018-12-26 15:42:16 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-26 15:42:16 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] BlockManagerMasterEndpoint up
2018-12-26 15:42:16 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Created local directory at C:\Users\junmei02\AppData\Local\Temp\blockmgr-6041118d-d745-4d5e-ab39-20cbc6e588bb
2018-12-26 15:42:16 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] MemoryStore started with capacity 900.6 MB
2018-12-26 15:42:16 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering OutputCommitCoordinator
2018-12-26 15:42:16 [ INFO ] - [ org.spark_project.jetty.util.log.Log.initialized(Log.java:186) ] Logging initialized @4557ms
2018-12-26 15:42:16 [ INFO ] - [ org.spark_project.jetty.server.Server.doStart(Server.java:327) ] jetty-9.2.z-SNAPSHOT
2018-12-26 15:42:16 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@66eb985d{/jobs,null,AVAILABLE}
2018-12-26 15:42:16 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@6a9287b1{/jobs/json,null,AVAILABLE}
2018-12-26 15:42:16 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@75504cef{/jobs/job,null,AVAILABLE}
2018-12-26 15:42:16 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@6c8a68c1{/jobs/job/json,null,AVAILABLE}
2018-12-26 15:42:16 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@56193c7d{/stages,null,AVAILABLE}
2018-12-26 15:42:16 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@28c88600{/stages/json,null,AVAILABLE}
2018-12-26 15:42:16 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@5f8890c2{/stages/stage,null,AVAILABLE}
2018-12-26 15:42:16 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@607b2792{/stages/stage/json,null,AVAILABLE}
2018-12-26 15:42:16 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@7f9e1534{/stages/pool,null,AVAILABLE}
2018-12-26 15:42:16 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@138a7441{/stages/pool/json,null,AVAILABLE}
2018-12-26 15:42:16 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@81ff872{/storage,null,AVAILABLE}
2018-12-26 15:42:16 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@31611954{/storage/json,null,AVAILABLE}
2018-12-26 15:42:16 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@3e598df9{/storage/rdd,null,AVAILABLE}
2018-12-26 15:42:16 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@7e31ce0f{/storage/rdd/json,null,AVAILABLE}
2018-12-26 15:42:16 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@99a65d3{/environment,null,AVAILABLE}
2018-12-26 15:42:16 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@3088660d{/environment/json,null,AVAILABLE}
2018-12-26 15:42:16 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@42cc13a0{/executors,null,AVAILABLE}
2018-12-26 15:42:16 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@32fdec40{/executors/json,null,AVAILABLE}
2018-12-26 15:42:16 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@6813a331{/executors/threadDump,null,AVAILABLE}
2018-12-26 15:42:16 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@1bd81830{/executors/threadDump/json,null,AVAILABLE}
2018-12-26 15:42:16 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@39ab59f8{/static,null,AVAILABLE}
2018-12-26 15:42:16 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@64e92d61{/,null,AVAILABLE}
2018-12-26 15:42:16 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@111610e6{/api,null,AVAILABLE}
2018-12-26 15:42:16 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@4ad4936c{/jobs/job/kill,null,AVAILABLE}
2018-12-26 15:42:16 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@29d37757{/stages/stage/kill,null,AVAILABLE}
2018-12-26 15:42:16 [ INFO ] - [ org.spark_project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:266) ] Started ServerConnector@522a75d8{HTTP/1.1}{0.0.0.0:4040}
2018-12-26 15:42:16 [ INFO ] - [ org.spark_project.jetty.server.Server.doStart(Server.java:379) ] Started @4727ms
2018-12-26 15:42:16 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'SparkUI' on port 4040.
2018-12-26 15:42:16 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Bound SparkUI to 0.0.0.0, and started at http://192.168.0.112:4040
2018-12-26 15:42:16 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Starting executor ID driver on host localhost
2018-12-26 15:42:16 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53616.
2018-12-26 15:42:16 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Server created on 192.168.0.112:53616
2018-12-26 15:42:16 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-26 15:42:16 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering BlockManager BlockManagerId(driver, 192.168.0.112, 53616, None)
2018-12-26 15:42:16 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering block manager 192.168.0.112:53616 with 900.6 MB RAM, BlockManagerId(driver, 192.168.0.112, 53616, None)
2018-12-26 15:42:16 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registered BlockManager BlockManagerId(driver, 192.168.0.112, 53616, None)
2018-12-26 15:42:16 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Initialized BlockManager: BlockManagerId(driver, 192.168.0.112, 53616, None)
2018-12-26 15:42:16 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@2d195ee4{/metrics/json,null,AVAILABLE}
2018-12-26 15:48:41 [ INFO ] - [ org.apache.curator.framework.imps.CuratorFrameworkImpl.start(CuratorFrameworkImpl.java:223) ] Starting
2018-12-26 15:48:41 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT
2018-12-26 15:48:41 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:host.name=windows10.microdone.cn
2018-12-26 15:48:41 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.version=1.8.0_171
2018-12-26 15:48:41 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.vendor=Oracle Corporation
2018-12-26 15:48:41 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.home=C:\Program Files\Java\jdk1.8.0_171\jre
2018-12-26 15:48:41 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.class.path=C:\Program Files\Java\jdk1.8.0_171\jre\lib\charsets.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\deploy.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\access-bridge-64.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\cldrdata.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\dnsns.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\jaccess.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\jfxrt.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\localedata.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\nashorn.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunec.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunjce_provider.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunmscapi.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunpkcs11.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\zipfs.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\javaws.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jce.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jfr.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jfxswt.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jsse.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\management-agent.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\plugin.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\resources.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\rt.jar;D:\springbootworkspace\spark\target\classes;D:\Repository\org\scala-lang\scala-library\2.11.8\scala-library-2.11.8.jar;D:\Repository\org\apache\spark\spark-core_2.11\2.1.0\spark-core_2.11-2.1.0.jar;D:\Repository\org\apache\avro\avro-mapred\1.7.7\avro-mapred-1.7.7-hadoop2.jar;D:\Repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7.jar;D:\Repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7-tests.jar;D:\Repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;D:\Repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;D:\Repository\com\twitter\chill_2.11\0.8.0\chill_2.11-0.8.0.jar;D:\Repository\com\esotericsoftware\kryo-shaded\3.0.3\kryo-shaded-3.0.3.jar;D:\Repository\com\esotericsoftware\minlog\1.3.0\minlog-1.3.0.jar;D:\Repository\org\objenesis\objenesis\2.1\objenesis-2.1.jar;D:\Repository\com\twitter\chill-java\0.8.0\chill-java-0.8.0.jar;D:\Repository\org\apache\xbean\xbean-asm5-shaded\4.4\xbean-asm5-shaded-4.4.jar;D:\Repository\org\apache\spark\spark-launcher_2.11\2.1.0\spark-launcher_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-network-common_2.11\2.1.0\spark-network-common_2.11-2.1.0.jar;D:\Repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;D:\Repository\com\fasterxml\jackson\core\jackson-annotations\2.6.5\jackson-annotations-2.6.5.jar;D:\Repository\org\apache\spark\spark-network-shuffle_2.11\2.1.0\spark-network-shuffle_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-unsafe_2.11\2.1.0\spark-unsafe_2.11-2.1.0.jar;D:\Repository\net\java\dev\jets3t\jets3t\0.7.1\jets3t-0.7.1.jar;D:\Repository\commons-codec\commons-codec\1.3\commons-codec-1.3.jar;D:\Repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;D:\Repository\org\apache\curator\curator-recipes\2.4.0\curator-recipes-2.4.0.jar;D:\Repository\org\apache\curator\curator-framework\2.4.0\curator-framework-2.4.0.jar;D:\Repository\com\google\guava\guava\14.0.1\guava-14.0.1.jar;D:\Repository\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;D:\Repository\org\apache\commons\commons-lang3\3.5\commons-lang3-3.5.jar;D:\Repository\org\apache\commons\commons-math3\3.4.1\commons-math3-3.4.1.jar;D:\Repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;D:\Repository\org\slf4j\slf4j-api\1.7.16\slf4j-api-1.7.16.jar;D:\Repository\org\slf4j\jul-to-slf4j\1.7.16\jul-to-slf4j-1.7.16.jar;D:\Repository\org\slf4j\jcl-over-slf4j\1.7.16\jcl-over-slf4j-1.7.16.jar;D:\Repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;D:\Repository\org\slf4j\slf4j-log4j12\1.7.16\slf4j-log4j12-1.7.16.jar;D:\Repository\com\ning\compress-lzf\1.0.3\compress-lzf-1.0.3.jar;D:\Repository\org\xerial\snappy\snappy-java\1.1.2.6\snappy-java-1.1.2.6.jar;D:\Repository\net\jpountz\lz4\lz4\1.3.0\lz4-1.3.0.jar;D:\Repository\org\roaringbitmap\RoaringBitmap\0.5.11\RoaringBitmap-0.5.11.jar;D:\Repository\commons-net\commons-net\2.2\commons-net-2.2.jar;D:\Repository\org\json4s\json4s-jackson_2.11\3.2.11\json4s-jackson_2.11-3.2.11.jar;D:\Repository\org\json4s\json4s-core_2.11\3.2.11\json4s-core_2.11-3.2.11.jar;D:\Repository\org\json4s\json4s-ast_2.11\3.2.11\json4s-ast_2.11-3.2.11.jar;D:\Repository\com\thoughtworks\paranamer\paranamer\2.6\paranamer-2.6.jar;D:\Repository\org\scala-lang\scalap\2.11.0\scalap-2.11.0.jar;D:\Repository\org\scala-lang\scala-compiler\2.11.0\scala-compiler-2.11.0.jar;D:\Repository\org\glassfish\jersey\core\jersey-client\2.22.2\jersey-client-2.22.2.jar;D:\Repository\javax\ws\rs\javax.ws.rs-api\2.0.1\javax.ws.rs-api-2.0.1.jar;D:\Repository\org\glassfish\hk2\hk2-api\2.4.0-b34\hk2-api-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\hk2-utils\2.4.0-b34\hk2-utils-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\external\aopalliance-repackaged\2.4.0-b34\aopalliance-repackaged-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\external\javax.inject\2.4.0-b34\javax.inject-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\hk2-locator\2.4.0-b34\hk2-locator-2.4.0-b34.jar;D:\Repository\org\javassist\javassist\3.18.1-GA\javassist-3.18.1-GA.jar;D:\Repository\org\glassfish\jersey\core\jersey-common\2.22.2\jersey-common-2.22.2.jar;D:\Repository\javax\annotation\javax.annotation-api\1.2\javax.annotation-api-1.2.jar;D:\Repository\org\glassfish\jersey\bundles\repackaged\jersey-guava\2.22.2\jersey-guava-2.22.2.jar;D:\Repository\org\glassfish\hk2\osgi-resource-locator\1.0.1\osgi-resource-locator-1.0.1.jar;D:\Repository\org\glassfish\jersey\core\jersey-server\2.22.2\jersey-server-2.22.2.jar;D:\Repository\org\glassfish\jersey\media\jersey-media-jaxb\2.22.2\jersey-media-jaxb-2.22.2.jar;D:\Repository\javax\validation\validation-api\1.1.0.Final\validation-api-1.1.0.Final.jar;D:\Repository\org\glassfish\jersey\containers\jersey-container-servlet\2.22.2\jersey-container-servlet-2.22.2.jar;D:\Repository\org\glassfish\jersey\containers\jersey-container-servlet-core\2.22.2\jersey-container-servlet-core-2.22.2.jar;D:\Repository\io\netty\netty-all\4.0.42.Final\netty-all-4.0.42.Final.jar;D:\Repository\io\netty\netty\3.8.0.Final\netty-3.8.0.Final.jar;D:\Repository\com\clearspring\analytics\stream\2.7.0\stream-2.7.0.jar;D:\Repository\io\dropwizard\metrics\metrics-core\3.1.2\metrics-core-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-jvm\3.1.2\metrics-jvm-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-json\3.1.2\metrics-json-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-graphite\3.1.2\metrics-graphite-3.1.2.jar;D:\Repository\com\fasterxml\jackson\core\jackson-databind\2.6.5\jackson-databind-2.6.5.jar;D:\Repository\com\fasterxml\jackson\core\jackson-core\2.6.5\jackson-core-2.6.5.jar;D:\Repository\com\fasterxml\jackson\module\jackson-module-scala_2.11\2.6.5\jackson-module-scala_2.11-2.6.5.jar;D:\Repository\org\scala-lang\scala-reflect\2.11.7\scala-reflect-2.11.7.jar;D:\Repository\com\fasterxml\jackson\module\jackson-module-paranamer\2.6.5\jackson-module-paranamer-2.6.5.jar;D:\Repository\org\apache\ivy\ivy\2.4.0\ivy-2.4.0.jar;D:\Repository\oro\oro\2.0.8\oro-2.0.8.jar;D:\Repository\net\razorvine\pyrolite\4.13\pyrolite-4.13.jar;D:\Repository\net\sf\py4j\py4j\0.10.4\py4j-0.10.4.jar;D:\Repository\org\apache\spark\spark-tags_2.11\2.1.0\spark-tags_2.11-2.1.0.jar;D:\Repository\org\scalatest\scalatest_2.11\2.2.6\scalatest_2.11-2.2.6.jar;D:\Repository\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;D:\Repository\org\spark-project\spark\unused\1.0.0\unused-1.0.0.jar;D:\Repository\org\apache\spark\spark-streaming_2.11\2.1.0\spark-streaming_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-sql_2.11\2.1.0\spark-sql_2.11-2.1.0.jar;D:\Repository\com\univocity\univocity-parsers\2.2.1\univocity-parsers-2.2.1.jar;D:\Repository\org\apache\spark\spark-sketch_2.11\2.1.0\spark-sketch_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-catalyst_2.11\2.1.0\spark-catalyst_2.11-2.1.0.jar;D:\Repository\org\codehaus\janino\janino\3.0.0\janino-3.0.0.jar;D:\Repository\org\codehaus\janino\commons-compiler\3.0.0\commons-compiler-3.0.0.jar;D:\Repository\org\antlr\antlr4-runtime\4.5.3\antlr4-runtime-4.5.3.jar;D:\Repository\org\apache\parquet\parquet-column\1.8.1\parquet-column-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-common\1.8.1\parquet-common-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-encoding\1.8.1\parquet-encoding-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-hadoop\1.8.1\parquet-hadoop-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-format\2.3.0-incubating\parquet-format-2.3.0-incubating.jar;D:\Repository\org\apache\parquet\parquet-jackson\1.8.1\parquet-jackson-1.8.1.jar;D:\Repository\org\apache\hadoop\hadoop-client\2.6.5\hadoop-client-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-common\2.6.5\hadoop-common-2.6.5.jar;D:\Repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;D:\Repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;D:\Repository\commons-io\commons-io\2.4\commons-io-2.4.jar;D:\Repository\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;D:\Repository\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;D:\Repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\Repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;D:\Repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;D:\Repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;D:\Repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;D:\Repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;D:\Repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;D:\Repository\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;D:\Repository\org\apache\hadoop\hadoop-auth\2.6.5\hadoop-auth-2.6.5.jar;D:\Repository\org\apache\httpcomponents\httpclient\4.2.5\httpclient-4.2.5.jar;D:\Repository\org\apache\httpcomponents\httpcore\4.2.4\httpcore-4.2.4.jar;D:\Repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;D:\Repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;D:\Repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;D:\Repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;D:\Repository\org\apache\curator\curator-client\2.6.0\curator-client-2.6.0.jar;D:\Repository\org\htrace\htrace-core\3.0.4\htrace-core-3.0.4.jar;D:\Repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;D:\Repository\org\tukaani\xz\1.0\xz-1.0.jar;D:\Repository\org\apache\hadoop\hadoop-hdfs\2.6.5\hadoop-hdfs-2.6.5.jar;D:\Repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;D:\Repository\xerces\xercesImpl\2.9.1\xercesImpl-2.9.1.jar;D:\Repository\xml-apis\xml-apis\1.3.04\xml-apis-1.3.04.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.6.5\hadoop-mapreduce-client-app-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.6.5\hadoop-mapreduce-client-common-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-client\2.6.5\hadoop-yarn-client-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-server-common\2.6.5\hadoop-yarn-server-common-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.6.5\hadoop-mapreduce-client-shuffle-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-api\2.6.5\hadoop-yarn-api-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.6.5\hadoop-mapreduce-client-core-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-common\2.6.5\hadoop-yarn-common-2.6.5.jar;D:\Repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;D:\Repository\javax\xml\stream\stax-api\1.0-2\stax-api-1.0-2.jar;D:\Repository\javax\activation\activation\1.1\activation-1.1.jar;D:\Repository\javax\servlet\servlet-api\2.5\servlet-api-2.5.jar;D:\Repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;D:\Repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;D:\Repository\org\codehaus\jackson\jackson-jaxrs\1.9.13\jackson-jaxrs-1.9.13.jar;D:\Repository\org\codehaus\jackson\jackson-xc\1.9.13\jackson-xc-1.9.13.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.6.5\hadoop-mapreduce-client-jobclient-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-annotations\2.6.5\hadoop-annotations-2.6.5.jar;D:\Repository\org\apache\kafka\kafka-clients\0.8.2.2\kafka-clients-0.8.2.2.jar;D:\Repository\org\apache\kafka\kafka_2.11\0.8.2.2\kafka_2.11-0.8.2.2.jar;D:\Repository\org\scala-lang\modules\scala-xml_2.11\1.0.2\scala-xml_2.11-1.0.2.jar;D:\Repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;D:\Repository\net\sf\jopt-simple\jopt-simple\3.2\jopt-simple-3.2.jar;D:\Repository\org\scala-lang\modules\scala-parser-combinators_2.11\1.0.2\scala-parser-combinators_2.11-1.0.2.jar;D:\Repository\com\101tec\zkclient\0.3\zkclient-0.3.jar;D:\Repository\mysql\mysql-connector-java\5.1.38\mysql-connector-java-5.1.38.jar;D:\Repository\org\apache\spark\spark-streaming-kafka-0-8_2.11\2.1.0\spark-streaming-kafka-0-8_2.11-2.1.0.jar;D:\Repository\org\apache\zookeeper\zookeeper\3.4.10\zookeeper-3.4.10.jar;D:\Repository\jline\jline\0.9.94\jline-0.9.94.jar;D:\developTools\IntelliJ IDEA 2018.2.3\lib\idea_rt.jar
2018-12-26 15:48:41 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_171\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;D:\developTools\Git\cmd;D:\developTools\svn\bin;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\scala\bin;C:\Users\junmei02\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk1.8.0_171\bin;D:\developTools\apache-maven-3.5.2\bin;D:\developTools\mysql-5.6.27-winx64\bin;D:\developTools\Git\cmd;D:\hadoop\hadoop-common-2.2.0-bin-master\bin;D:\hadoop\hbase-1.2.6\bin;C:\Program Files (x86)\scala\bin;D:\bigdata\zookeeper-3.4.10\bin;;.
2018-12-26 15:48:41 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.io.tmpdir=C:\Users\junmei02\AppData\Local\Temp\
2018-12-26 15:48:41 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.compiler=<NA>
2018-12-26 15:48:41 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.name=Windows 10
2018-12-26 15:48:41 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.arch=amd64
2018-12-26 15:48:41 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.version=10.0
2018-12-26 15:48:41 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.name=junmei02
2018-12-26 15:48:41 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.home=C:\Users\junmei02
2018-12-26 15:48:41 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.dir=D:\springbootworkspace\spark
2018-12-26 15:48:41 [ INFO ] - [ org.apache.zookeeper.ZooKeeper.<init>(ZooKeeper.java:438) ] Initiating client connection, connectString=127.0.0.1:2181 sessionTimeout=10000 watcher=org.apache.curator.ConnectionState@2034b64c
2018-12-26 15:48:42 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:1032) ] Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2018-12-26 15:48:42 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$SendThread.primeConnection(ClientCnxn.java:876) ] Socket connection established to 127.0.0.1/127.0.0.1:2181, initiating session
2018-12-26 15:48:42 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$SendThread.onConnected(ClientCnxn.java:1299) ] Session establishment complete on server 127.0.0.1/127.0.0.1:2181, sessionid = 0x167e951e94d0005, negotiated timeout = 10000
2018-12-26 15:48:42 [ INFO ] - [ org.apache.curator.framework.state.ConnectionStateManager.postState(ConnectionStateManager.java:194) ] State change: CONNECTED
2018-12-26 15:48:42 [ WARN ] - [ org.apache.curator.framework.state.ConnectionStateManager.processEvents(ConnectionStateManager.java:212) ] There are no ConnectionStateListeners registered.
2018-12-26 15:48:42 [ INFO ] - [ org.apache.zookeeper.ZooKeeper.close(ZooKeeper.java:684) ] Session: 0x167e951e94d0005 closed
2018-12-26 15:48:42 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:519) ] EventThread shut down for session: 0x167e951e94d0005
2018-12-26 15:48:43 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Running Spark version 2.1.0
2018-12-26 15:48:43 [ ERROR ] - [ org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:396) ] Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2373)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2373)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2373)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:837)
	at org.apache.spark.streaming.StreamingContext.<init>(StreamingContext.scala:84)
	at org.apache.spark.streaming.api.java.JavaStreamingContext.<init>(JavaStreamingContext.scala:138)
	at com.zqg.StreamKafka.KafkaSparkStreamingWithZookeeperoffset.main(KafkaSparkStreamingWithZookeeperoffset.java:67)
2018-12-26 15:48:43 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing view acls to: junmei02
2018-12-26 15:48:43 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing modify acls to: junmei02
2018-12-26 15:48:43 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing view acls groups to: 
2018-12-26 15:48:43 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing modify acls groups to: 
2018-12-26 15:48:43 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(junmei02); groups with view permissions: Set(); users  with modify permissions: Set(junmei02); groups with modify permissions: Set()
2018-12-26 15:48:44 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'sparkDriver' on port 53852.
2018-12-26 15:48:44 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering MapOutputTracker
2018-12-26 15:48:44 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering BlockManagerMaster
2018-12-26 15:48:44 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-26 15:48:44 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] BlockManagerMasterEndpoint up
2018-12-26 15:48:44 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Created local directory at C:\Users\junmei02\AppData\Local\Temp\blockmgr-30d17a0e-d463-41f1-ae1e-d5156b8fe833
2018-12-26 15:48:44 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] MemoryStore started with capacity 900.6 MB
2018-12-26 15:48:44 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering OutputCommitCoordinator
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.util.log.Log.initialized(Log.java:186) ] Logging initialized @3578ms
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.Server.doStart(Server.java:327) ] jetty-9.2.z-SNAPSHOT
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@5f8890c2{/jobs,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@607b2792{/jobs/json,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@7f9e1534{/jobs/job,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@138a7441{/jobs/job/json,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@81ff872{/stages,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@31611954{/stages/json,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@3e598df9{/stages/stage,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@7e31ce0f{/stages/stage/json,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@99a65d3{/stages/pool,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@3088660d{/stages/pool/json,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@42cc13a0{/storage,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@32fdec40{/storage/json,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@6813a331{/storage/rdd,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@1bd81830{/storage/rdd/json,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@39ab59f8{/environment,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@64e92d61{/environment/json,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@111610e6{/executors,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@4ad4936c{/executors/json,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@29d37757{/executors/threadDump,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@4fcc529{/executors/threadDump/json,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@25cc7470{/static,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@4beddc56{/,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@79b663b3{/api,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@1b812421{/jobs/job/kill,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@5d28bcd5{/stages/stage/kill,null,AVAILABLE}
2018-12-26 15:48:44 [ WARN ] - [ org.spark_project.jetty.util.component.AbstractLifeCycle.setFailed(AbstractLifeCycle.java:212) ] FAILED ServerConnector@127d7908{HTTP/1.1}{0.0.0.0:4040}: java.net.BindException: Address already in use: bind
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:349)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:359)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:359)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2195)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2186)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:359)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:140)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:460)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:460)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:460)
	at org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:837)
	at org.apache.spark.streaming.StreamingContext.<init>(StreamingContext.scala:84)
	at org.apache.spark.streaming.api.java.JavaStreamingContext.<init>(JavaStreamingContext.scala:138)
	at com.zqg.StreamKafka.KafkaSparkStreamingWithZookeeperoffset.main(KafkaSparkStreamingWithZookeeperoffset.java:67)
2018-12-26 15:48:44 [ WARN ] - [ org.spark_project.jetty.util.component.AbstractLifeCycle.setFailed(AbstractLifeCycle.java:212) ] FAILED org.spark_project.jetty.server.Server@6622a690: java.net.BindException: Address already in use: bind
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:349)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:359)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:359)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2195)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2186)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:359)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:140)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:460)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:460)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:460)
	at org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:837)
	at org.apache.spark.streaming.StreamingContext.<init>(StreamingContext.scala:84)
	at org.apache.spark.streaming.api.java.JavaStreamingContext.<init>(JavaStreamingContext.scala:138)
	at com.zqg.StreamKafka.KafkaSparkStreamingWithZookeeperoffset.main(KafkaSparkStreamingWithZookeeperoffset.java:67)
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.AbstractConnector.doStop(AbstractConnector.java:306) ] Stopped ServerConnector@127d7908{HTTP/1.1}{0.0.0.0:4040}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@5d28bcd5{/stages/stage/kill,null,UNAVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@1b812421{/jobs/job/kill,null,UNAVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@79b663b3{/api,null,UNAVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@4beddc56{/,null,UNAVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@25cc7470{/static,null,UNAVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@4fcc529{/executors/threadDump/json,null,UNAVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@29d37757{/executors/threadDump,null,UNAVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@4ad4936c{/executors/json,null,UNAVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@111610e6{/executors,null,UNAVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@64e92d61{/environment/json,null,UNAVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@39ab59f8{/environment,null,UNAVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@1bd81830{/storage/rdd/json,null,UNAVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@6813a331{/storage/rdd,null,UNAVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@32fdec40{/storage/json,null,UNAVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@42cc13a0{/storage,null,UNAVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@3088660d{/stages/pool/json,null,UNAVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@99a65d3{/stages/pool,null,UNAVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@7e31ce0f{/stages/stage/json,null,UNAVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@3e598df9{/stages/stage,null,UNAVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@31611954{/stages/json,null,UNAVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@81ff872{/stages,null,UNAVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@138a7441{/jobs/job/json,null,UNAVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@7f9e1534{/jobs/job,null,UNAVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@607b2792{/jobs/json,null,UNAVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:865) ] Stopped o.s.j.s.ServletContextHandler@5f8890c2{/jobs,null,UNAVAILABLE}
2018-12-26 15:48:44 [ WARN ] - [ org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66) ] Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.Server.doStart(Server.java:327) ] jetty-9.2.z-SNAPSHOT
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@5f8890c2{/jobs,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@607b2792{/jobs/json,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@7f9e1534{/jobs/job,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@138a7441{/jobs/job/json,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@81ff872{/stages,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@31611954{/stages/json,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@3e598df9{/stages/stage,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@7e31ce0f{/stages/stage/json,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@99a65d3{/stages/pool,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@3088660d{/stages/pool/json,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@42cc13a0{/storage,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@32fdec40{/storage/json,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@6813a331{/storage/rdd,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@1bd81830{/storage/rdd/json,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@39ab59f8{/environment,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@64e92d61{/environment/json,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@111610e6{/executors,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@4ad4936c{/executors/json,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@29d37757{/executors/threadDump,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@4fcc529{/executors/threadDump/json,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@25cc7470{/static,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@4beddc56{/,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@79b663b3{/api,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@1b812421{/jobs/job/kill,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@5d28bcd5{/stages/stage/kill,null,AVAILABLE}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:266) ] Started ServerConnector@1f86099a{HTTP/1.1}{0.0.0.0:4041}
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.Server.doStart(Server.java:379) ] Started @3762ms
2018-12-26 15:48:44 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'SparkUI' on port 4041.
2018-12-26 15:48:44 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Bound SparkUI to 0.0.0.0, and started at http://192.168.0.112:4041
2018-12-26 15:48:44 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Starting executor ID driver on host localhost
2018-12-26 15:48:44 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53873.
2018-12-26 15:48:44 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Server created on 192.168.0.112:53873
2018-12-26 15:48:44 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-26 15:48:44 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering BlockManager BlockManagerId(driver, 192.168.0.112, 53873, None)
2018-12-26 15:48:44 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering block manager 192.168.0.112:53873 with 900.6 MB RAM, BlockManagerId(driver, 192.168.0.112, 53873, None)
2018-12-26 15:48:44 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registered BlockManager BlockManagerId(driver, 192.168.0.112, 53873, None)
2018-12-26 15:48:44 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Initialized BlockManager: BlockManagerId(driver, 192.168.0.112, 53873, None)
2018-12-26 15:48:44 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@777c350f{/metrics/json,null,AVAILABLE}
2018-12-26 15:49:28 [ INFO ] - [ org.apache.curator.framework.imps.CuratorFrameworkImpl.start(CuratorFrameworkImpl.java:223) ] Starting
2018-12-26 15:49:28 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT
2018-12-26 15:49:28 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:host.name=windows10.microdone.cn
2018-12-26 15:49:28 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.version=1.8.0_171
2018-12-26 15:49:28 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.vendor=Oracle Corporation
2018-12-26 15:49:28 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.home=C:\Program Files\Java\jdk1.8.0_171\jre
2018-12-26 15:49:28 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.class.path=C:\Program Files\Java\jdk1.8.0_171\jre\lib\charsets.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\deploy.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\access-bridge-64.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\cldrdata.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\dnsns.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\jaccess.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\jfxrt.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\localedata.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\nashorn.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunec.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunjce_provider.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunmscapi.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunpkcs11.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\zipfs.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\javaws.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jce.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jfr.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jfxswt.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jsse.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\management-agent.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\plugin.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\resources.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\rt.jar;D:\springbootworkspace\spark\target\classes;D:\Repository\org\scala-lang\scala-library\2.11.8\scala-library-2.11.8.jar;D:\Repository\org\apache\spark\spark-core_2.11\2.1.0\spark-core_2.11-2.1.0.jar;D:\Repository\org\apache\avro\avro-mapred\1.7.7\avro-mapred-1.7.7-hadoop2.jar;D:\Repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7.jar;D:\Repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7-tests.jar;D:\Repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;D:\Repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;D:\Repository\com\twitter\chill_2.11\0.8.0\chill_2.11-0.8.0.jar;D:\Repository\com\esotericsoftware\kryo-shaded\3.0.3\kryo-shaded-3.0.3.jar;D:\Repository\com\esotericsoftware\minlog\1.3.0\minlog-1.3.0.jar;D:\Repository\org\objenesis\objenesis\2.1\objenesis-2.1.jar;D:\Repository\com\twitter\chill-java\0.8.0\chill-java-0.8.0.jar;D:\Repository\org\apache\xbean\xbean-asm5-shaded\4.4\xbean-asm5-shaded-4.4.jar;D:\Repository\org\apache\spark\spark-launcher_2.11\2.1.0\spark-launcher_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-network-common_2.11\2.1.0\spark-network-common_2.11-2.1.0.jar;D:\Repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;D:\Repository\com\fasterxml\jackson\core\jackson-annotations\2.6.5\jackson-annotations-2.6.5.jar;D:\Repository\org\apache\spark\spark-network-shuffle_2.11\2.1.0\spark-network-shuffle_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-unsafe_2.11\2.1.0\spark-unsafe_2.11-2.1.0.jar;D:\Repository\net\java\dev\jets3t\jets3t\0.7.1\jets3t-0.7.1.jar;D:\Repository\commons-codec\commons-codec\1.3\commons-codec-1.3.jar;D:\Repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;D:\Repository\org\apache\curator\curator-recipes\2.4.0\curator-recipes-2.4.0.jar;D:\Repository\org\apache\curator\curator-framework\2.4.0\curator-framework-2.4.0.jar;D:\Repository\com\google\guava\guava\14.0.1\guava-14.0.1.jar;D:\Repository\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;D:\Repository\org\apache\commons\commons-lang3\3.5\commons-lang3-3.5.jar;D:\Repository\org\apache\commons\commons-math3\3.4.1\commons-math3-3.4.1.jar;D:\Repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;D:\Repository\org\slf4j\slf4j-api\1.7.16\slf4j-api-1.7.16.jar;D:\Repository\org\slf4j\jul-to-slf4j\1.7.16\jul-to-slf4j-1.7.16.jar;D:\Repository\org\slf4j\jcl-over-slf4j\1.7.16\jcl-over-slf4j-1.7.16.jar;D:\Repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;D:\Repository\org\slf4j\slf4j-log4j12\1.7.16\slf4j-log4j12-1.7.16.jar;D:\Repository\com\ning\compress-lzf\1.0.3\compress-lzf-1.0.3.jar;D:\Repository\org\xerial\snappy\snappy-java\1.1.2.6\snappy-java-1.1.2.6.jar;D:\Repository\net\jpountz\lz4\lz4\1.3.0\lz4-1.3.0.jar;D:\Repository\org\roaringbitmap\RoaringBitmap\0.5.11\RoaringBitmap-0.5.11.jar;D:\Repository\commons-net\commons-net\2.2\commons-net-2.2.jar;D:\Repository\org\json4s\json4s-jackson_2.11\3.2.11\json4s-jackson_2.11-3.2.11.jar;D:\Repository\org\json4s\json4s-core_2.11\3.2.11\json4s-core_2.11-3.2.11.jar;D:\Repository\org\json4s\json4s-ast_2.11\3.2.11\json4s-ast_2.11-3.2.11.jar;D:\Repository\com\thoughtworks\paranamer\paranamer\2.6\paranamer-2.6.jar;D:\Repository\org\scala-lang\scalap\2.11.0\scalap-2.11.0.jar;D:\Repository\org\scala-lang\scala-compiler\2.11.0\scala-compiler-2.11.0.jar;D:\Repository\org\glassfish\jersey\core\jersey-client\2.22.2\jersey-client-2.22.2.jar;D:\Repository\javax\ws\rs\javax.ws.rs-api\2.0.1\javax.ws.rs-api-2.0.1.jar;D:\Repository\org\glassfish\hk2\hk2-api\2.4.0-b34\hk2-api-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\hk2-utils\2.4.0-b34\hk2-utils-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\external\aopalliance-repackaged\2.4.0-b34\aopalliance-repackaged-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\external\javax.inject\2.4.0-b34\javax.inject-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\hk2-locator\2.4.0-b34\hk2-locator-2.4.0-b34.jar;D:\Repository\org\javassist\javassist\3.18.1-GA\javassist-3.18.1-GA.jar;D:\Repository\org\glassfish\jersey\core\jersey-common\2.22.2\jersey-common-2.22.2.jar;D:\Repository\javax\annotation\javax.annotation-api\1.2\javax.annotation-api-1.2.jar;D:\Repository\org\glassfish\jersey\bundles\repackaged\jersey-guava\2.22.2\jersey-guava-2.22.2.jar;D:\Repository\org\glassfish\hk2\osgi-resource-locator\1.0.1\osgi-resource-locator-1.0.1.jar;D:\Repository\org\glassfish\jersey\core\jersey-server\2.22.2\jersey-server-2.22.2.jar;D:\Repository\org\glassfish\jersey\media\jersey-media-jaxb\2.22.2\jersey-media-jaxb-2.22.2.jar;D:\Repository\javax\validation\validation-api\1.1.0.Final\validation-api-1.1.0.Final.jar;D:\Repository\org\glassfish\jersey\containers\jersey-container-servlet\2.22.2\jersey-container-servlet-2.22.2.jar;D:\Repository\org\glassfish\jersey\containers\jersey-container-servlet-core\2.22.2\jersey-container-servlet-core-2.22.2.jar;D:\Repository\io\netty\netty-all\4.0.42.Final\netty-all-4.0.42.Final.jar;D:\Repository\io\netty\netty\3.8.0.Final\netty-3.8.0.Final.jar;D:\Repository\com\clearspring\analytics\stream\2.7.0\stream-2.7.0.jar;D:\Repository\io\dropwizard\metrics\metrics-core\3.1.2\metrics-core-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-jvm\3.1.2\metrics-jvm-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-json\3.1.2\metrics-json-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-graphite\3.1.2\metrics-graphite-3.1.2.jar;D:\Repository\com\fasterxml\jackson\core\jackson-databind\2.6.5\jackson-databind-2.6.5.jar;D:\Repository\com\fasterxml\jackson\core\jackson-core\2.6.5\jackson-core-2.6.5.jar;D:\Repository\com\fasterxml\jackson\module\jackson-module-scala_2.11\2.6.5\jackson-module-scala_2.11-2.6.5.jar;D:\Repository\org\scala-lang\scala-reflect\2.11.7\scala-reflect-2.11.7.jar;D:\Repository\com\fasterxml\jackson\module\jackson-module-paranamer\2.6.5\jackson-module-paranamer-2.6.5.jar;D:\Repository\org\apache\ivy\ivy\2.4.0\ivy-2.4.0.jar;D:\Repository\oro\oro\2.0.8\oro-2.0.8.jar;D:\Repository\net\razorvine\pyrolite\4.13\pyrolite-4.13.jar;D:\Repository\net\sf\py4j\py4j\0.10.4\py4j-0.10.4.jar;D:\Repository\org\apache\spark\spark-tags_2.11\2.1.0\spark-tags_2.11-2.1.0.jar;D:\Repository\org\scalatest\scalatest_2.11\2.2.6\scalatest_2.11-2.2.6.jar;D:\Repository\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;D:\Repository\org\spark-project\spark\unused\1.0.0\unused-1.0.0.jar;D:\Repository\org\apache\spark\spark-streaming_2.11\2.1.0\spark-streaming_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-sql_2.11\2.1.0\spark-sql_2.11-2.1.0.jar;D:\Repository\com\univocity\univocity-parsers\2.2.1\univocity-parsers-2.2.1.jar;D:\Repository\org\apache\spark\spark-sketch_2.11\2.1.0\spark-sketch_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-catalyst_2.11\2.1.0\spark-catalyst_2.11-2.1.0.jar;D:\Repository\org\codehaus\janino\janino\3.0.0\janino-3.0.0.jar;D:\Repository\org\codehaus\janino\commons-compiler\3.0.0\commons-compiler-3.0.0.jar;D:\Repository\org\antlr\antlr4-runtime\4.5.3\antlr4-runtime-4.5.3.jar;D:\Repository\org\apache\parquet\parquet-column\1.8.1\parquet-column-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-common\1.8.1\parquet-common-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-encoding\1.8.1\parquet-encoding-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-hadoop\1.8.1\parquet-hadoop-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-format\2.3.0-incubating\parquet-format-2.3.0-incubating.jar;D:\Repository\org\apache\parquet\parquet-jackson\1.8.1\parquet-jackson-1.8.1.jar;D:\Repository\org\apache\hadoop\hadoop-client\2.6.5\hadoop-client-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-common\2.6.5\hadoop-common-2.6.5.jar;D:\Repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;D:\Repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;D:\Repository\commons-io\commons-io\2.4\commons-io-2.4.jar;D:\Repository\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;D:\Repository\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;D:\Repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\Repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;D:\Repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;D:\Repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;D:\Repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;D:\Repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;D:\Repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;D:\Repository\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;D:\Repository\org\apache\hadoop\hadoop-auth\2.6.5\hadoop-auth-2.6.5.jar;D:\Repository\org\apache\httpcomponents\httpclient\4.2.5\httpclient-4.2.5.jar;D:\Repository\org\apache\httpcomponents\httpcore\4.2.4\httpcore-4.2.4.jar;D:\Repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;D:\Repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;D:\Repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;D:\Repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;D:\Repository\org\apache\curator\curator-client\2.6.0\curator-client-2.6.0.jar;D:\Repository\org\htrace\htrace-core\3.0.4\htrace-core-3.0.4.jar;D:\Repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;D:\Repository\org\tukaani\xz\1.0\xz-1.0.jar;D:\Repository\org\apache\hadoop\hadoop-hdfs\2.6.5\hadoop-hdfs-2.6.5.jar;D:\Repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;D:\Repository\xerces\xercesImpl\2.9.1\xercesImpl-2.9.1.jar;D:\Repository\xml-apis\xml-apis\1.3.04\xml-apis-1.3.04.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.6.5\hadoop-mapreduce-client-app-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.6.5\hadoop-mapreduce-client-common-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-client\2.6.5\hadoop-yarn-client-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-server-common\2.6.5\hadoop-yarn-server-common-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.6.5\hadoop-mapreduce-client-shuffle-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-api\2.6.5\hadoop-yarn-api-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.6.5\hadoop-mapreduce-client-core-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-common\2.6.5\hadoop-yarn-common-2.6.5.jar;D:\Repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;D:\Repository\javax\xml\stream\stax-api\1.0-2\stax-api-1.0-2.jar;D:\Repository\javax\activation\activation\1.1\activation-1.1.jar;D:\Repository\javax\servlet\servlet-api\2.5\servlet-api-2.5.jar;D:\Repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;D:\Repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;D:\Repository\org\codehaus\jackson\jackson-jaxrs\1.9.13\jackson-jaxrs-1.9.13.jar;D:\Repository\org\codehaus\jackson\jackson-xc\1.9.13\jackson-xc-1.9.13.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.6.5\hadoop-mapreduce-client-jobclient-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-annotations\2.6.5\hadoop-annotations-2.6.5.jar;D:\Repository\org\apache\kafka\kafka-clients\0.8.2.2\kafka-clients-0.8.2.2.jar;D:\Repository\org\apache\kafka\kafka_2.11\0.8.2.2\kafka_2.11-0.8.2.2.jar;D:\Repository\org\scala-lang\modules\scala-xml_2.11\1.0.2\scala-xml_2.11-1.0.2.jar;D:\Repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;D:\Repository\net\sf\jopt-simple\jopt-simple\3.2\jopt-simple-3.2.jar;D:\Repository\org\scala-lang\modules\scala-parser-combinators_2.11\1.0.2\scala-parser-combinators_2.11-1.0.2.jar;D:\Repository\com\101tec\zkclient\0.3\zkclient-0.3.jar;D:\Repository\mysql\mysql-connector-java\5.1.38\mysql-connector-java-5.1.38.jar;D:\Repository\org\apache\spark\spark-streaming-kafka-0-8_2.11\2.1.0\spark-streaming-kafka-0-8_2.11-2.1.0.jar;D:\Repository\org\apache\zookeeper\zookeeper\3.4.10\zookeeper-3.4.10.jar;D:\Repository\jline\jline\0.9.94\jline-0.9.94.jar;D:\developTools\IntelliJ IDEA 2018.2.3\lib\idea_rt.jar
2018-12-26 15:49:28 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_171\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;D:\developTools\Git\cmd;D:\developTools\svn\bin;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\scala\bin;C:\Users\junmei02\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk1.8.0_171\bin;D:\developTools\apache-maven-3.5.2\bin;D:\developTools\mysql-5.6.27-winx64\bin;D:\developTools\Git\cmd;D:\hadoop\hadoop-common-2.2.0-bin-master\bin;D:\hadoop\hbase-1.2.6\bin;C:\Program Files (x86)\scala\bin;D:\bigdata\zookeeper-3.4.10\bin;;.
2018-12-26 15:49:28 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.io.tmpdir=C:\Users\junmei02\AppData\Local\Temp\
2018-12-26 15:49:28 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.compiler=<NA>
2018-12-26 15:49:28 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.name=Windows 10
2018-12-26 15:49:28 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.arch=amd64
2018-12-26 15:49:28 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.version=10.0
2018-12-26 15:49:28 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.name=junmei02
2018-12-26 15:49:28 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.home=C:\Users\junmei02
2018-12-26 15:49:28 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.dir=D:\springbootworkspace\spark
2018-12-26 15:49:28 [ INFO ] - [ org.apache.zookeeper.ZooKeeper.<init>(ZooKeeper.java:438) ] Initiating client connection, connectString=127.0.0.1:2181 sessionTimeout=10000 watcher=org.apache.curator.ConnectionState@2034b64c
2018-12-26 15:49:28 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:1032) ] Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2018-12-26 15:49:28 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$SendThread.primeConnection(ClientCnxn.java:876) ] Socket connection established to 127.0.0.1/127.0.0.1:2181, initiating session
2018-12-26 15:49:28 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$SendThread.onConnected(ClientCnxn.java:1299) ] Session establishment complete on server 127.0.0.1/127.0.0.1:2181, sessionid = 0x167e951e94d0006, negotiated timeout = 10000
2018-12-26 15:49:28 [ INFO ] - [ org.apache.curator.framework.state.ConnectionStateManager.postState(ConnectionStateManager.java:194) ] State change: CONNECTED
2018-12-26 15:49:28 [ WARN ] - [ org.apache.curator.framework.state.ConnectionStateManager.processEvents(ConnectionStateManager.java:212) ] There are no ConnectionStateListeners registered.
2018-12-26 15:49:29 [ INFO ] - [ org.apache.zookeeper.ZooKeeper.close(ZooKeeper.java:684) ] Session: 0x167e951e94d0006 closed
2018-12-26 15:49:29 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:519) ] EventThread shut down for session: 0x167e951e94d0006
2018-12-26 15:49:30 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Running Spark version 2.1.0
2018-12-26 15:49:30 [ ERROR ] - [ org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:396) ] Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2373)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2373)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2373)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:837)
	at org.apache.spark.streaming.StreamingContext.<init>(StreamingContext.scala:84)
	at org.apache.spark.streaming.api.java.JavaStreamingContext.<init>(JavaStreamingContext.scala:138)
	at com.zqg.StreamKafka.KafkaSparkStreamingWithZookeeperoffset.main(KafkaSparkStreamingWithZookeeperoffset.java:67)
2018-12-26 15:49:31 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing view acls to: junmei02
2018-12-26 15:49:31 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing modify acls to: junmei02
2018-12-26 15:49:31 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing view acls groups to: 
2018-12-26 15:49:31 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing modify acls groups to: 
2018-12-26 15:49:31 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(junmei02); groups with view permissions: Set(); users  with modify permissions: Set(junmei02); groups with modify permissions: Set()
2018-12-26 15:49:31 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'sparkDriver' on port 53932.
2018-12-26 15:49:31 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering MapOutputTracker
2018-12-26 15:49:31 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering BlockManagerMaster
2018-12-26 15:49:31 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-26 15:49:31 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] BlockManagerMasterEndpoint up
2018-12-26 15:49:31 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Created local directory at C:\Users\junmei02\AppData\Local\Temp\blockmgr-3c6382f8-d750-4d04-9e5e-7d98ac23ab8e
2018-12-26 15:49:31 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] MemoryStore started with capacity 900.6 MB
2018-12-26 15:49:31 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering OutputCommitCoordinator
2018-12-26 15:49:31 [ INFO ] - [ org.spark_project.jetty.util.log.Log.initialized(Log.java:186) ] Logging initialized @4480ms
2018-12-26 15:49:31 [ INFO ] - [ org.spark_project.jetty.server.Server.doStart(Server.java:327) ] jetty-9.2.z-SNAPSHOT
2018-12-26 15:49:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@7fcff1b9{/jobs,null,AVAILABLE}
2018-12-26 15:49:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@697446d4{/jobs/json,null,AVAILABLE}
2018-12-26 15:49:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@76adb233{/jobs/job,null,AVAILABLE}
2018-12-26 15:49:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@36074e47{/jobs/job/json,null,AVAILABLE}
2018-12-26 15:49:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@36453307{/stages,null,AVAILABLE}
2018-12-26 15:49:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@7dcc91fd{/stages/json,null,AVAILABLE}
2018-12-26 15:49:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@66eb985d{/stages/stage,null,AVAILABLE}
2018-12-26 15:49:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@6a9287b1{/stages/stage/json,null,AVAILABLE}
2018-12-26 15:49:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@75504cef{/stages/pool,null,AVAILABLE}
2018-12-26 15:49:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@6c8a68c1{/stages/pool/json,null,AVAILABLE}
2018-12-26 15:49:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@56193c7d{/storage,null,AVAILABLE}
2018-12-26 15:49:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@28c88600{/storage/json,null,AVAILABLE}
2018-12-26 15:49:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@5f8890c2{/storage/rdd,null,AVAILABLE}
2018-12-26 15:49:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@607b2792{/storage/rdd/json,null,AVAILABLE}
2018-12-26 15:49:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@7f9e1534{/environment,null,AVAILABLE}
2018-12-26 15:49:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@138a7441{/environment/json,null,AVAILABLE}
2018-12-26 15:49:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@81ff872{/executors,null,AVAILABLE}
2018-12-26 15:49:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@31611954{/executors/json,null,AVAILABLE}
2018-12-26 15:49:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@3e598df9{/executors/threadDump,null,AVAILABLE}
2018-12-26 15:49:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@7e31ce0f{/executors/threadDump/json,null,AVAILABLE}
2018-12-26 15:49:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@99a65d3{/static,null,AVAILABLE}
2018-12-26 15:49:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@3088660d{/,null,AVAILABLE}
2018-12-26 15:49:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@42cc13a0{/api,null,AVAILABLE}
2018-12-26 15:49:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@32fdec40{/jobs/job/kill,null,AVAILABLE}
2018-12-26 15:49:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@6813a331{/stages/stage/kill,null,AVAILABLE}
2018-12-26 15:49:31 [ INFO ] - [ org.spark_project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:266) ] Started ServerConnector@6622a690{HTTP/1.1}{0.0.0.0:4040}
2018-12-26 15:49:31 [ INFO ] - [ org.spark_project.jetty.server.Server.doStart(Server.java:379) ] Started @4637ms
2018-12-26 15:49:31 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'SparkUI' on port 4040.
2018-12-26 15:49:31 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Bound SparkUI to 0.0.0.0, and started at http://192.168.0.112:4040
2018-12-26 15:49:31 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Starting executor ID driver on host localhost
2018-12-26 15:49:31 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53953.
2018-12-26 15:49:31 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Server created on 192.168.0.112:53953
2018-12-26 15:49:31 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-26 15:49:31 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering BlockManager BlockManagerId(driver, 192.168.0.112, 53953, None)
2018-12-26 15:49:31 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering block manager 192.168.0.112:53953 with 900.6 MB RAM, BlockManagerId(driver, 192.168.0.112, 53953, None)
2018-12-26 15:49:31 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registered BlockManager BlockManagerId(driver, 192.168.0.112, 53953, None)
2018-12-26 15:49:31 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Initialized BlockManager: BlockManagerId(driver, 192.168.0.112, 53953, None)
2018-12-26 15:49:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@6b1e7ad3{/metrics/json,null,AVAILABLE}
2018-12-26 15:50:07 [ ERROR ] - [ org.apache.spark.internal.Logging$class.logError(Logging.scala:70) ] ArrayBuffer(java.nio.channels.ClosedChannelException)
2018-12-26 15:50:09 [ ERROR ] - [ org.apache.spark.internal.Logging$class.logError(Logging.scala:91) ] Error generating jobs for time 1545810605000 ms
org.apache.spark.SparkException: ArrayBuffer(java.nio.channels.ClosedChannelException)
	at org.apache.spark.streaming.kafka.DirectKafkaInputDStream.latestLeaderOffsets(DirectKafkaInputDStream.scala:133)
	at org.apache.spark.streaming.kafka.DirectKafkaInputDStream.compute(DirectKafkaInputDStream.scala:158)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1$$anonfun$apply$7.apply(DStream.scala:341)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1$$anonfun$apply$7.apply(DStream.scala:341)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1.apply(DStream.scala:340)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1.apply(DStream.scala:340)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:415)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1.apply(DStream.scala:335)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1.apply(DStream.scala:333)
	at scala.Option.orElse(Option.scala:289)
	at org.apache.spark.streaming.dstream.DStream.getOrCompute(DStream.scala:330)
	at org.apache.spark.streaming.dstream.TransformedDStream$$anonfun$6.apply(TransformedDStream.scala:42)
	at org.apache.spark.streaming.dstream.TransformedDStream$$anonfun$6.apply(TransformedDStream.scala:42)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.immutable.List.map(List.scala:285)
	at org.apache.spark.streaming.dstream.TransformedDStream.compute(TransformedDStream.scala:42)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1$$anonfun$apply$7.apply(DStream.scala:341)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1$$anonfun$apply$7.apply(DStream.scala:341)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1.apply(DStream.scala:340)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1.apply(DStream.scala:340)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:415)
	at org.apache.spark.streaming.dstream.TransformedDStream.createRDDWithLocalProperties(TransformedDStream.scala:65)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1.apply(DStream.scala:335)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1.apply(DStream.scala:333)
	at scala.Option.orElse(Option.scala:289)
	at org.apache.spark.streaming.dstream.DStream.getOrCompute(DStream.scala:330)
	at org.apache.spark.streaming.dstream.FlatMappedDStream.compute(FlatMappedDStream.scala:36)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1$$anonfun$apply$7.apply(DStream.scala:341)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1$$anonfun$apply$7.apply(DStream.scala:341)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1.apply(DStream.scala:340)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1.apply(DStream.scala:340)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:415)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1.apply(DStream.scala:335)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1.apply(DStream.scala:333)
	at scala.Option.orElse(Option.scala:289)
	at org.apache.spark.streaming.dstream.DStream.getOrCompute(DStream.scala:330)
	at org.apache.spark.streaming.dstream.MappedDStream.compute(MappedDStream.scala:36)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1$$anonfun$apply$7.apply(DStream.scala:341)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1$$anonfun$apply$7.apply(DStream.scala:341)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1.apply(DStream.scala:340)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1.apply(DStream.scala:340)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:415)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1.apply(DStream.scala:335)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1.apply(DStream.scala:333)
	at scala.Option.orElse(Option.scala:289)
	at org.apache.spark.streaming.dstream.DStream.getOrCompute(DStream.scala:330)
	at org.apache.spark.streaming.dstream.ForEachDStream.generateJob(ForEachDStream.scala:48)
	at org.apache.spark.streaming.DStreamGraph$$anonfun$1.apply(DStreamGraph.scala:117)
	at org.apache.spark.streaming.DStreamGraph$$anonfun$1.apply(DStreamGraph.scala:116)
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:104)
	at org.apache.spark.streaming.DStreamGraph.generateJobs(DStreamGraph.scala:116)
	at org.apache.spark.streaming.scheduler.JobGenerator$$anonfun$3.apply(JobGenerator.scala:249)
	at org.apache.spark.streaming.scheduler.JobGenerator$$anonfun$3.apply(JobGenerator.scala:247)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.streaming.scheduler.JobGenerator.generateJobs(JobGenerator.scala:247)
	at org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:183)
	at org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:89)
	at org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:88)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
2018-12-26 15:52:22 [ INFO ] - [ kafka.utils.Logging$class.info(Logging.scala:68) ] Reconnect due to socket error: java.nio.channels.ClosedChannelException
2018-12-26 16:10:17 [ INFO ] - [ org.apache.curator.framework.imps.CuratorFrameworkImpl.start(CuratorFrameworkImpl.java:223) ] Starting
2018-12-26 16:10:17 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT
2018-12-26 16:10:17 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:host.name=windows10.microdone.cn
2018-12-26 16:10:17 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.version=1.8.0_171
2018-12-26 16:10:17 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.vendor=Oracle Corporation
2018-12-26 16:10:17 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.home=C:\Program Files\Java\jdk1.8.0_171\jre
2018-12-26 16:10:17 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.class.path=C:\Program Files\Java\jdk1.8.0_171\jre\lib\charsets.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\deploy.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\access-bridge-64.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\cldrdata.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\dnsns.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\jaccess.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\jfxrt.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\localedata.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\nashorn.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunec.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunjce_provider.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunmscapi.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunpkcs11.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\zipfs.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\javaws.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jce.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jfr.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jfxswt.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jsse.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\management-agent.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\plugin.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\resources.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\rt.jar;D:\springbootworkspace\spark\target\classes;D:\Repository\org\scala-lang\scala-library\2.11.8\scala-library-2.11.8.jar;D:\Repository\org\apache\spark\spark-core_2.11\2.1.0\spark-core_2.11-2.1.0.jar;D:\Repository\org\apache\avro\avro-mapred\1.7.7\avro-mapred-1.7.7-hadoop2.jar;D:\Repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7.jar;D:\Repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7-tests.jar;D:\Repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;D:\Repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;D:\Repository\com\twitter\chill_2.11\0.8.0\chill_2.11-0.8.0.jar;D:\Repository\com\esotericsoftware\kryo-shaded\3.0.3\kryo-shaded-3.0.3.jar;D:\Repository\com\esotericsoftware\minlog\1.3.0\minlog-1.3.0.jar;D:\Repository\org\objenesis\objenesis\2.1\objenesis-2.1.jar;D:\Repository\com\twitter\chill-java\0.8.0\chill-java-0.8.0.jar;D:\Repository\org\apache\xbean\xbean-asm5-shaded\4.4\xbean-asm5-shaded-4.4.jar;D:\Repository\org\apache\spark\spark-launcher_2.11\2.1.0\spark-launcher_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-network-common_2.11\2.1.0\spark-network-common_2.11-2.1.0.jar;D:\Repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;D:\Repository\com\fasterxml\jackson\core\jackson-annotations\2.6.5\jackson-annotations-2.6.5.jar;D:\Repository\org\apache\spark\spark-network-shuffle_2.11\2.1.0\spark-network-shuffle_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-unsafe_2.11\2.1.0\spark-unsafe_2.11-2.1.0.jar;D:\Repository\net\java\dev\jets3t\jets3t\0.7.1\jets3t-0.7.1.jar;D:\Repository\commons-codec\commons-codec\1.3\commons-codec-1.3.jar;D:\Repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;D:\Repository\org\apache\curator\curator-recipes\2.4.0\curator-recipes-2.4.0.jar;D:\Repository\org\apache\curator\curator-framework\2.4.0\curator-framework-2.4.0.jar;D:\Repository\com\google\guava\guava\14.0.1\guava-14.0.1.jar;D:\Repository\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;D:\Repository\org\apache\commons\commons-lang3\3.5\commons-lang3-3.5.jar;D:\Repository\org\apache\commons\commons-math3\3.4.1\commons-math3-3.4.1.jar;D:\Repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;D:\Repository\org\slf4j\slf4j-api\1.7.16\slf4j-api-1.7.16.jar;D:\Repository\org\slf4j\jul-to-slf4j\1.7.16\jul-to-slf4j-1.7.16.jar;D:\Repository\org\slf4j\jcl-over-slf4j\1.7.16\jcl-over-slf4j-1.7.16.jar;D:\Repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;D:\Repository\org\slf4j\slf4j-log4j12\1.7.16\slf4j-log4j12-1.7.16.jar;D:\Repository\com\ning\compress-lzf\1.0.3\compress-lzf-1.0.3.jar;D:\Repository\org\xerial\snappy\snappy-java\1.1.2.6\snappy-java-1.1.2.6.jar;D:\Repository\net\jpountz\lz4\lz4\1.3.0\lz4-1.3.0.jar;D:\Repository\org\roaringbitmap\RoaringBitmap\0.5.11\RoaringBitmap-0.5.11.jar;D:\Repository\commons-net\commons-net\2.2\commons-net-2.2.jar;D:\Repository\org\json4s\json4s-jackson_2.11\3.2.11\json4s-jackson_2.11-3.2.11.jar;D:\Repository\org\json4s\json4s-core_2.11\3.2.11\json4s-core_2.11-3.2.11.jar;D:\Repository\org\json4s\json4s-ast_2.11\3.2.11\json4s-ast_2.11-3.2.11.jar;D:\Repository\com\thoughtworks\paranamer\paranamer\2.6\paranamer-2.6.jar;D:\Repository\org\scala-lang\scalap\2.11.0\scalap-2.11.0.jar;D:\Repository\org\scala-lang\scala-compiler\2.11.0\scala-compiler-2.11.0.jar;D:\Repository\org\glassfish\jersey\core\jersey-client\2.22.2\jersey-client-2.22.2.jar;D:\Repository\javax\ws\rs\javax.ws.rs-api\2.0.1\javax.ws.rs-api-2.0.1.jar;D:\Repository\org\glassfish\hk2\hk2-api\2.4.0-b34\hk2-api-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\hk2-utils\2.4.0-b34\hk2-utils-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\external\aopalliance-repackaged\2.4.0-b34\aopalliance-repackaged-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\external\javax.inject\2.4.0-b34\javax.inject-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\hk2-locator\2.4.0-b34\hk2-locator-2.4.0-b34.jar;D:\Repository\org\javassist\javassist\3.18.1-GA\javassist-3.18.1-GA.jar;D:\Repository\org\glassfish\jersey\core\jersey-common\2.22.2\jersey-common-2.22.2.jar;D:\Repository\javax\annotation\javax.annotation-api\1.2\javax.annotation-api-1.2.jar;D:\Repository\org\glassfish\jersey\bundles\repackaged\jersey-guava\2.22.2\jersey-guava-2.22.2.jar;D:\Repository\org\glassfish\hk2\osgi-resource-locator\1.0.1\osgi-resource-locator-1.0.1.jar;D:\Repository\org\glassfish\jersey\core\jersey-server\2.22.2\jersey-server-2.22.2.jar;D:\Repository\org\glassfish\jersey\media\jersey-media-jaxb\2.22.2\jersey-media-jaxb-2.22.2.jar;D:\Repository\javax\validation\validation-api\1.1.0.Final\validation-api-1.1.0.Final.jar;D:\Repository\org\glassfish\jersey\containers\jersey-container-servlet\2.22.2\jersey-container-servlet-2.22.2.jar;D:\Repository\org\glassfish\jersey\containers\jersey-container-servlet-core\2.22.2\jersey-container-servlet-core-2.22.2.jar;D:\Repository\io\netty\netty-all\4.0.42.Final\netty-all-4.0.42.Final.jar;D:\Repository\io\netty\netty\3.8.0.Final\netty-3.8.0.Final.jar;D:\Repository\com\clearspring\analytics\stream\2.7.0\stream-2.7.0.jar;D:\Repository\io\dropwizard\metrics\metrics-core\3.1.2\metrics-core-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-jvm\3.1.2\metrics-jvm-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-json\3.1.2\metrics-json-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-graphite\3.1.2\metrics-graphite-3.1.2.jar;D:\Repository\com\fasterxml\jackson\core\jackson-databind\2.6.5\jackson-databind-2.6.5.jar;D:\Repository\com\fasterxml\jackson\core\jackson-core\2.6.5\jackson-core-2.6.5.jar;D:\Repository\com\fasterxml\jackson\module\jackson-module-scala_2.11\2.6.5\jackson-module-scala_2.11-2.6.5.jar;D:\Repository\org\scala-lang\scala-reflect\2.11.7\scala-reflect-2.11.7.jar;D:\Repository\com\fasterxml\jackson\module\jackson-module-paranamer\2.6.5\jackson-module-paranamer-2.6.5.jar;D:\Repository\org\apache\ivy\ivy\2.4.0\ivy-2.4.0.jar;D:\Repository\oro\oro\2.0.8\oro-2.0.8.jar;D:\Repository\net\razorvine\pyrolite\4.13\pyrolite-4.13.jar;D:\Repository\net\sf\py4j\py4j\0.10.4\py4j-0.10.4.jar;D:\Repository\org\apache\spark\spark-tags_2.11\2.1.0\spark-tags_2.11-2.1.0.jar;D:\Repository\org\scalatest\scalatest_2.11\2.2.6\scalatest_2.11-2.2.6.jar;D:\Repository\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;D:\Repository\org\spark-project\spark\unused\1.0.0\unused-1.0.0.jar;D:\Repository\org\apache\spark\spark-streaming_2.11\2.1.0\spark-streaming_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-sql_2.11\2.1.0\spark-sql_2.11-2.1.0.jar;D:\Repository\com\univocity\univocity-parsers\2.2.1\univocity-parsers-2.2.1.jar;D:\Repository\org\apache\spark\spark-sketch_2.11\2.1.0\spark-sketch_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-catalyst_2.11\2.1.0\spark-catalyst_2.11-2.1.0.jar;D:\Repository\org\codehaus\janino\janino\3.0.0\janino-3.0.0.jar;D:\Repository\org\codehaus\janino\commons-compiler\3.0.0\commons-compiler-3.0.0.jar;D:\Repository\org\antlr\antlr4-runtime\4.5.3\antlr4-runtime-4.5.3.jar;D:\Repository\org\apache\parquet\parquet-column\1.8.1\parquet-column-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-common\1.8.1\parquet-common-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-encoding\1.8.1\parquet-encoding-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-hadoop\1.8.1\parquet-hadoop-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-format\2.3.0-incubating\parquet-format-2.3.0-incubating.jar;D:\Repository\org\apache\parquet\parquet-jackson\1.8.1\parquet-jackson-1.8.1.jar;D:\Repository\org\apache\hadoop\hadoop-client\2.6.5\hadoop-client-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-common\2.6.5\hadoop-common-2.6.5.jar;D:\Repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;D:\Repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;D:\Repository\commons-io\commons-io\2.4\commons-io-2.4.jar;D:\Repository\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;D:\Repository\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;D:\Repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\Repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;D:\Repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;D:\Repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;D:\Repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;D:\Repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;D:\Repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;D:\Repository\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;D:\Repository\org\apache\hadoop\hadoop-auth\2.6.5\hadoop-auth-2.6.5.jar;D:\Repository\org\apache\httpcomponents\httpclient\4.2.5\httpclient-4.2.5.jar;D:\Repository\org\apache\httpcomponents\httpcore\4.2.4\httpcore-4.2.4.jar;D:\Repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;D:\Repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;D:\Repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;D:\Repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;D:\Repository\org\apache\curator\curator-client\2.6.0\curator-client-2.6.0.jar;D:\Repository\org\htrace\htrace-core\3.0.4\htrace-core-3.0.4.jar;D:\Repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;D:\Repository\org\tukaani\xz\1.0\xz-1.0.jar;D:\Repository\org\apache\hadoop\hadoop-hdfs\2.6.5\hadoop-hdfs-2.6.5.jar;D:\Repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;D:\Repository\xerces\xercesImpl\2.9.1\xercesImpl-2.9.1.jar;D:\Repository\xml-apis\xml-apis\1.3.04\xml-apis-1.3.04.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.6.5\hadoop-mapreduce-client-app-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.6.5\hadoop-mapreduce-client-common-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-client\2.6.5\hadoop-yarn-client-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-server-common\2.6.5\hadoop-yarn-server-common-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.6.5\hadoop-mapreduce-client-shuffle-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-api\2.6.5\hadoop-yarn-api-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.6.5\hadoop-mapreduce-client-core-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-common\2.6.5\hadoop-yarn-common-2.6.5.jar;D:\Repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;D:\Repository\javax\xml\stream\stax-api\1.0-2\stax-api-1.0-2.jar;D:\Repository\javax\activation\activation\1.1\activation-1.1.jar;D:\Repository\javax\servlet\servlet-api\2.5\servlet-api-2.5.jar;D:\Repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;D:\Repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;D:\Repository\org\codehaus\jackson\jackson-jaxrs\1.9.13\jackson-jaxrs-1.9.13.jar;D:\Repository\org\codehaus\jackson\jackson-xc\1.9.13\jackson-xc-1.9.13.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.6.5\hadoop-mapreduce-client-jobclient-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-annotations\2.6.5\hadoop-annotations-2.6.5.jar;D:\Repository\org\apache\kafka\kafka-clients\0.8.2.2\kafka-clients-0.8.2.2.jar;D:\Repository\org\apache\kafka\kafka_2.11\0.8.2.2\kafka_2.11-0.8.2.2.jar;D:\Repository\org\scala-lang\modules\scala-xml_2.11\1.0.2\scala-xml_2.11-1.0.2.jar;D:\Repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;D:\Repository\net\sf\jopt-simple\jopt-simple\3.2\jopt-simple-3.2.jar;D:\Repository\org\scala-lang\modules\scala-parser-combinators_2.11\1.0.2\scala-parser-combinators_2.11-1.0.2.jar;D:\Repository\com\101tec\zkclient\0.3\zkclient-0.3.jar;D:\Repository\mysql\mysql-connector-java\5.1.38\mysql-connector-java-5.1.38.jar;D:\Repository\org\apache\spark\spark-streaming-kafka-0-8_2.11\2.1.0\spark-streaming-kafka-0-8_2.11-2.1.0.jar;D:\Repository\org\apache\zookeeper\zookeeper\3.4.10\zookeeper-3.4.10.jar;D:\Repository\jline\jline\0.9.94\jline-0.9.94.jar;D:\developTools\IntelliJ IDEA 2018.2.3\lib\idea_rt.jar
2018-12-26 16:10:17 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_171\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;D:\developTools\Git\cmd;D:\developTools\svn\bin;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\scala\bin;C:\Users\junmei02\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk1.8.0_171\bin;D:\developTools\apache-maven-3.5.2\bin;D:\developTools\mysql-5.6.27-winx64\bin;D:\developTools\Git\cmd;D:\hadoop\hadoop-common-2.2.0-bin-master\bin;D:\hadoop\hbase-1.2.6\bin;C:\Program Files (x86)\scala\bin;D:\bigdata\zookeeper-3.4.10\bin;;.
2018-12-26 16:10:17 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.io.tmpdir=C:\Users\junmei02\AppData\Local\Temp\
2018-12-26 16:10:17 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.compiler=<NA>
2018-12-26 16:10:17 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.name=Windows 10
2018-12-26 16:10:17 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.arch=amd64
2018-12-26 16:10:17 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.version=10.0
2018-12-26 16:10:17 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.name=junmei02
2018-12-26 16:10:17 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.home=C:\Users\junmei02
2018-12-26 16:10:17 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.dir=D:\springbootworkspace\spark
2018-12-26 16:10:17 [ INFO ] - [ org.apache.zookeeper.ZooKeeper.<init>(ZooKeeper.java:438) ] Initiating client connection, connectString=127.0.0.1:2181 sessionTimeout=10000 watcher=org.apache.curator.ConnectionState@2034b64c
2018-12-26 16:10:18 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:1032) ] Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2018-12-26 16:10:18 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$SendThread.primeConnection(ClientCnxn.java:876) ] Socket connection established to 127.0.0.1/127.0.0.1:2181, initiating session
2018-12-26 16:10:19 [ ERROR ] - [ org.apache.curator.ConnectionState.checkTimeouts(ConnectionState.java:201) ] Connection timed out for connection string (127.0.0.1:2181) and timeout (1000) / elapsed (1304)
org.apache.curator.CuratorConnectionLossException: KeeperErrorCode = ConnectionLoss
	at org.apache.curator.ConnectionState.checkTimeouts(ConnectionState.java:198)
	at org.apache.curator.ConnectionState.getZooKeeper(ConnectionState.java:88)
	at org.apache.curator.CuratorZookeeperClient.getZooKeeper(CuratorZookeeperClient.java:115)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.getZooKeeper(CuratorFrameworkImpl.java:457)
	at org.apache.curator.framework.imps.ExistsBuilderImpl$2.call(ExistsBuilderImpl.java:172)
	at org.apache.curator.framework.imps.ExistsBuilderImpl$2.call(ExistsBuilderImpl.java:161)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.ExistsBuilderImpl.pathInForeground(ExistsBuilderImpl.java:157)
	at org.apache.curator.framework.imps.ExistsBuilderImpl.forPath(ExistsBuilderImpl.java:148)
	at org.apache.curator.framework.imps.ExistsBuilderImpl.forPath(ExistsBuilderImpl.java:36)
	at com.zqg.StreamKafka.getOffset.GetTopicOffsetFromZookeeper.getConsumerOffsets(GetTopicOffsetFromZookeeper.java:31)
	at com.zqg.StreamKafka.KafkaSparkStreamingWithZookeeperoffset.main(KafkaSparkStreamingWithZookeeperoffset.java:39)
2018-12-26 16:10:28 [ WARN ] - [ org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1108) ] Client session timed out, have not heard from server in 10000ms for sessionid 0x0
2018-12-26 16:10:28 [ INFO ] - [ org.apache.zookeeper.ZooKeeper.close(ZooKeeper.java:684) ] Session: 0x0 closed
2018-12-26 16:10:28 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:519) ] EventThread shut down for session: 0x0
2018-12-26 16:10:29 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Running Spark version 2.1.0
2018-12-26 16:10:29 [ ERROR ] - [ org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:396) ] Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2373)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2373)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2373)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:837)
	at org.apache.spark.streaming.StreamingContext.<init>(StreamingContext.scala:84)
	at org.apache.spark.streaming.api.java.JavaStreamingContext.<init>(JavaStreamingContext.scala:138)
	at com.zqg.StreamKafka.KafkaSparkStreamingWithZookeeperoffset.main(KafkaSparkStreamingWithZookeeperoffset.java:67)
2018-12-26 16:10:29 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing view acls to: junmei02
2018-12-26 16:10:29 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing modify acls to: junmei02
2018-12-26 16:10:29 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing view acls groups to: 
2018-12-26 16:10:29 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing modify acls groups to: 
2018-12-26 16:10:29 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(junmei02); groups with view permissions: Set(); users  with modify permissions: Set(junmei02); groups with modify permissions: Set()
2018-12-26 16:10:29 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'sparkDriver' on port 54664.
2018-12-26 16:10:29 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering MapOutputTracker
2018-12-26 16:10:30 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering BlockManagerMaster
2018-12-26 16:10:30 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-26 16:10:30 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] BlockManagerMasterEndpoint up
2018-12-26 16:10:30 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Created local directory at C:\Users\junmei02\AppData\Local\Temp\blockmgr-2c447f2c-62c1-4fae-a252-57a8badd92ed
2018-12-26 16:10:30 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] MemoryStore started with capacity 900.6 MB
2018-12-26 16:10:30 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering OutputCommitCoordinator
2018-12-26 16:10:30 [ INFO ] - [ org.spark_project.jetty.util.log.Log.initialized(Log.java:186) ] Logging initialized @13612ms
2018-12-26 16:10:30 [ INFO ] - [ org.spark_project.jetty.server.Server.doStart(Server.java:327) ] jetty-9.2.z-SNAPSHOT
2018-12-26 16:10:30 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@4b61d0c6{/jobs,null,AVAILABLE}
2018-12-26 16:10:30 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@6f815e7f{/jobs/json,null,AVAILABLE}
2018-12-26 16:10:30 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@65e7f52a{/jobs/job,null,AVAILABLE}
2018-12-26 16:10:30 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@304b9f1a{/jobs/job/json,null,AVAILABLE}
2018-12-26 16:10:30 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@75699e35{/stages,null,AVAILABLE}
2018-12-26 16:10:30 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@107e5441{/stages/json,null,AVAILABLE}
2018-12-26 16:10:30 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@4aeaadc1{/stages/stage,null,AVAILABLE}
2018-12-26 16:10:30 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@263558c9{/stages/stage/json,null,AVAILABLE}
2018-12-26 16:10:30 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@1f14f20c{/stages/pool,null,AVAILABLE}
2018-12-26 16:10:30 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@7daa61f3{/stages/pool/json,null,AVAILABLE}
2018-12-26 16:10:30 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@62315f22{/storage,null,AVAILABLE}
2018-12-26 16:10:30 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@6e4ea0bd{/storage/json,null,AVAILABLE}
2018-12-26 16:10:30 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@56f2bbea{/storage/rdd,null,AVAILABLE}
2018-12-26 16:10:30 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@78f9ed3e{/storage/rdd/json,null,AVAILABLE}
2018-12-26 16:10:30 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@1059754c{/environment,null,AVAILABLE}
2018-12-26 16:10:30 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@b0964b2{/environment/json,null,AVAILABLE}
2018-12-26 16:10:30 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@48e7b3d2{/executors,null,AVAILABLE}
2018-12-26 16:10:30 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@7f4037ed{/executors/json,null,AVAILABLE}
2018-12-26 16:10:30 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@24e8de5c{/executors/threadDump,null,AVAILABLE}
2018-12-26 16:10:30 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@64040287{/executors/threadDump/json,null,AVAILABLE}
2018-12-26 16:10:30 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@110844f6{/static,null,AVAILABLE}
2018-12-26 16:10:30 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@6f89f665{/,null,AVAILABLE}
2018-12-26 16:10:30 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@df1cff6{/api,null,AVAILABLE}
2018-12-26 16:10:30 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@4925f4f5{/jobs/job/kill,null,AVAILABLE}
2018-12-26 16:10:30 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@1ad926d3{/stages/stage/kill,null,AVAILABLE}
2018-12-26 16:10:30 [ INFO ] - [ org.spark_project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:266) ] Started ServerConnector@3e521715{HTTP/1.1}{0.0.0.0:4040}
2018-12-26 16:10:30 [ INFO ] - [ org.spark_project.jetty.server.Server.doStart(Server.java:379) ] Started @13807ms
2018-12-26 16:10:30 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'SparkUI' on port 4040.
2018-12-26 16:10:30 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Bound SparkUI to 0.0.0.0, and started at http://192.168.0.112:4040
2018-12-26 16:10:30 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Starting executor ID driver on host localhost
2018-12-26 16:10:30 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54685.
2018-12-26 16:10:30 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Server created on 192.168.0.112:54685
2018-12-26 16:10:30 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-26 16:10:30 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering BlockManager BlockManagerId(driver, 192.168.0.112, 54685, None)
2018-12-26 16:10:30 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering block manager 192.168.0.112:54685 with 900.6 MB RAM, BlockManagerId(driver, 192.168.0.112, 54685, None)
2018-12-26 16:10:30 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registered BlockManager BlockManagerId(driver, 192.168.0.112, 54685, None)
2018-12-26 16:10:30 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Initialized BlockManager: BlockManagerId(driver, 192.168.0.112, 54685, None)
2018-12-26 16:10:30 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@1e6308a9{/metrics/json,null,AVAILABLE}
2018-12-26 16:10:35 [ ERROR ] - [ org.apache.spark.internal.Logging$class.logError(Logging.scala:70) ] ArrayBuffer(org.apache.spark.SparkException: Couldn't find leader offsets for Set())
2018-12-26 16:10:35 [ ERROR ] - [ org.apache.spark.internal.Logging$class.logError(Logging.scala:91) ] Error generating jobs for time 1545811835000 ms
org.apache.spark.SparkException: ArrayBuffer(org.apache.spark.SparkException: Couldn't find leader offsets for Set())
	at org.apache.spark.streaming.kafka.DirectKafkaInputDStream.latestLeaderOffsets(DirectKafkaInputDStream.scala:133)
	at org.apache.spark.streaming.kafka.DirectKafkaInputDStream.compute(DirectKafkaInputDStream.scala:158)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1$$anonfun$apply$7.apply(DStream.scala:341)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1$$anonfun$apply$7.apply(DStream.scala:341)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1.apply(DStream.scala:340)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1.apply(DStream.scala:340)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:415)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1.apply(DStream.scala:335)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1.apply(DStream.scala:333)
	at scala.Option.orElse(Option.scala:289)
	at org.apache.spark.streaming.dstream.DStream.getOrCompute(DStream.scala:330)
	at org.apache.spark.streaming.dstream.TransformedDStream$$anonfun$6.apply(TransformedDStream.scala:42)
	at org.apache.spark.streaming.dstream.TransformedDStream$$anonfun$6.apply(TransformedDStream.scala:42)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.immutable.List.map(List.scala:285)
	at org.apache.spark.streaming.dstream.TransformedDStream.compute(TransformedDStream.scala:42)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1$$anonfun$apply$7.apply(DStream.scala:341)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1$$anonfun$apply$7.apply(DStream.scala:341)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1.apply(DStream.scala:340)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1.apply(DStream.scala:340)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:415)
	at org.apache.spark.streaming.dstream.TransformedDStream.createRDDWithLocalProperties(TransformedDStream.scala:65)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1.apply(DStream.scala:335)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1.apply(DStream.scala:333)
	at scala.Option.orElse(Option.scala:289)
	at org.apache.spark.streaming.dstream.DStream.getOrCompute(DStream.scala:330)
	at org.apache.spark.streaming.dstream.FlatMappedDStream.compute(FlatMappedDStream.scala:36)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1$$anonfun$apply$7.apply(DStream.scala:341)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1$$anonfun$apply$7.apply(DStream.scala:341)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1.apply(DStream.scala:340)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1.apply(DStream.scala:340)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:415)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1.apply(DStream.scala:335)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1.apply(DStream.scala:333)
	at scala.Option.orElse(Option.scala:289)
	at org.apache.spark.streaming.dstream.DStream.getOrCompute(DStream.scala:330)
	at org.apache.spark.streaming.dstream.MappedDStream.compute(MappedDStream.scala:36)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1$$anonfun$apply$7.apply(DStream.scala:341)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1$$anonfun$apply$7.apply(DStream.scala:341)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1.apply(DStream.scala:340)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1.apply(DStream.scala:340)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:415)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1.apply(DStream.scala:335)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1.apply(DStream.scala:333)
	at scala.Option.orElse(Option.scala:289)
	at org.apache.spark.streaming.dstream.DStream.getOrCompute(DStream.scala:330)
	at org.apache.spark.streaming.dstream.ForEachDStream.generateJob(ForEachDStream.scala:48)
	at org.apache.spark.streaming.DStreamGraph$$anonfun$1.apply(DStreamGraph.scala:117)
	at org.apache.spark.streaming.DStreamGraph$$anonfun$1.apply(DStreamGraph.scala:116)
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:104)
	at org.apache.spark.streaming.DStreamGraph.generateJobs(DStreamGraph.scala:116)
	at org.apache.spark.streaming.scheduler.JobGenerator$$anonfun$3.apply(JobGenerator.scala:249)
	at org.apache.spark.streaming.scheduler.JobGenerator$$anonfun$3.apply(JobGenerator.scala:247)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.streaming.scheduler.JobGenerator.generateJobs(JobGenerator.scala:247)
	at org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:183)
	at org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:89)
	at org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:88)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
2018-12-26 16:14:15 [ INFO ] - [ org.apache.curator.framework.imps.CuratorFrameworkImpl.start(CuratorFrameworkImpl.java:223) ] Starting
2018-12-26 16:14:15 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT
2018-12-26 16:14:15 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:host.name=windows10.microdone.cn
2018-12-26 16:14:15 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.version=1.8.0_171
2018-12-26 16:14:15 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.vendor=Oracle Corporation
2018-12-26 16:14:15 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.home=C:\Program Files\Java\jdk1.8.0_171\jre
2018-12-26 16:14:15 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.class.path=C:\Program Files\Java\jdk1.8.0_171\jre\lib\charsets.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\deploy.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\access-bridge-64.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\cldrdata.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\dnsns.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\jaccess.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\jfxrt.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\localedata.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\nashorn.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunec.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunjce_provider.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunmscapi.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunpkcs11.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\zipfs.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\javaws.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jce.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jfr.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jfxswt.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jsse.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\management-agent.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\plugin.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\resources.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\rt.jar;D:\springbootworkspace\spark\target\classes;D:\Repository\org\scala-lang\scala-library\2.11.8\scala-library-2.11.8.jar;D:\Repository\org\apache\spark\spark-core_2.11\2.1.0\spark-core_2.11-2.1.0.jar;D:\Repository\org\apache\avro\avro-mapred\1.7.7\avro-mapred-1.7.7-hadoop2.jar;D:\Repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7.jar;D:\Repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7-tests.jar;D:\Repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;D:\Repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;D:\Repository\com\twitter\chill_2.11\0.8.0\chill_2.11-0.8.0.jar;D:\Repository\com\esotericsoftware\kryo-shaded\3.0.3\kryo-shaded-3.0.3.jar;D:\Repository\com\esotericsoftware\minlog\1.3.0\minlog-1.3.0.jar;D:\Repository\org\objenesis\objenesis\2.1\objenesis-2.1.jar;D:\Repository\com\twitter\chill-java\0.8.0\chill-java-0.8.0.jar;D:\Repository\org\apache\xbean\xbean-asm5-shaded\4.4\xbean-asm5-shaded-4.4.jar;D:\Repository\org\apache\spark\spark-launcher_2.11\2.1.0\spark-launcher_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-network-common_2.11\2.1.0\spark-network-common_2.11-2.1.0.jar;D:\Repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;D:\Repository\com\fasterxml\jackson\core\jackson-annotations\2.6.5\jackson-annotations-2.6.5.jar;D:\Repository\org\apache\spark\spark-network-shuffle_2.11\2.1.0\spark-network-shuffle_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-unsafe_2.11\2.1.0\spark-unsafe_2.11-2.1.0.jar;D:\Repository\net\java\dev\jets3t\jets3t\0.7.1\jets3t-0.7.1.jar;D:\Repository\commons-codec\commons-codec\1.3\commons-codec-1.3.jar;D:\Repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;D:\Repository\org\apache\curator\curator-recipes\2.4.0\curator-recipes-2.4.0.jar;D:\Repository\org\apache\curator\curator-framework\2.4.0\curator-framework-2.4.0.jar;D:\Repository\com\google\guava\guava\14.0.1\guava-14.0.1.jar;D:\Repository\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;D:\Repository\org\apache\commons\commons-lang3\3.5\commons-lang3-3.5.jar;D:\Repository\org\apache\commons\commons-math3\3.4.1\commons-math3-3.4.1.jar;D:\Repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;D:\Repository\org\slf4j\slf4j-api\1.7.16\slf4j-api-1.7.16.jar;D:\Repository\org\slf4j\jul-to-slf4j\1.7.16\jul-to-slf4j-1.7.16.jar;D:\Repository\org\slf4j\jcl-over-slf4j\1.7.16\jcl-over-slf4j-1.7.16.jar;D:\Repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;D:\Repository\org\slf4j\slf4j-log4j12\1.7.16\slf4j-log4j12-1.7.16.jar;D:\Repository\com\ning\compress-lzf\1.0.3\compress-lzf-1.0.3.jar;D:\Repository\org\xerial\snappy\snappy-java\1.1.2.6\snappy-java-1.1.2.6.jar;D:\Repository\net\jpountz\lz4\lz4\1.3.0\lz4-1.3.0.jar;D:\Repository\org\roaringbitmap\RoaringBitmap\0.5.11\RoaringBitmap-0.5.11.jar;D:\Repository\commons-net\commons-net\2.2\commons-net-2.2.jar;D:\Repository\org\json4s\json4s-jackson_2.11\3.2.11\json4s-jackson_2.11-3.2.11.jar;D:\Repository\org\json4s\json4s-core_2.11\3.2.11\json4s-core_2.11-3.2.11.jar;D:\Repository\org\json4s\json4s-ast_2.11\3.2.11\json4s-ast_2.11-3.2.11.jar;D:\Repository\com\thoughtworks\paranamer\paranamer\2.6\paranamer-2.6.jar;D:\Repository\org\scala-lang\scalap\2.11.0\scalap-2.11.0.jar;D:\Repository\org\scala-lang\scala-compiler\2.11.0\scala-compiler-2.11.0.jar;D:\Repository\org\glassfish\jersey\core\jersey-client\2.22.2\jersey-client-2.22.2.jar;D:\Repository\javax\ws\rs\javax.ws.rs-api\2.0.1\javax.ws.rs-api-2.0.1.jar;D:\Repository\org\glassfish\hk2\hk2-api\2.4.0-b34\hk2-api-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\hk2-utils\2.4.0-b34\hk2-utils-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\external\aopalliance-repackaged\2.4.0-b34\aopalliance-repackaged-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\external\javax.inject\2.4.0-b34\javax.inject-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\hk2-locator\2.4.0-b34\hk2-locator-2.4.0-b34.jar;D:\Repository\org\javassist\javassist\3.18.1-GA\javassist-3.18.1-GA.jar;D:\Repository\org\glassfish\jersey\core\jersey-common\2.22.2\jersey-common-2.22.2.jar;D:\Repository\javax\annotation\javax.annotation-api\1.2\javax.annotation-api-1.2.jar;D:\Repository\org\glassfish\jersey\bundles\repackaged\jersey-guava\2.22.2\jersey-guava-2.22.2.jar;D:\Repository\org\glassfish\hk2\osgi-resource-locator\1.0.1\osgi-resource-locator-1.0.1.jar;D:\Repository\org\glassfish\jersey\core\jersey-server\2.22.2\jersey-server-2.22.2.jar;D:\Repository\org\glassfish\jersey\media\jersey-media-jaxb\2.22.2\jersey-media-jaxb-2.22.2.jar;D:\Repository\javax\validation\validation-api\1.1.0.Final\validation-api-1.1.0.Final.jar;D:\Repository\org\glassfish\jersey\containers\jersey-container-servlet\2.22.2\jersey-container-servlet-2.22.2.jar;D:\Repository\org\glassfish\jersey\containers\jersey-container-servlet-core\2.22.2\jersey-container-servlet-core-2.22.2.jar;D:\Repository\io\netty\netty-all\4.0.42.Final\netty-all-4.0.42.Final.jar;D:\Repository\io\netty\netty\3.8.0.Final\netty-3.8.0.Final.jar;D:\Repository\com\clearspring\analytics\stream\2.7.0\stream-2.7.0.jar;D:\Repository\io\dropwizard\metrics\metrics-core\3.1.2\metrics-core-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-jvm\3.1.2\metrics-jvm-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-json\3.1.2\metrics-json-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-graphite\3.1.2\metrics-graphite-3.1.2.jar;D:\Repository\com\fasterxml\jackson\core\jackson-databind\2.6.5\jackson-databind-2.6.5.jar;D:\Repository\com\fasterxml\jackson\core\jackson-core\2.6.5\jackson-core-2.6.5.jar;D:\Repository\com\fasterxml\jackson\module\jackson-module-scala_2.11\2.6.5\jackson-module-scala_2.11-2.6.5.jar;D:\Repository\org\scala-lang\scala-reflect\2.11.7\scala-reflect-2.11.7.jar;D:\Repository\com\fasterxml\jackson\module\jackson-module-paranamer\2.6.5\jackson-module-paranamer-2.6.5.jar;D:\Repository\org\apache\ivy\ivy\2.4.0\ivy-2.4.0.jar;D:\Repository\oro\oro\2.0.8\oro-2.0.8.jar;D:\Repository\net\razorvine\pyrolite\4.13\pyrolite-4.13.jar;D:\Repository\net\sf\py4j\py4j\0.10.4\py4j-0.10.4.jar;D:\Repository\org\apache\spark\spark-tags_2.11\2.1.0\spark-tags_2.11-2.1.0.jar;D:\Repository\org\scalatest\scalatest_2.11\2.2.6\scalatest_2.11-2.2.6.jar;D:\Repository\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;D:\Repository\org\spark-project\spark\unused\1.0.0\unused-1.0.0.jar;D:\Repository\org\apache\spark\spark-streaming_2.11\2.1.0\spark-streaming_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-sql_2.11\2.1.0\spark-sql_2.11-2.1.0.jar;D:\Repository\com\univocity\univocity-parsers\2.2.1\univocity-parsers-2.2.1.jar;D:\Repository\org\apache\spark\spark-sketch_2.11\2.1.0\spark-sketch_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-catalyst_2.11\2.1.0\spark-catalyst_2.11-2.1.0.jar;D:\Repository\org\codehaus\janino\janino\3.0.0\janino-3.0.0.jar;D:\Repository\org\codehaus\janino\commons-compiler\3.0.0\commons-compiler-3.0.0.jar;D:\Repository\org\antlr\antlr4-runtime\4.5.3\antlr4-runtime-4.5.3.jar;D:\Repository\org\apache\parquet\parquet-column\1.8.1\parquet-column-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-common\1.8.1\parquet-common-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-encoding\1.8.1\parquet-encoding-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-hadoop\1.8.1\parquet-hadoop-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-format\2.3.0-incubating\parquet-format-2.3.0-incubating.jar;D:\Repository\org\apache\parquet\parquet-jackson\1.8.1\parquet-jackson-1.8.1.jar;D:\Repository\org\apache\hadoop\hadoop-client\2.6.5\hadoop-client-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-common\2.6.5\hadoop-common-2.6.5.jar;D:\Repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;D:\Repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;D:\Repository\commons-io\commons-io\2.4\commons-io-2.4.jar;D:\Repository\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;D:\Repository\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;D:\Repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\Repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;D:\Repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;D:\Repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;D:\Repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;D:\Repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;D:\Repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;D:\Repository\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;D:\Repository\org\apache\hadoop\hadoop-auth\2.6.5\hadoop-auth-2.6.5.jar;D:\Repository\org\apache\httpcomponents\httpclient\4.2.5\httpclient-4.2.5.jar;D:\Repository\org\apache\httpcomponents\httpcore\4.2.4\httpcore-4.2.4.jar;D:\Repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;D:\Repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;D:\Repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;D:\Repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;D:\Repository\org\apache\curator\curator-client\2.6.0\curator-client-2.6.0.jar;D:\Repository\org\htrace\htrace-core\3.0.4\htrace-core-3.0.4.jar;D:\Repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;D:\Repository\org\tukaani\xz\1.0\xz-1.0.jar;D:\Repository\org\apache\hadoop\hadoop-hdfs\2.6.5\hadoop-hdfs-2.6.5.jar;D:\Repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;D:\Repository\xerces\xercesImpl\2.9.1\xercesImpl-2.9.1.jar;D:\Repository\xml-apis\xml-apis\1.3.04\xml-apis-1.3.04.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.6.5\hadoop-mapreduce-client-app-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.6.5\hadoop-mapreduce-client-common-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-client\2.6.5\hadoop-yarn-client-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-server-common\2.6.5\hadoop-yarn-server-common-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.6.5\hadoop-mapreduce-client-shuffle-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-api\2.6.5\hadoop-yarn-api-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.6.5\hadoop-mapreduce-client-core-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-common\2.6.5\hadoop-yarn-common-2.6.5.jar;D:\Repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;D:\Repository\javax\xml\stream\stax-api\1.0-2\stax-api-1.0-2.jar;D:\Repository\javax\activation\activation\1.1\activation-1.1.jar;D:\Repository\javax\servlet\servlet-api\2.5\servlet-api-2.5.jar;D:\Repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;D:\Repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;D:\Repository\org\codehaus\jackson\jackson-jaxrs\1.9.13\jackson-jaxrs-1.9.13.jar;D:\Repository\org\codehaus\jackson\jackson-xc\1.9.13\jackson-xc-1.9.13.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.6.5\hadoop-mapreduce-client-jobclient-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-annotations\2.6.5\hadoop-annotations-2.6.5.jar;D:\Repository\org\apache\kafka\kafka-clients\0.8.2.2\kafka-clients-0.8.2.2.jar;D:\Repository\org\apache\kafka\kafka_2.11\0.8.2.2\kafka_2.11-0.8.2.2.jar;D:\Repository\org\scala-lang\modules\scala-xml_2.11\1.0.2\scala-xml_2.11-1.0.2.jar;D:\Repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;D:\Repository\net\sf\jopt-simple\jopt-simple\3.2\jopt-simple-3.2.jar;D:\Repository\org\scala-lang\modules\scala-parser-combinators_2.11\1.0.2\scala-parser-combinators_2.11-1.0.2.jar;D:\Repository\com\101tec\zkclient\0.3\zkclient-0.3.jar;D:\Repository\mysql\mysql-connector-java\5.1.38\mysql-connector-java-5.1.38.jar;D:\Repository\org\apache\spark\spark-streaming-kafka-0-8_2.11\2.1.0\spark-streaming-kafka-0-8_2.11-2.1.0.jar;D:\Repository\org\apache\zookeeper\zookeeper\3.4.10\zookeeper-3.4.10.jar;D:\Repository\jline\jline\0.9.94\jline-0.9.94.jar;D:\developTools\IntelliJ IDEA 2018.2.3\lib\idea_rt.jar
2018-12-26 16:14:15 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_171\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;D:\developTools\Git\cmd;D:\developTools\svn\bin;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\scala\bin;C:\Users\junmei02\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk1.8.0_171\bin;D:\developTools\apache-maven-3.5.2\bin;D:\developTools\mysql-5.6.27-winx64\bin;D:\developTools\Git\cmd;D:\hadoop\hadoop-common-2.2.0-bin-master\bin;D:\hadoop\hbase-1.2.6\bin;C:\Program Files (x86)\scala\bin;D:\bigdata\zookeeper-3.4.10\bin;;.
2018-12-26 16:14:15 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.io.tmpdir=C:\Users\junmei02\AppData\Local\Temp\
2018-12-26 16:14:15 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.compiler=<NA>
2018-12-26 16:14:15 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.name=Windows 10
2018-12-26 16:14:15 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.arch=amd64
2018-12-26 16:14:15 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.version=10.0
2018-12-26 16:14:15 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.name=junmei02
2018-12-26 16:14:15 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.home=C:\Users\junmei02
2018-12-26 16:14:15 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.dir=D:\springbootworkspace\spark
2018-12-26 16:14:15 [ INFO ] - [ org.apache.zookeeper.ZooKeeper.<init>(ZooKeeper.java:438) ] Initiating client connection, connectString=127.0.0.1:2181 sessionTimeout=10000 watcher=org.apache.curator.ConnectionState@2034b64c
2018-12-26 16:14:15 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:1032) ] Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2018-12-26 16:14:15 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$SendThread.primeConnection(ClientCnxn.java:876) ] Socket connection established to 127.0.0.1/127.0.0.1:2181, initiating session
2018-12-26 16:14:15 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$SendThread.onConnected(ClientCnxn.java:1299) ] Session establishment complete on server 127.0.0.1/127.0.0.1:2181, sessionid = 0x167e991b4b60002, negotiated timeout = 10000
2018-12-26 16:14:15 [ INFO ] - [ org.apache.curator.framework.state.ConnectionStateManager.postState(ConnectionStateManager.java:194) ] State change: CONNECTED
2018-12-26 16:14:15 [ WARN ] - [ org.apache.curator.framework.state.ConnectionStateManager.processEvents(ConnectionStateManager.java:212) ] There are no ConnectionStateListeners registered.
2018-12-26 16:14:16 [ INFO ] - [ org.apache.zookeeper.ZooKeeper.close(ZooKeeper.java:684) ] Session: 0x167e991b4b60002 closed
2018-12-26 16:14:16 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:519) ] EventThread shut down for session: 0x167e991b4b60002
2018-12-26 16:14:17 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Running Spark version 2.1.0
2018-12-26 16:14:18 [ ERROR ] - [ org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:396) ] Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2373)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2373)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2373)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:837)
	at org.apache.spark.streaming.StreamingContext.<init>(StreamingContext.scala:84)
	at org.apache.spark.streaming.api.java.JavaStreamingContext.<init>(JavaStreamingContext.scala:138)
	at com.zqg.StreamKafka.KafkaSparkStreamingWithZookeeperoffset.main(KafkaSparkStreamingWithZookeeperoffset.java:67)
2018-12-26 16:14:18 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing view acls to: junmei02
2018-12-26 16:14:18 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing modify acls to: junmei02
2018-12-26 16:14:18 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing view acls groups to: 
2018-12-26 16:14:18 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing modify acls groups to: 
2018-12-26 16:14:18 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(junmei02); groups with view permissions: Set(); users  with modify permissions: Set(junmei02); groups with modify permissions: Set()
2018-12-26 16:14:18 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'sparkDriver' on port 54791.
2018-12-26 16:14:18 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering MapOutputTracker
2018-12-26 16:14:18 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering BlockManagerMaster
2018-12-26 16:14:18 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-26 16:14:18 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] BlockManagerMasterEndpoint up
2018-12-26 16:14:18 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Created local directory at C:\Users\junmei02\AppData\Local\Temp\blockmgr-b6c26a04-f78a-4345-bb67-a682f0747cc1
2018-12-26 16:14:18 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] MemoryStore started with capacity 900.6 MB
2018-12-26 16:14:18 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering OutputCommitCoordinator
2018-12-26 16:14:18 [ INFO ] - [ org.spark_project.jetty.util.log.Log.initialized(Log.java:186) ] Logging initialized @4602ms
2018-12-26 16:14:19 [ INFO ] - [ org.spark_project.jetty.server.Server.doStart(Server.java:327) ] jetty-9.2.z-SNAPSHOT
2018-12-26 16:14:19 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@5f8890c2{/jobs,null,AVAILABLE}
2018-12-26 16:14:19 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@607b2792{/jobs/json,null,AVAILABLE}
2018-12-26 16:14:19 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@7f9e1534{/jobs/job,null,AVAILABLE}
2018-12-26 16:14:19 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@138a7441{/jobs/job/json,null,AVAILABLE}
2018-12-26 16:14:19 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@81ff872{/stages,null,AVAILABLE}
2018-12-26 16:14:19 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@31611954{/stages/json,null,AVAILABLE}
2018-12-26 16:14:19 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@3e598df9{/stages/stage,null,AVAILABLE}
2018-12-26 16:14:19 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@7e31ce0f{/stages/stage/json,null,AVAILABLE}
2018-12-26 16:14:19 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@99a65d3{/stages/pool,null,AVAILABLE}
2018-12-26 16:14:19 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@3088660d{/stages/pool/json,null,AVAILABLE}
2018-12-26 16:14:19 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@42cc13a0{/storage,null,AVAILABLE}
2018-12-26 16:14:19 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@32fdec40{/storage/json,null,AVAILABLE}
2018-12-26 16:14:19 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@6813a331{/storage/rdd,null,AVAILABLE}
2018-12-26 16:14:19 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@1bd81830{/storage/rdd/json,null,AVAILABLE}
2018-12-26 16:14:19 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@39ab59f8{/environment,null,AVAILABLE}
2018-12-26 16:14:19 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@64e92d61{/environment/json,null,AVAILABLE}
2018-12-26 16:14:19 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@111610e6{/executors,null,AVAILABLE}
2018-12-26 16:14:19 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@4ad4936c{/executors/json,null,AVAILABLE}
2018-12-26 16:14:19 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@29d37757{/executors/threadDump,null,AVAILABLE}
2018-12-26 16:14:19 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@4fcc529{/executors/threadDump/json,null,AVAILABLE}
2018-12-26 16:14:19 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@25cc7470{/static,null,AVAILABLE}
2018-12-26 16:14:19 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@4beddc56{/,null,AVAILABLE}
2018-12-26 16:14:19 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@79b663b3{/api,null,AVAILABLE}
2018-12-26 16:14:19 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@1b812421{/jobs/job/kill,null,AVAILABLE}
2018-12-26 16:14:19 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@5d28bcd5{/stages/stage/kill,null,AVAILABLE}
2018-12-26 16:14:19 [ INFO ] - [ org.spark_project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:266) ] Started ServerConnector@2e647e59{HTTP/1.1}{0.0.0.0:4040}
2018-12-26 16:14:19 [ INFO ] - [ org.spark_project.jetty.server.Server.doStart(Server.java:379) ] Started @4755ms
2018-12-26 16:14:19 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'SparkUI' on port 4040.
2018-12-26 16:14:19 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Bound SparkUI to 0.0.0.0, and started at http://192.168.0.112:4040
2018-12-26 16:14:19 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Starting executor ID driver on host localhost
2018-12-26 16:14:19 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54812.
2018-12-26 16:14:19 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Server created on 192.168.0.112:54812
2018-12-26 16:14:19 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-26 16:14:19 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering BlockManager BlockManagerId(driver, 192.168.0.112, 54812, None)
2018-12-26 16:14:19 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering block manager 192.168.0.112:54812 with 900.6 MB RAM, BlockManagerId(driver, 192.168.0.112, 54812, None)
2018-12-26 16:14:19 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registered BlockManager BlockManagerId(driver, 192.168.0.112, 54812, None)
2018-12-26 16:14:19 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Initialized BlockManager: BlockManagerId(driver, 192.168.0.112, 54812, None)
2018-12-26 16:14:19 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@6b1e7ad3{/metrics/json,null,AVAILABLE}
2018-12-26 16:14:45 [ INFO ] - [ org.apache.curator.framework.imps.CuratorFrameworkImpl.start(CuratorFrameworkImpl.java:223) ] Starting
2018-12-26 16:14:45 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT
2018-12-26 16:14:45 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:host.name=windows10.microdone.cn
2018-12-26 16:14:45 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.version=1.8.0_171
2018-12-26 16:14:45 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.vendor=Oracle Corporation
2018-12-26 16:14:45 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.home=C:\Program Files\Java\jdk1.8.0_171\jre
2018-12-26 16:14:45 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.class.path=C:\Program Files\Java\jdk1.8.0_171\jre\lib\charsets.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\deploy.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\access-bridge-64.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\cldrdata.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\dnsns.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\jaccess.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\jfxrt.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\localedata.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\nashorn.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunec.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunjce_provider.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunmscapi.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunpkcs11.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\zipfs.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\javaws.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jce.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jfr.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jfxswt.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jsse.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\management-agent.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\plugin.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\resources.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\rt.jar;D:\springbootworkspace\spark\target\classes;D:\Repository\org\scala-lang\scala-library\2.11.8\scala-library-2.11.8.jar;D:\Repository\org\apache\spark\spark-core_2.11\2.1.0\spark-core_2.11-2.1.0.jar;D:\Repository\org\apache\avro\avro-mapred\1.7.7\avro-mapred-1.7.7-hadoop2.jar;D:\Repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7.jar;D:\Repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7-tests.jar;D:\Repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;D:\Repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;D:\Repository\com\twitter\chill_2.11\0.8.0\chill_2.11-0.8.0.jar;D:\Repository\com\esotericsoftware\kryo-shaded\3.0.3\kryo-shaded-3.0.3.jar;D:\Repository\com\esotericsoftware\minlog\1.3.0\minlog-1.3.0.jar;D:\Repository\org\objenesis\objenesis\2.1\objenesis-2.1.jar;D:\Repository\com\twitter\chill-java\0.8.0\chill-java-0.8.0.jar;D:\Repository\org\apache\xbean\xbean-asm5-shaded\4.4\xbean-asm5-shaded-4.4.jar;D:\Repository\org\apache\spark\spark-launcher_2.11\2.1.0\spark-launcher_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-network-common_2.11\2.1.0\spark-network-common_2.11-2.1.0.jar;D:\Repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;D:\Repository\com\fasterxml\jackson\core\jackson-annotations\2.6.5\jackson-annotations-2.6.5.jar;D:\Repository\org\apache\spark\spark-network-shuffle_2.11\2.1.0\spark-network-shuffle_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-unsafe_2.11\2.1.0\spark-unsafe_2.11-2.1.0.jar;D:\Repository\net\java\dev\jets3t\jets3t\0.7.1\jets3t-0.7.1.jar;D:\Repository\commons-codec\commons-codec\1.3\commons-codec-1.3.jar;D:\Repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;D:\Repository\org\apache\curator\curator-recipes\2.4.0\curator-recipes-2.4.0.jar;D:\Repository\org\apache\curator\curator-framework\2.4.0\curator-framework-2.4.0.jar;D:\Repository\com\google\guava\guava\14.0.1\guava-14.0.1.jar;D:\Repository\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;D:\Repository\org\apache\commons\commons-lang3\3.5\commons-lang3-3.5.jar;D:\Repository\org\apache\commons\commons-math3\3.4.1\commons-math3-3.4.1.jar;D:\Repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;D:\Repository\org\slf4j\slf4j-api\1.7.16\slf4j-api-1.7.16.jar;D:\Repository\org\slf4j\jul-to-slf4j\1.7.16\jul-to-slf4j-1.7.16.jar;D:\Repository\org\slf4j\jcl-over-slf4j\1.7.16\jcl-over-slf4j-1.7.16.jar;D:\Repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;D:\Repository\org\slf4j\slf4j-log4j12\1.7.16\slf4j-log4j12-1.7.16.jar;D:\Repository\com\ning\compress-lzf\1.0.3\compress-lzf-1.0.3.jar;D:\Repository\org\xerial\snappy\snappy-java\1.1.2.6\snappy-java-1.1.2.6.jar;D:\Repository\net\jpountz\lz4\lz4\1.3.0\lz4-1.3.0.jar;D:\Repository\org\roaringbitmap\RoaringBitmap\0.5.11\RoaringBitmap-0.5.11.jar;D:\Repository\commons-net\commons-net\2.2\commons-net-2.2.jar;D:\Repository\org\json4s\json4s-jackson_2.11\3.2.11\json4s-jackson_2.11-3.2.11.jar;D:\Repository\org\json4s\json4s-core_2.11\3.2.11\json4s-core_2.11-3.2.11.jar;D:\Repository\org\json4s\json4s-ast_2.11\3.2.11\json4s-ast_2.11-3.2.11.jar;D:\Repository\com\thoughtworks\paranamer\paranamer\2.6\paranamer-2.6.jar;D:\Repository\org\scala-lang\scalap\2.11.0\scalap-2.11.0.jar;D:\Repository\org\scala-lang\scala-compiler\2.11.0\scala-compiler-2.11.0.jar;D:\Repository\org\glassfish\jersey\core\jersey-client\2.22.2\jersey-client-2.22.2.jar;D:\Repository\javax\ws\rs\javax.ws.rs-api\2.0.1\javax.ws.rs-api-2.0.1.jar;D:\Repository\org\glassfish\hk2\hk2-api\2.4.0-b34\hk2-api-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\hk2-utils\2.4.0-b34\hk2-utils-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\external\aopalliance-repackaged\2.4.0-b34\aopalliance-repackaged-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\external\javax.inject\2.4.0-b34\javax.inject-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\hk2-locator\2.4.0-b34\hk2-locator-2.4.0-b34.jar;D:\Repository\org\javassist\javassist\3.18.1-GA\javassist-3.18.1-GA.jar;D:\Repository\org\glassfish\jersey\core\jersey-common\2.22.2\jersey-common-2.22.2.jar;D:\Repository\javax\annotation\javax.annotation-api\1.2\javax.annotation-api-1.2.jar;D:\Repository\org\glassfish\jersey\bundles\repackaged\jersey-guava\2.22.2\jersey-guava-2.22.2.jar;D:\Repository\org\glassfish\hk2\osgi-resource-locator\1.0.1\osgi-resource-locator-1.0.1.jar;D:\Repository\org\glassfish\jersey\core\jersey-server\2.22.2\jersey-server-2.22.2.jar;D:\Repository\org\glassfish\jersey\media\jersey-media-jaxb\2.22.2\jersey-media-jaxb-2.22.2.jar;D:\Repository\javax\validation\validation-api\1.1.0.Final\validation-api-1.1.0.Final.jar;D:\Repository\org\glassfish\jersey\containers\jersey-container-servlet\2.22.2\jersey-container-servlet-2.22.2.jar;D:\Repository\org\glassfish\jersey\containers\jersey-container-servlet-core\2.22.2\jersey-container-servlet-core-2.22.2.jar;D:\Repository\io\netty\netty-all\4.0.42.Final\netty-all-4.0.42.Final.jar;D:\Repository\io\netty\netty\3.8.0.Final\netty-3.8.0.Final.jar;D:\Repository\com\clearspring\analytics\stream\2.7.0\stream-2.7.0.jar;D:\Repository\io\dropwizard\metrics\metrics-core\3.1.2\metrics-core-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-jvm\3.1.2\metrics-jvm-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-json\3.1.2\metrics-json-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-graphite\3.1.2\metrics-graphite-3.1.2.jar;D:\Repository\com\fasterxml\jackson\core\jackson-databind\2.6.5\jackson-databind-2.6.5.jar;D:\Repository\com\fasterxml\jackson\core\jackson-core\2.6.5\jackson-core-2.6.5.jar;D:\Repository\com\fasterxml\jackson\module\jackson-module-scala_2.11\2.6.5\jackson-module-scala_2.11-2.6.5.jar;D:\Repository\org\scala-lang\scala-reflect\2.11.7\scala-reflect-2.11.7.jar;D:\Repository\com\fasterxml\jackson\module\jackson-module-paranamer\2.6.5\jackson-module-paranamer-2.6.5.jar;D:\Repository\org\apache\ivy\ivy\2.4.0\ivy-2.4.0.jar;D:\Repository\oro\oro\2.0.8\oro-2.0.8.jar;D:\Repository\net\razorvine\pyrolite\4.13\pyrolite-4.13.jar;D:\Repository\net\sf\py4j\py4j\0.10.4\py4j-0.10.4.jar;D:\Repository\org\apache\spark\spark-tags_2.11\2.1.0\spark-tags_2.11-2.1.0.jar;D:\Repository\org\scalatest\scalatest_2.11\2.2.6\scalatest_2.11-2.2.6.jar;D:\Repository\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;D:\Repository\org\spark-project\spark\unused\1.0.0\unused-1.0.0.jar;D:\Repository\org\apache\spark\spark-streaming_2.11\2.1.0\spark-streaming_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-sql_2.11\2.1.0\spark-sql_2.11-2.1.0.jar;D:\Repository\com\univocity\univocity-parsers\2.2.1\univocity-parsers-2.2.1.jar;D:\Repository\org\apache\spark\spark-sketch_2.11\2.1.0\spark-sketch_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-catalyst_2.11\2.1.0\spark-catalyst_2.11-2.1.0.jar;D:\Repository\org\codehaus\janino\janino\3.0.0\janino-3.0.0.jar;D:\Repository\org\codehaus\janino\commons-compiler\3.0.0\commons-compiler-3.0.0.jar;D:\Repository\org\antlr\antlr4-runtime\4.5.3\antlr4-runtime-4.5.3.jar;D:\Repository\org\apache\parquet\parquet-column\1.8.1\parquet-column-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-common\1.8.1\parquet-common-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-encoding\1.8.1\parquet-encoding-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-hadoop\1.8.1\parquet-hadoop-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-format\2.3.0-incubating\parquet-format-2.3.0-incubating.jar;D:\Repository\org\apache\parquet\parquet-jackson\1.8.1\parquet-jackson-1.8.1.jar;D:\Repository\org\apache\hadoop\hadoop-client\2.6.5\hadoop-client-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-common\2.6.5\hadoop-common-2.6.5.jar;D:\Repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;D:\Repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;D:\Repository\commons-io\commons-io\2.4\commons-io-2.4.jar;D:\Repository\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;D:\Repository\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;D:\Repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\Repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;D:\Repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;D:\Repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;D:\Repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;D:\Repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;D:\Repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;D:\Repository\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;D:\Repository\org\apache\hadoop\hadoop-auth\2.6.5\hadoop-auth-2.6.5.jar;D:\Repository\org\apache\httpcomponents\httpclient\4.2.5\httpclient-4.2.5.jar;D:\Repository\org\apache\httpcomponents\httpcore\4.2.4\httpcore-4.2.4.jar;D:\Repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;D:\Repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;D:\Repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;D:\Repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;D:\Repository\org\apache\curator\curator-client\2.6.0\curator-client-2.6.0.jar;D:\Repository\org\htrace\htrace-core\3.0.4\htrace-core-3.0.4.jar;D:\Repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;D:\Repository\org\tukaani\xz\1.0\xz-1.0.jar;D:\Repository\org\apache\hadoop\hadoop-hdfs\2.6.5\hadoop-hdfs-2.6.5.jar;D:\Repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;D:\Repository\xerces\xercesImpl\2.9.1\xercesImpl-2.9.1.jar;D:\Repository\xml-apis\xml-apis\1.3.04\xml-apis-1.3.04.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.6.5\hadoop-mapreduce-client-app-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.6.5\hadoop-mapreduce-client-common-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-client\2.6.5\hadoop-yarn-client-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-server-common\2.6.5\hadoop-yarn-server-common-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.6.5\hadoop-mapreduce-client-shuffle-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-api\2.6.5\hadoop-yarn-api-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.6.5\hadoop-mapreduce-client-core-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-common\2.6.5\hadoop-yarn-common-2.6.5.jar;D:\Repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;D:\Repository\javax\xml\stream\stax-api\1.0-2\stax-api-1.0-2.jar;D:\Repository\javax\activation\activation\1.1\activation-1.1.jar;D:\Repository\javax\servlet\servlet-api\2.5\servlet-api-2.5.jar;D:\Repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;D:\Repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;D:\Repository\org\codehaus\jackson\jackson-jaxrs\1.9.13\jackson-jaxrs-1.9.13.jar;D:\Repository\org\codehaus\jackson\jackson-xc\1.9.13\jackson-xc-1.9.13.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.6.5\hadoop-mapreduce-client-jobclient-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-annotations\2.6.5\hadoop-annotations-2.6.5.jar;D:\Repository\org\apache\kafka\kafka-clients\0.8.2.2\kafka-clients-0.8.2.2.jar;D:\Repository\org\apache\kafka\kafka_2.11\0.8.2.2\kafka_2.11-0.8.2.2.jar;D:\Repository\org\scala-lang\modules\scala-xml_2.11\1.0.2\scala-xml_2.11-1.0.2.jar;D:\Repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;D:\Repository\net\sf\jopt-simple\jopt-simple\3.2\jopt-simple-3.2.jar;D:\Repository\org\scala-lang\modules\scala-parser-combinators_2.11\1.0.2\scala-parser-combinators_2.11-1.0.2.jar;D:\Repository\com\101tec\zkclient\0.3\zkclient-0.3.jar;D:\Repository\mysql\mysql-connector-java\5.1.38\mysql-connector-java-5.1.38.jar;D:\Repository\org\apache\spark\spark-streaming-kafka-0-8_2.11\2.1.0\spark-streaming-kafka-0-8_2.11-2.1.0.jar;D:\Repository\org\apache\zookeeper\zookeeper\3.4.10\zookeeper-3.4.10.jar;D:\Repository\jline\jline\0.9.94\jline-0.9.94.jar;D:\developTools\IntelliJ IDEA 2018.2.3\lib\idea_rt.jar
2018-12-26 16:14:45 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_171\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;D:\developTools\Git\cmd;D:\developTools\svn\bin;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\scala\bin;C:\Users\junmei02\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk1.8.0_171\bin;D:\developTools\apache-maven-3.5.2\bin;D:\developTools\mysql-5.6.27-winx64\bin;D:\developTools\Git\cmd;D:\hadoop\hadoop-common-2.2.0-bin-master\bin;D:\hadoop\hbase-1.2.6\bin;C:\Program Files (x86)\scala\bin;D:\bigdata\zookeeper-3.4.10\bin;;.
2018-12-26 16:14:45 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.io.tmpdir=C:\Users\junmei02\AppData\Local\Temp\
2018-12-26 16:14:45 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.compiler=<NA>
2018-12-26 16:14:45 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.name=Windows 10
2018-12-26 16:14:45 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.arch=amd64
2018-12-26 16:14:45 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.version=10.0
2018-12-26 16:14:45 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.name=junmei02
2018-12-26 16:14:45 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.home=C:\Users\junmei02
2018-12-26 16:14:45 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.dir=D:\springbootworkspace\spark
2018-12-26 16:14:45 [ INFO ] - [ org.apache.zookeeper.ZooKeeper.<init>(ZooKeeper.java:438) ] Initiating client connection, connectString=127.0.0.1:2181 sessionTimeout=10000 watcher=org.apache.curator.ConnectionState@2034b64c
2018-12-26 16:14:45 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:1032) ] Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2018-12-26 16:14:45 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$SendThread.primeConnection(ClientCnxn.java:876) ] Socket connection established to 127.0.0.1/127.0.0.1:2181, initiating session
2018-12-26 16:14:45 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$SendThread.onConnected(ClientCnxn.java:1299) ] Session establishment complete on server 127.0.0.1/127.0.0.1:2181, sessionid = 0x167e991b4b60003, negotiated timeout = 10000
2018-12-26 16:14:45 [ INFO ] - [ org.apache.curator.framework.state.ConnectionStateManager.postState(ConnectionStateManager.java:194) ] State change: CONNECTED
2018-12-26 16:14:45 [ WARN ] - [ org.apache.curator.framework.state.ConnectionStateManager.processEvents(ConnectionStateManager.java:212) ] There are no ConnectionStateListeners registered.
2018-12-26 16:14:46 [ INFO ] - [ org.apache.zookeeper.ZooKeeper.close(ZooKeeper.java:684) ] Session: 0x167e991b4b60003 closed
2018-12-26 16:14:46 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:519) ] EventThread shut down for session: 0x167e991b4b60003
2018-12-26 16:14:48 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Running Spark version 2.1.0
2018-12-26 16:14:48 [ ERROR ] - [ org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:396) ] Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2373)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2373)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2373)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:837)
	at org.apache.spark.streaming.StreamingContext.<init>(StreamingContext.scala:84)
	at org.apache.spark.streaming.api.java.JavaStreamingContext.<init>(JavaStreamingContext.scala:138)
	at com.zqg.StreamKafka.KafkaSparkStreamingWithZookeeperoffset.main(KafkaSparkStreamingWithZookeeperoffset.java:67)
2018-12-26 16:14:48 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing view acls to: junmei02
2018-12-26 16:14:48 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing modify acls to: junmei02
2018-12-26 16:14:48 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing view acls groups to: 
2018-12-26 16:14:48 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing modify acls groups to: 
2018-12-26 16:14:48 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(junmei02); groups with view permissions: Set(); users  with modify permissions: Set(junmei02); groups with modify permissions: Set()
2018-12-26 16:14:48 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'sparkDriver' on port 54856.
2018-12-26 16:14:48 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering MapOutputTracker
2018-12-26 16:14:48 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering BlockManagerMaster
2018-12-26 16:14:48 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-26 16:14:48 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] BlockManagerMasterEndpoint up
2018-12-26 16:14:48 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Created local directory at C:\Users\junmei02\AppData\Local\Temp\blockmgr-ba1c7394-f9f0-408b-8b2c-406f4b3f2628
2018-12-26 16:14:48 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] MemoryStore started with capacity 900.6 MB
2018-12-26 16:14:48 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering OutputCommitCoordinator
2018-12-26 16:14:48 [ INFO ] - [ org.spark_project.jetty.util.log.Log.initialized(Log.java:186) ] Logging initialized @4450ms
2018-12-26 16:14:48 [ INFO ] - [ org.spark_project.jetty.server.Server.doStart(Server.java:327) ] jetty-9.2.z-SNAPSHOT
2018-12-26 16:14:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@5f8890c2{/jobs,null,AVAILABLE}
2018-12-26 16:14:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@607b2792{/jobs/json,null,AVAILABLE}
2018-12-26 16:14:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@7f9e1534{/jobs/job,null,AVAILABLE}
2018-12-26 16:14:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@138a7441{/jobs/job/json,null,AVAILABLE}
2018-12-26 16:14:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@81ff872{/stages,null,AVAILABLE}
2018-12-26 16:14:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@31611954{/stages/json,null,AVAILABLE}
2018-12-26 16:14:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@3e598df9{/stages/stage,null,AVAILABLE}
2018-12-26 16:14:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@7e31ce0f{/stages/stage/json,null,AVAILABLE}
2018-12-26 16:14:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@99a65d3{/stages/pool,null,AVAILABLE}
2018-12-26 16:14:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@3088660d{/stages/pool/json,null,AVAILABLE}
2018-12-26 16:14:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@42cc13a0{/storage,null,AVAILABLE}
2018-12-26 16:14:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@32fdec40{/storage/json,null,AVAILABLE}
2018-12-26 16:14:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@6813a331{/storage/rdd,null,AVAILABLE}
2018-12-26 16:14:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@1bd81830{/storage/rdd/json,null,AVAILABLE}
2018-12-26 16:14:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@39ab59f8{/environment,null,AVAILABLE}
2018-12-26 16:14:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@64e92d61{/environment/json,null,AVAILABLE}
2018-12-26 16:14:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@111610e6{/executors,null,AVAILABLE}
2018-12-26 16:14:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@4ad4936c{/executors/json,null,AVAILABLE}
2018-12-26 16:14:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@29d37757{/executors/threadDump,null,AVAILABLE}
2018-12-26 16:14:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@4fcc529{/executors/threadDump/json,null,AVAILABLE}
2018-12-26 16:14:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@25cc7470{/static,null,AVAILABLE}
2018-12-26 16:14:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@4beddc56{/,null,AVAILABLE}
2018-12-26 16:14:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@79b663b3{/api,null,AVAILABLE}
2018-12-26 16:14:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@1b812421{/jobs/job/kill,null,AVAILABLE}
2018-12-26 16:14:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@5d28bcd5{/stages/stage/kill,null,AVAILABLE}
2018-12-26 16:14:49 [ INFO ] - [ org.spark_project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:266) ] Started ServerConnector@391cbe4{HTTP/1.1}{0.0.0.0:4040}
2018-12-26 16:14:49 [ INFO ] - [ org.spark_project.jetty.server.Server.doStart(Server.java:379) ] Started @4617ms
2018-12-26 16:14:49 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'SparkUI' on port 4040.
2018-12-26 16:14:49 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Bound SparkUI to 0.0.0.0, and started at http://192.168.0.112:4040
2018-12-26 16:14:49 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Starting executor ID driver on host localhost
2018-12-26 16:14:49 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54877.
2018-12-26 16:14:49 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Server created on 192.168.0.112:54877
2018-12-26 16:14:49 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-26 16:14:49 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering BlockManager BlockManagerId(driver, 192.168.0.112, 54877, None)
2018-12-26 16:14:49 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering block manager 192.168.0.112:54877 with 900.6 MB RAM, BlockManagerId(driver, 192.168.0.112, 54877, None)
2018-12-26 16:14:49 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registered BlockManager BlockManagerId(driver, 192.168.0.112, 54877, None)
2018-12-26 16:14:49 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Initialized BlockManager: BlockManagerId(driver, 192.168.0.112, 54877, None)
2018-12-26 16:14:49 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@48ea2003{/metrics/json,null,AVAILABLE}
2018-12-26 16:18:20 [ INFO ] - [ org.apache.curator.framework.imps.CuratorFrameworkImpl.start(CuratorFrameworkImpl.java:223) ] Starting
2018-12-26 16:18:20 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT
2018-12-26 16:18:20 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:host.name=windows10.microdone.cn
2018-12-26 16:18:20 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.version=1.8.0_171
2018-12-26 16:18:20 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.vendor=Oracle Corporation
2018-12-26 16:18:20 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.home=C:\Program Files\Java\jdk1.8.0_171\jre
2018-12-26 16:18:20 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.class.path=C:\Program Files\Java\jdk1.8.0_171\jre\lib\charsets.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\deploy.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\access-bridge-64.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\cldrdata.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\dnsns.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\jaccess.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\jfxrt.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\localedata.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\nashorn.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunec.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunjce_provider.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunmscapi.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunpkcs11.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\zipfs.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\javaws.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jce.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jfr.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jfxswt.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jsse.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\management-agent.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\plugin.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\resources.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\rt.jar;D:\springbootworkspace\spark\target\classes;D:\Repository\org\scala-lang\scala-library\2.11.8\scala-library-2.11.8.jar;D:\Repository\org\apache\spark\spark-core_2.11\2.1.0\spark-core_2.11-2.1.0.jar;D:\Repository\org\apache\avro\avro-mapred\1.7.7\avro-mapred-1.7.7-hadoop2.jar;D:\Repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7.jar;D:\Repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7-tests.jar;D:\Repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;D:\Repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;D:\Repository\com\twitter\chill_2.11\0.8.0\chill_2.11-0.8.0.jar;D:\Repository\com\esotericsoftware\kryo-shaded\3.0.3\kryo-shaded-3.0.3.jar;D:\Repository\com\esotericsoftware\minlog\1.3.0\minlog-1.3.0.jar;D:\Repository\org\objenesis\objenesis\2.1\objenesis-2.1.jar;D:\Repository\com\twitter\chill-java\0.8.0\chill-java-0.8.0.jar;D:\Repository\org\apache\xbean\xbean-asm5-shaded\4.4\xbean-asm5-shaded-4.4.jar;D:\Repository\org\apache\spark\spark-launcher_2.11\2.1.0\spark-launcher_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-network-common_2.11\2.1.0\spark-network-common_2.11-2.1.0.jar;D:\Repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;D:\Repository\com\fasterxml\jackson\core\jackson-annotations\2.6.5\jackson-annotations-2.6.5.jar;D:\Repository\org\apache\spark\spark-network-shuffle_2.11\2.1.0\spark-network-shuffle_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-unsafe_2.11\2.1.0\spark-unsafe_2.11-2.1.0.jar;D:\Repository\net\java\dev\jets3t\jets3t\0.7.1\jets3t-0.7.1.jar;D:\Repository\commons-codec\commons-codec\1.3\commons-codec-1.3.jar;D:\Repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;D:\Repository\org\apache\curator\curator-recipes\2.4.0\curator-recipes-2.4.0.jar;D:\Repository\org\apache\curator\curator-framework\2.4.0\curator-framework-2.4.0.jar;D:\Repository\com\google\guava\guava\14.0.1\guava-14.0.1.jar;D:\Repository\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;D:\Repository\org\apache\commons\commons-lang3\3.5\commons-lang3-3.5.jar;D:\Repository\org\apache\commons\commons-math3\3.4.1\commons-math3-3.4.1.jar;D:\Repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;D:\Repository\org\slf4j\slf4j-api\1.7.16\slf4j-api-1.7.16.jar;D:\Repository\org\slf4j\jul-to-slf4j\1.7.16\jul-to-slf4j-1.7.16.jar;D:\Repository\org\slf4j\jcl-over-slf4j\1.7.16\jcl-over-slf4j-1.7.16.jar;D:\Repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;D:\Repository\org\slf4j\slf4j-log4j12\1.7.16\slf4j-log4j12-1.7.16.jar;D:\Repository\com\ning\compress-lzf\1.0.3\compress-lzf-1.0.3.jar;D:\Repository\org\xerial\snappy\snappy-java\1.1.2.6\snappy-java-1.1.2.6.jar;D:\Repository\net\jpountz\lz4\lz4\1.3.0\lz4-1.3.0.jar;D:\Repository\org\roaringbitmap\RoaringBitmap\0.5.11\RoaringBitmap-0.5.11.jar;D:\Repository\commons-net\commons-net\2.2\commons-net-2.2.jar;D:\Repository\org\json4s\json4s-jackson_2.11\3.2.11\json4s-jackson_2.11-3.2.11.jar;D:\Repository\org\json4s\json4s-core_2.11\3.2.11\json4s-core_2.11-3.2.11.jar;D:\Repository\org\json4s\json4s-ast_2.11\3.2.11\json4s-ast_2.11-3.2.11.jar;D:\Repository\com\thoughtworks\paranamer\paranamer\2.6\paranamer-2.6.jar;D:\Repository\org\scala-lang\scalap\2.11.0\scalap-2.11.0.jar;D:\Repository\org\scala-lang\scala-compiler\2.11.0\scala-compiler-2.11.0.jar;D:\Repository\org\glassfish\jersey\core\jersey-client\2.22.2\jersey-client-2.22.2.jar;D:\Repository\javax\ws\rs\javax.ws.rs-api\2.0.1\javax.ws.rs-api-2.0.1.jar;D:\Repository\org\glassfish\hk2\hk2-api\2.4.0-b34\hk2-api-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\hk2-utils\2.4.0-b34\hk2-utils-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\external\aopalliance-repackaged\2.4.0-b34\aopalliance-repackaged-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\external\javax.inject\2.4.0-b34\javax.inject-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\hk2-locator\2.4.0-b34\hk2-locator-2.4.0-b34.jar;D:\Repository\org\javassist\javassist\3.18.1-GA\javassist-3.18.1-GA.jar;D:\Repository\org\glassfish\jersey\core\jersey-common\2.22.2\jersey-common-2.22.2.jar;D:\Repository\javax\annotation\javax.annotation-api\1.2\javax.annotation-api-1.2.jar;D:\Repository\org\glassfish\jersey\bundles\repackaged\jersey-guava\2.22.2\jersey-guava-2.22.2.jar;D:\Repository\org\glassfish\hk2\osgi-resource-locator\1.0.1\osgi-resource-locator-1.0.1.jar;D:\Repository\org\glassfish\jersey\core\jersey-server\2.22.2\jersey-server-2.22.2.jar;D:\Repository\org\glassfish\jersey\media\jersey-media-jaxb\2.22.2\jersey-media-jaxb-2.22.2.jar;D:\Repository\javax\validation\validation-api\1.1.0.Final\validation-api-1.1.0.Final.jar;D:\Repository\org\glassfish\jersey\containers\jersey-container-servlet\2.22.2\jersey-container-servlet-2.22.2.jar;D:\Repository\org\glassfish\jersey\containers\jersey-container-servlet-core\2.22.2\jersey-container-servlet-core-2.22.2.jar;D:\Repository\io\netty\netty-all\4.0.42.Final\netty-all-4.0.42.Final.jar;D:\Repository\io\netty\netty\3.8.0.Final\netty-3.8.0.Final.jar;D:\Repository\com\clearspring\analytics\stream\2.7.0\stream-2.7.0.jar;D:\Repository\io\dropwizard\metrics\metrics-core\3.1.2\metrics-core-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-jvm\3.1.2\metrics-jvm-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-json\3.1.2\metrics-json-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-graphite\3.1.2\metrics-graphite-3.1.2.jar;D:\Repository\com\fasterxml\jackson\core\jackson-databind\2.6.5\jackson-databind-2.6.5.jar;D:\Repository\com\fasterxml\jackson\core\jackson-core\2.6.5\jackson-core-2.6.5.jar;D:\Repository\com\fasterxml\jackson\module\jackson-module-scala_2.11\2.6.5\jackson-module-scala_2.11-2.6.5.jar;D:\Repository\org\scala-lang\scala-reflect\2.11.7\scala-reflect-2.11.7.jar;D:\Repository\com\fasterxml\jackson\module\jackson-module-paranamer\2.6.5\jackson-module-paranamer-2.6.5.jar;D:\Repository\org\apache\ivy\ivy\2.4.0\ivy-2.4.0.jar;D:\Repository\oro\oro\2.0.8\oro-2.0.8.jar;D:\Repository\net\razorvine\pyrolite\4.13\pyrolite-4.13.jar;D:\Repository\net\sf\py4j\py4j\0.10.4\py4j-0.10.4.jar;D:\Repository\org\apache\spark\spark-tags_2.11\2.1.0\spark-tags_2.11-2.1.0.jar;D:\Repository\org\scalatest\scalatest_2.11\2.2.6\scalatest_2.11-2.2.6.jar;D:\Repository\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;D:\Repository\org\spark-project\spark\unused\1.0.0\unused-1.0.0.jar;D:\Repository\org\apache\spark\spark-streaming_2.11\2.1.0\spark-streaming_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-sql_2.11\2.1.0\spark-sql_2.11-2.1.0.jar;D:\Repository\com\univocity\univocity-parsers\2.2.1\univocity-parsers-2.2.1.jar;D:\Repository\org\apache\spark\spark-sketch_2.11\2.1.0\spark-sketch_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-catalyst_2.11\2.1.0\spark-catalyst_2.11-2.1.0.jar;D:\Repository\org\codehaus\janino\janino\3.0.0\janino-3.0.0.jar;D:\Repository\org\codehaus\janino\commons-compiler\3.0.0\commons-compiler-3.0.0.jar;D:\Repository\org\antlr\antlr4-runtime\4.5.3\antlr4-runtime-4.5.3.jar;D:\Repository\org\apache\parquet\parquet-column\1.8.1\parquet-column-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-common\1.8.1\parquet-common-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-encoding\1.8.1\parquet-encoding-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-hadoop\1.8.1\parquet-hadoop-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-format\2.3.0-incubating\parquet-format-2.3.0-incubating.jar;D:\Repository\org\apache\parquet\parquet-jackson\1.8.1\parquet-jackson-1.8.1.jar;D:\Repository\org\apache\hadoop\hadoop-client\2.6.5\hadoop-client-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-common\2.6.5\hadoop-common-2.6.5.jar;D:\Repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;D:\Repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;D:\Repository\commons-io\commons-io\2.4\commons-io-2.4.jar;D:\Repository\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;D:\Repository\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;D:\Repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\Repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;D:\Repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;D:\Repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;D:\Repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;D:\Repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;D:\Repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;D:\Repository\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;D:\Repository\org\apache\hadoop\hadoop-auth\2.6.5\hadoop-auth-2.6.5.jar;D:\Repository\org\apache\httpcomponents\httpclient\4.2.5\httpclient-4.2.5.jar;D:\Repository\org\apache\httpcomponents\httpcore\4.2.4\httpcore-4.2.4.jar;D:\Repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;D:\Repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;D:\Repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;D:\Repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;D:\Repository\org\apache\curator\curator-client\2.6.0\curator-client-2.6.0.jar;D:\Repository\org\htrace\htrace-core\3.0.4\htrace-core-3.0.4.jar;D:\Repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;D:\Repository\org\tukaani\xz\1.0\xz-1.0.jar;D:\Repository\org\apache\hadoop\hadoop-hdfs\2.6.5\hadoop-hdfs-2.6.5.jar;D:\Repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;D:\Repository\xerces\xercesImpl\2.9.1\xercesImpl-2.9.1.jar;D:\Repository\xml-apis\xml-apis\1.3.04\xml-apis-1.3.04.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.6.5\hadoop-mapreduce-client-app-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.6.5\hadoop-mapreduce-client-common-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-client\2.6.5\hadoop-yarn-client-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-server-common\2.6.5\hadoop-yarn-server-common-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.6.5\hadoop-mapreduce-client-shuffle-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-api\2.6.5\hadoop-yarn-api-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.6.5\hadoop-mapreduce-client-core-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-common\2.6.5\hadoop-yarn-common-2.6.5.jar;D:\Repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;D:\Repository\javax\xml\stream\stax-api\1.0-2\stax-api-1.0-2.jar;D:\Repository\javax\activation\activation\1.1\activation-1.1.jar;D:\Repository\javax\servlet\servlet-api\2.5\servlet-api-2.5.jar;D:\Repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;D:\Repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;D:\Repository\org\codehaus\jackson\jackson-jaxrs\1.9.13\jackson-jaxrs-1.9.13.jar;D:\Repository\org\codehaus\jackson\jackson-xc\1.9.13\jackson-xc-1.9.13.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.6.5\hadoop-mapreduce-client-jobclient-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-annotations\2.6.5\hadoop-annotations-2.6.5.jar;D:\Repository\org\apache\kafka\kafka-clients\0.8.2.2\kafka-clients-0.8.2.2.jar;D:\Repository\org\apache\kafka\kafka_2.11\0.8.2.2\kafka_2.11-0.8.2.2.jar;D:\Repository\org\scala-lang\modules\scala-xml_2.11\1.0.2\scala-xml_2.11-1.0.2.jar;D:\Repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;D:\Repository\net\sf\jopt-simple\jopt-simple\3.2\jopt-simple-3.2.jar;D:\Repository\org\scala-lang\modules\scala-parser-combinators_2.11\1.0.2\scala-parser-combinators_2.11-1.0.2.jar;D:\Repository\com\101tec\zkclient\0.3\zkclient-0.3.jar;D:\Repository\mysql\mysql-connector-java\5.1.38\mysql-connector-java-5.1.38.jar;D:\Repository\org\apache\spark\spark-streaming-kafka-0-8_2.11\2.1.0\spark-streaming-kafka-0-8_2.11-2.1.0.jar;D:\Repository\org\apache\zookeeper\zookeeper\3.4.10\zookeeper-3.4.10.jar;D:\Repository\jline\jline\0.9.94\jline-0.9.94.jar;D:\developTools\IntelliJ IDEA 2018.2.3\lib\idea_rt.jar
2018-12-26 16:18:20 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_171\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;D:\developTools\Git\cmd;D:\developTools\svn\bin;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\scala\bin;C:\Users\junmei02\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk1.8.0_171\bin;D:\developTools\apache-maven-3.5.2\bin;D:\developTools\mysql-5.6.27-winx64\bin;D:\developTools\Git\cmd;D:\hadoop\hadoop-common-2.2.0-bin-master\bin;D:\hadoop\hbase-1.2.6\bin;C:\Program Files (x86)\scala\bin;D:\bigdata\zookeeper-3.4.10\bin;;.
2018-12-26 16:18:20 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.io.tmpdir=C:\Users\junmei02\AppData\Local\Temp\
2018-12-26 16:18:20 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.compiler=<NA>
2018-12-26 16:18:20 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.name=Windows 10
2018-12-26 16:18:20 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.arch=amd64
2018-12-26 16:18:20 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.version=10.0
2018-12-26 16:18:20 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.name=junmei02
2018-12-26 16:18:20 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.home=C:\Users\junmei02
2018-12-26 16:18:20 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.dir=D:\springbootworkspace\spark
2018-12-26 16:18:20 [ INFO ] - [ org.apache.zookeeper.ZooKeeper.<init>(ZooKeeper.java:438) ] Initiating client connection, connectString=127.0.0.1:2181 sessionTimeout=10000 watcher=org.apache.curator.ConnectionState@2034b64c
2018-12-26 16:18:21 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:1032) ] Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2018-12-26 16:18:21 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$SendThread.primeConnection(ClientCnxn.java:876) ] Socket connection established to 127.0.0.1/127.0.0.1:2181, initiating session
2018-12-26 16:18:21 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$SendThread.onConnected(ClientCnxn.java:1299) ] Session establishment complete on server 127.0.0.1/127.0.0.1:2181, sessionid = 0x167e991b4b60004, negotiated timeout = 10000
2018-12-26 16:18:21 [ INFO ] - [ org.apache.curator.framework.state.ConnectionStateManager.postState(ConnectionStateManager.java:194) ] State change: CONNECTED
2018-12-26 16:18:21 [ WARN ] - [ org.apache.curator.framework.state.ConnectionStateManager.processEvents(ConnectionStateManager.java:212) ] There are no ConnectionStateListeners registered.
2018-12-26 16:18:22 [ INFO ] - [ org.apache.zookeeper.ZooKeeper.close(ZooKeeper.java:684) ] Session: 0x167e991b4b60004 closed
2018-12-26 16:18:22 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:519) ] EventThread shut down for session: 0x167e991b4b60004
2018-12-26 16:18:23 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Running Spark version 2.1.0
2018-12-26 16:18:23 [ ERROR ] - [ org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:396) ] Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2373)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2373)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2373)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:837)
	at org.apache.spark.streaming.StreamingContext.<init>(StreamingContext.scala:84)
	at org.apache.spark.streaming.api.java.JavaStreamingContext.<init>(JavaStreamingContext.scala:138)
	at com.zqg.StreamKafka.KafkaSparkStreamingWithZookeeperoffset.main(KafkaSparkStreamingWithZookeeperoffset.java:67)
2018-12-26 16:18:23 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing view acls to: junmei02
2018-12-26 16:18:23 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing modify acls to: junmei02
2018-12-26 16:18:23 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing view acls groups to: 
2018-12-26 16:18:23 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing modify acls groups to: 
2018-12-26 16:18:23 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(junmei02); groups with view permissions: Set(); users  with modify permissions: Set(junmei02); groups with modify permissions: Set()
2018-12-26 16:18:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'sparkDriver' on port 55033.
2018-12-26 16:18:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering MapOutputTracker
2018-12-26 16:18:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering BlockManagerMaster
2018-12-26 16:18:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-26 16:18:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] BlockManagerMasterEndpoint up
2018-12-26 16:18:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Created local directory at C:\Users\junmei02\AppData\Local\Temp\blockmgr-ece33799-8f82-4997-9f50-92979a6ba33e
2018-12-26 16:18:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] MemoryStore started with capacity 900.6 MB
2018-12-26 16:18:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering OutputCommitCoordinator
2018-12-26 16:18:24 [ INFO ] - [ org.spark_project.jetty.util.log.Log.initialized(Log.java:186) ] Logging initialized @4585ms
2018-12-26 16:18:24 [ INFO ] - [ org.spark_project.jetty.server.Server.doStart(Server.java:327) ] jetty-9.2.z-SNAPSHOT
2018-12-26 16:18:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@7fcff1b9{/jobs,null,AVAILABLE}
2018-12-26 16:18:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@697446d4{/jobs/json,null,AVAILABLE}
2018-12-26 16:18:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@76adb233{/jobs/job,null,AVAILABLE}
2018-12-26 16:18:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@36074e47{/jobs/job/json,null,AVAILABLE}
2018-12-26 16:18:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@36453307{/stages,null,AVAILABLE}
2018-12-26 16:18:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@7dcc91fd{/stages/json,null,AVAILABLE}
2018-12-26 16:18:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@66eb985d{/stages/stage,null,AVAILABLE}
2018-12-26 16:18:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@6a9287b1{/stages/stage/json,null,AVAILABLE}
2018-12-26 16:18:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@75504cef{/stages/pool,null,AVAILABLE}
2018-12-26 16:18:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@6c8a68c1{/stages/pool/json,null,AVAILABLE}
2018-12-26 16:18:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@56193c7d{/storage,null,AVAILABLE}
2018-12-26 16:18:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@28c88600{/storage/json,null,AVAILABLE}
2018-12-26 16:18:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@5f8890c2{/storage/rdd,null,AVAILABLE}
2018-12-26 16:18:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@607b2792{/storage/rdd/json,null,AVAILABLE}
2018-12-26 16:18:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@7f9e1534{/environment,null,AVAILABLE}
2018-12-26 16:18:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@138a7441{/environment/json,null,AVAILABLE}
2018-12-26 16:18:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@81ff872{/executors,null,AVAILABLE}
2018-12-26 16:18:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@31611954{/executors/json,null,AVAILABLE}
2018-12-26 16:18:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@3e598df9{/executors/threadDump,null,AVAILABLE}
2018-12-26 16:18:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@7e31ce0f{/executors/threadDump/json,null,AVAILABLE}
2018-12-26 16:18:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@99a65d3{/static,null,AVAILABLE}
2018-12-26 16:18:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@3088660d{/,null,AVAILABLE}
2018-12-26 16:18:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@42cc13a0{/api,null,AVAILABLE}
2018-12-26 16:18:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@32fdec40{/jobs/job/kill,null,AVAILABLE}
2018-12-26 16:18:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@6813a331{/stages/stage/kill,null,AVAILABLE}
2018-12-26 16:18:24 [ INFO ] - [ org.spark_project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:266) ] Started ServerConnector@6622a690{HTTP/1.1}{0.0.0.0:4040}
2018-12-26 16:18:24 [ INFO ] - [ org.spark_project.jetty.server.Server.doStart(Server.java:379) ] Started @4746ms
2018-12-26 16:18:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'SparkUI' on port 4040.
2018-12-26 16:18:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Bound SparkUI to 0.0.0.0, and started at http://192.168.0.112:4040
2018-12-26 16:18:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Starting executor ID driver on host localhost
2018-12-26 16:18:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55054.
2018-12-26 16:18:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Server created on 192.168.0.112:55054
2018-12-26 16:18:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-26 16:18:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering BlockManager BlockManagerId(driver, 192.168.0.112, 55054, None)
2018-12-26 16:18:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering block manager 192.168.0.112:55054 with 900.6 MB RAM, BlockManagerId(driver, 192.168.0.112, 55054, None)
2018-12-26 16:18:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registered BlockManager BlockManagerId(driver, 192.168.0.112, 55054, None)
2018-12-26 16:18:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Initialized BlockManager: BlockManagerId(driver, 192.168.0.112, 55054, None)
2018-12-26 16:18:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@6b1e7ad3{/metrics/json,null,AVAILABLE}
2018-12-26 16:30:27 [ INFO ] - [ org.apache.curator.framework.imps.CuratorFrameworkImpl.start(CuratorFrameworkImpl.java:223) ] Starting
2018-12-26 16:30:27 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT
2018-12-26 16:30:27 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:host.name=windows10.microdone.cn
2018-12-26 16:30:27 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.version=1.8.0_171
2018-12-26 16:30:27 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.vendor=Oracle Corporation
2018-12-26 16:30:27 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.home=C:\Program Files\Java\jdk1.8.0_171\jre
2018-12-26 16:30:27 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.class.path=C:\Program Files\Java\jdk1.8.0_171\jre\lib\charsets.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\deploy.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\access-bridge-64.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\cldrdata.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\dnsns.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\jaccess.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\jfxrt.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\localedata.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\nashorn.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunec.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunjce_provider.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunmscapi.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunpkcs11.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\zipfs.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\javaws.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jce.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jfr.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jfxswt.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jsse.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\management-agent.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\plugin.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\resources.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\rt.jar;D:\springbootworkspace\spark\target\classes;D:\Repository\org\scala-lang\scala-library\2.11.8\scala-library-2.11.8.jar;D:\Repository\org\apache\spark\spark-core_2.11\2.1.0\spark-core_2.11-2.1.0.jar;D:\Repository\org\apache\avro\avro-mapred\1.7.7\avro-mapred-1.7.7-hadoop2.jar;D:\Repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7.jar;D:\Repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7-tests.jar;D:\Repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;D:\Repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;D:\Repository\com\twitter\chill_2.11\0.8.0\chill_2.11-0.8.0.jar;D:\Repository\com\esotericsoftware\kryo-shaded\3.0.3\kryo-shaded-3.0.3.jar;D:\Repository\com\esotericsoftware\minlog\1.3.0\minlog-1.3.0.jar;D:\Repository\org\objenesis\objenesis\2.1\objenesis-2.1.jar;D:\Repository\com\twitter\chill-java\0.8.0\chill-java-0.8.0.jar;D:\Repository\org\apache\xbean\xbean-asm5-shaded\4.4\xbean-asm5-shaded-4.4.jar;D:\Repository\org\apache\spark\spark-launcher_2.11\2.1.0\spark-launcher_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-network-common_2.11\2.1.0\spark-network-common_2.11-2.1.0.jar;D:\Repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;D:\Repository\com\fasterxml\jackson\core\jackson-annotations\2.6.5\jackson-annotations-2.6.5.jar;D:\Repository\org\apache\spark\spark-network-shuffle_2.11\2.1.0\spark-network-shuffle_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-unsafe_2.11\2.1.0\spark-unsafe_2.11-2.1.0.jar;D:\Repository\net\java\dev\jets3t\jets3t\0.7.1\jets3t-0.7.1.jar;D:\Repository\commons-codec\commons-codec\1.3\commons-codec-1.3.jar;D:\Repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;D:\Repository\org\apache\curator\curator-recipes\2.4.0\curator-recipes-2.4.0.jar;D:\Repository\org\apache\curator\curator-framework\2.4.0\curator-framework-2.4.0.jar;D:\Repository\com\google\guava\guava\14.0.1\guava-14.0.1.jar;D:\Repository\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;D:\Repository\org\apache\commons\commons-lang3\3.5\commons-lang3-3.5.jar;D:\Repository\org\apache\commons\commons-math3\3.4.1\commons-math3-3.4.1.jar;D:\Repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;D:\Repository\org\slf4j\slf4j-api\1.7.16\slf4j-api-1.7.16.jar;D:\Repository\org\slf4j\jul-to-slf4j\1.7.16\jul-to-slf4j-1.7.16.jar;D:\Repository\org\slf4j\jcl-over-slf4j\1.7.16\jcl-over-slf4j-1.7.16.jar;D:\Repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;D:\Repository\org\slf4j\slf4j-log4j12\1.7.16\slf4j-log4j12-1.7.16.jar;D:\Repository\com\ning\compress-lzf\1.0.3\compress-lzf-1.0.3.jar;D:\Repository\org\xerial\snappy\snappy-java\1.1.2.6\snappy-java-1.1.2.6.jar;D:\Repository\net\jpountz\lz4\lz4\1.3.0\lz4-1.3.0.jar;D:\Repository\org\roaringbitmap\RoaringBitmap\0.5.11\RoaringBitmap-0.5.11.jar;D:\Repository\commons-net\commons-net\2.2\commons-net-2.2.jar;D:\Repository\org\json4s\json4s-jackson_2.11\3.2.11\json4s-jackson_2.11-3.2.11.jar;D:\Repository\org\json4s\json4s-core_2.11\3.2.11\json4s-core_2.11-3.2.11.jar;D:\Repository\org\json4s\json4s-ast_2.11\3.2.11\json4s-ast_2.11-3.2.11.jar;D:\Repository\com\thoughtworks\paranamer\paranamer\2.6\paranamer-2.6.jar;D:\Repository\org\scala-lang\scalap\2.11.0\scalap-2.11.0.jar;D:\Repository\org\scala-lang\scala-compiler\2.11.0\scala-compiler-2.11.0.jar;D:\Repository\org\glassfish\jersey\core\jersey-client\2.22.2\jersey-client-2.22.2.jar;D:\Repository\javax\ws\rs\javax.ws.rs-api\2.0.1\javax.ws.rs-api-2.0.1.jar;D:\Repository\org\glassfish\hk2\hk2-api\2.4.0-b34\hk2-api-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\hk2-utils\2.4.0-b34\hk2-utils-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\external\aopalliance-repackaged\2.4.0-b34\aopalliance-repackaged-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\external\javax.inject\2.4.0-b34\javax.inject-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\hk2-locator\2.4.0-b34\hk2-locator-2.4.0-b34.jar;D:\Repository\org\javassist\javassist\3.18.1-GA\javassist-3.18.1-GA.jar;D:\Repository\org\glassfish\jersey\core\jersey-common\2.22.2\jersey-common-2.22.2.jar;D:\Repository\javax\annotation\javax.annotation-api\1.2\javax.annotation-api-1.2.jar;D:\Repository\org\glassfish\jersey\bundles\repackaged\jersey-guava\2.22.2\jersey-guava-2.22.2.jar;D:\Repository\org\glassfish\hk2\osgi-resource-locator\1.0.1\osgi-resource-locator-1.0.1.jar;D:\Repository\org\glassfish\jersey\core\jersey-server\2.22.2\jersey-server-2.22.2.jar;D:\Repository\org\glassfish\jersey\media\jersey-media-jaxb\2.22.2\jersey-media-jaxb-2.22.2.jar;D:\Repository\javax\validation\validation-api\1.1.0.Final\validation-api-1.1.0.Final.jar;D:\Repository\org\glassfish\jersey\containers\jersey-container-servlet\2.22.2\jersey-container-servlet-2.22.2.jar;D:\Repository\org\glassfish\jersey\containers\jersey-container-servlet-core\2.22.2\jersey-container-servlet-core-2.22.2.jar;D:\Repository\io\netty\netty-all\4.0.42.Final\netty-all-4.0.42.Final.jar;D:\Repository\io\netty\netty\3.8.0.Final\netty-3.8.0.Final.jar;D:\Repository\com\clearspring\analytics\stream\2.7.0\stream-2.7.0.jar;D:\Repository\io\dropwizard\metrics\metrics-core\3.1.2\metrics-core-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-jvm\3.1.2\metrics-jvm-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-json\3.1.2\metrics-json-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-graphite\3.1.2\metrics-graphite-3.1.2.jar;D:\Repository\com\fasterxml\jackson\core\jackson-databind\2.6.5\jackson-databind-2.6.5.jar;D:\Repository\com\fasterxml\jackson\core\jackson-core\2.6.5\jackson-core-2.6.5.jar;D:\Repository\com\fasterxml\jackson\module\jackson-module-scala_2.11\2.6.5\jackson-module-scala_2.11-2.6.5.jar;D:\Repository\org\scala-lang\scala-reflect\2.11.7\scala-reflect-2.11.7.jar;D:\Repository\com\fasterxml\jackson\module\jackson-module-paranamer\2.6.5\jackson-module-paranamer-2.6.5.jar;D:\Repository\org\apache\ivy\ivy\2.4.0\ivy-2.4.0.jar;D:\Repository\oro\oro\2.0.8\oro-2.0.8.jar;D:\Repository\net\razorvine\pyrolite\4.13\pyrolite-4.13.jar;D:\Repository\net\sf\py4j\py4j\0.10.4\py4j-0.10.4.jar;D:\Repository\org\apache\spark\spark-tags_2.11\2.1.0\spark-tags_2.11-2.1.0.jar;D:\Repository\org\scalatest\scalatest_2.11\2.2.6\scalatest_2.11-2.2.6.jar;D:\Repository\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;D:\Repository\org\spark-project\spark\unused\1.0.0\unused-1.0.0.jar;D:\Repository\org\apache\spark\spark-streaming_2.11\2.1.0\spark-streaming_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-sql_2.11\2.1.0\spark-sql_2.11-2.1.0.jar;D:\Repository\com\univocity\univocity-parsers\2.2.1\univocity-parsers-2.2.1.jar;D:\Repository\org\apache\spark\spark-sketch_2.11\2.1.0\spark-sketch_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-catalyst_2.11\2.1.0\spark-catalyst_2.11-2.1.0.jar;D:\Repository\org\codehaus\janino\janino\3.0.0\janino-3.0.0.jar;D:\Repository\org\codehaus\janino\commons-compiler\3.0.0\commons-compiler-3.0.0.jar;D:\Repository\org\antlr\antlr4-runtime\4.5.3\antlr4-runtime-4.5.3.jar;D:\Repository\org\apache\parquet\parquet-column\1.8.1\parquet-column-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-common\1.8.1\parquet-common-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-encoding\1.8.1\parquet-encoding-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-hadoop\1.8.1\parquet-hadoop-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-format\2.3.0-incubating\parquet-format-2.3.0-incubating.jar;D:\Repository\org\apache\parquet\parquet-jackson\1.8.1\parquet-jackson-1.8.1.jar;D:\Repository\org\apache\hadoop\hadoop-client\2.6.5\hadoop-client-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-common\2.6.5\hadoop-common-2.6.5.jar;D:\Repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;D:\Repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;D:\Repository\commons-io\commons-io\2.4\commons-io-2.4.jar;D:\Repository\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;D:\Repository\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;D:\Repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\Repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;D:\Repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;D:\Repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;D:\Repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;D:\Repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;D:\Repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;D:\Repository\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;D:\Repository\org\apache\hadoop\hadoop-auth\2.6.5\hadoop-auth-2.6.5.jar;D:\Repository\org\apache\httpcomponents\httpclient\4.2.5\httpclient-4.2.5.jar;D:\Repository\org\apache\httpcomponents\httpcore\4.2.4\httpcore-4.2.4.jar;D:\Repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;D:\Repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;D:\Repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;D:\Repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;D:\Repository\org\apache\curator\curator-client\2.6.0\curator-client-2.6.0.jar;D:\Repository\org\htrace\htrace-core\3.0.4\htrace-core-3.0.4.jar;D:\Repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;D:\Repository\org\tukaani\xz\1.0\xz-1.0.jar;D:\Repository\org\apache\hadoop\hadoop-hdfs\2.6.5\hadoop-hdfs-2.6.5.jar;D:\Repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;D:\Repository\xerces\xercesImpl\2.9.1\xercesImpl-2.9.1.jar;D:\Repository\xml-apis\xml-apis\1.3.04\xml-apis-1.3.04.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.6.5\hadoop-mapreduce-client-app-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.6.5\hadoop-mapreduce-client-common-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-client\2.6.5\hadoop-yarn-client-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-server-common\2.6.5\hadoop-yarn-server-common-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.6.5\hadoop-mapreduce-client-shuffle-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-api\2.6.5\hadoop-yarn-api-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.6.5\hadoop-mapreduce-client-core-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-common\2.6.5\hadoop-yarn-common-2.6.5.jar;D:\Repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;D:\Repository\javax\xml\stream\stax-api\1.0-2\stax-api-1.0-2.jar;D:\Repository\javax\activation\activation\1.1\activation-1.1.jar;D:\Repository\javax\servlet\servlet-api\2.5\servlet-api-2.5.jar;D:\Repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;D:\Repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;D:\Repository\org\codehaus\jackson\jackson-jaxrs\1.9.13\jackson-jaxrs-1.9.13.jar;D:\Repository\org\codehaus\jackson\jackson-xc\1.9.13\jackson-xc-1.9.13.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.6.5\hadoop-mapreduce-client-jobclient-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-annotations\2.6.5\hadoop-annotations-2.6.5.jar;D:\Repository\org\apache\kafka\kafka-clients\0.8.2.2\kafka-clients-0.8.2.2.jar;D:\Repository\org\apache\kafka\kafka_2.11\0.8.2.2\kafka_2.11-0.8.2.2.jar;D:\Repository\org\scala-lang\modules\scala-xml_2.11\1.0.2\scala-xml_2.11-1.0.2.jar;D:\Repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;D:\Repository\net\sf\jopt-simple\jopt-simple\3.2\jopt-simple-3.2.jar;D:\Repository\org\scala-lang\modules\scala-parser-combinators_2.11\1.0.2\scala-parser-combinators_2.11-1.0.2.jar;D:\Repository\com\101tec\zkclient\0.3\zkclient-0.3.jar;D:\Repository\mysql\mysql-connector-java\5.1.38\mysql-connector-java-5.1.38.jar;D:\Repository\org\apache\spark\spark-streaming-kafka-0-8_2.11\2.1.0\spark-streaming-kafka-0-8_2.11-2.1.0.jar;D:\Repository\org\apache\zookeeper\zookeeper\3.4.10\zookeeper-3.4.10.jar;D:\Repository\jline\jline\0.9.94\jline-0.9.94.jar;D:\developTools\IntelliJ IDEA 2018.2.3\lib\idea_rt.jar
2018-12-26 16:30:27 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_171\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;D:\developTools\Git\cmd;D:\developTools\svn\bin;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\scala\bin;C:\Users\junmei02\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk1.8.0_171\bin;D:\developTools\apache-maven-3.5.2\bin;D:\developTools\mysql-5.6.27-winx64\bin;D:\developTools\Git\cmd;D:\hadoop\hadoop-common-2.2.0-bin-master\bin;D:\hadoop\hbase-1.2.6\bin;C:\Program Files (x86)\scala\bin;D:\bigdata\zookeeper-3.4.10\bin;;.
2018-12-26 16:30:27 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.io.tmpdir=C:\Users\junmei02\AppData\Local\Temp\
2018-12-26 16:30:27 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.compiler=<NA>
2018-12-26 16:30:27 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.name=Windows 10
2018-12-26 16:30:27 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.arch=amd64
2018-12-26 16:30:27 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.version=10.0
2018-12-26 16:30:27 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.name=junmei02
2018-12-26 16:30:27 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.home=C:\Users\junmei02
2018-12-26 16:30:27 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.dir=D:\springbootworkspace\spark
2018-12-26 16:30:27 [ INFO ] - [ org.apache.zookeeper.ZooKeeper.<init>(ZooKeeper.java:438) ] Initiating client connection, connectString=127.0.0.1:2181 sessionTimeout=10000 watcher=org.apache.curator.ConnectionState@2034b64c
2018-12-26 16:30:27 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:1032) ] Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2018-12-26 16:30:27 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$SendThread.primeConnection(ClientCnxn.java:876) ] Socket connection established to 127.0.0.1/127.0.0.1:2181, initiating session
2018-12-26 16:30:27 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$SendThread.onConnected(ClientCnxn.java:1299) ] Session establishment complete on server 127.0.0.1/127.0.0.1:2181, sessionid = 0x167e991b4b60005, negotiated timeout = 10000
2018-12-26 16:30:27 [ INFO ] - [ org.apache.curator.framework.state.ConnectionStateManager.postState(ConnectionStateManager.java:194) ] State change: CONNECTED
2018-12-26 16:30:27 [ WARN ] - [ org.apache.curator.framework.state.ConnectionStateManager.processEvents(ConnectionStateManager.java:212) ] There are no ConnectionStateListeners registered.
2018-12-26 16:30:28 [ INFO ] - [ org.apache.zookeeper.ZooKeeper.close(ZooKeeper.java:684) ] Session: 0x167e991b4b60005 closed
2018-12-26 16:30:28 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:519) ] EventThread shut down for session: 0x167e991b4b60005
2018-12-26 16:30:29 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Running Spark version 2.1.0
2018-12-26 16:30:30 [ ERROR ] - [ org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:396) ] Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2373)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2373)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2373)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:837)
	at org.apache.spark.streaming.StreamingContext.<init>(StreamingContext.scala:84)
	at org.apache.spark.streaming.api.java.JavaStreamingContext.<init>(JavaStreamingContext.scala:138)
	at com.zqg.StreamKafka.KafkaSparkStreamingWithZookeeperoffset.main(KafkaSparkStreamingWithZookeeperoffset.java:67)
2018-12-26 16:30:30 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing view acls to: junmei02
2018-12-26 16:30:30 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing modify acls to: junmei02
2018-12-26 16:30:30 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing view acls groups to: 
2018-12-26 16:30:30 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing modify acls groups to: 
2018-12-26 16:30:30 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(junmei02); groups with view permissions: Set(); users  with modify permissions: Set(junmei02); groups with modify permissions: Set()
2018-12-26 16:30:30 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'sparkDriver' on port 55430.
2018-12-26 16:30:30 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering MapOutputTracker
2018-12-26 16:30:30 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering BlockManagerMaster
2018-12-26 16:30:30 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-26 16:30:30 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] BlockManagerMasterEndpoint up
2018-12-26 16:30:30 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Created local directory at C:\Users\junmei02\AppData\Local\Temp\blockmgr-774ae8d2-66b3-4b7c-948c-5248aaf09001
2018-12-26 16:30:30 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] MemoryStore started with capacity 900.6 MB
2018-12-26 16:30:30 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering OutputCommitCoordinator
2018-12-26 16:30:30 [ INFO ] - [ org.spark_project.jetty.util.log.Log.initialized(Log.java:186) ] Logging initialized @5255ms
2018-12-26 16:30:30 [ INFO ] - [ org.spark_project.jetty.server.Server.doStart(Server.java:327) ] jetty-9.2.z-SNAPSHOT
2018-12-26 16:30:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@56193c7d{/jobs,null,AVAILABLE}
2018-12-26 16:30:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@28c88600{/jobs/json,null,AVAILABLE}
2018-12-26 16:30:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@5f8890c2{/jobs/job,null,AVAILABLE}
2018-12-26 16:30:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@607b2792{/jobs/job/json,null,AVAILABLE}
2018-12-26 16:30:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@7f9e1534{/stages,null,AVAILABLE}
2018-12-26 16:30:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@138a7441{/stages/json,null,AVAILABLE}
2018-12-26 16:30:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@81ff872{/stages/stage,null,AVAILABLE}
2018-12-26 16:30:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@31611954{/stages/stage/json,null,AVAILABLE}
2018-12-26 16:30:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@3e598df9{/stages/pool,null,AVAILABLE}
2018-12-26 16:30:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@7e31ce0f{/stages/pool/json,null,AVAILABLE}
2018-12-26 16:30:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@99a65d3{/storage,null,AVAILABLE}
2018-12-26 16:30:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@3088660d{/storage/json,null,AVAILABLE}
2018-12-26 16:30:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@42cc13a0{/storage/rdd,null,AVAILABLE}
2018-12-26 16:30:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@32fdec40{/storage/rdd/json,null,AVAILABLE}
2018-12-26 16:30:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@6813a331{/environment,null,AVAILABLE}
2018-12-26 16:30:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@1bd81830{/environment/json,null,AVAILABLE}
2018-12-26 16:30:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@39ab59f8{/executors,null,AVAILABLE}
2018-12-26 16:30:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@64e92d61{/executors/json,null,AVAILABLE}
2018-12-26 16:30:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@111610e6{/executors/threadDump,null,AVAILABLE}
2018-12-26 16:30:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@4ad4936c{/executors/threadDump/json,null,AVAILABLE}
2018-12-26 16:30:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@29d37757{/static,null,AVAILABLE}
2018-12-26 16:30:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@4fcc529{/,null,AVAILABLE}
2018-12-26 16:30:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@25cc7470{/api,null,AVAILABLE}
2018-12-26 16:30:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@4beddc56{/jobs/job/kill,null,AVAILABLE}
2018-12-26 16:30:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@79b663b3{/stages/stage/kill,null,AVAILABLE}
2018-12-26 16:30:31 [ INFO ] - [ org.spark_project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:266) ] Started ServerConnector@155d1021{HTTP/1.1}{0.0.0.0:4040}
2018-12-26 16:30:31 [ INFO ] - [ org.spark_project.jetty.server.Server.doStart(Server.java:379) ] Started @5461ms
2018-12-26 16:30:31 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'SparkUI' on port 4040.
2018-12-26 16:30:31 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Bound SparkUI to 0.0.0.0, and started at http://192.168.0.112:4040
2018-12-26 16:30:31 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Starting executor ID driver on host localhost
2018-12-26 16:30:31 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55451.
2018-12-26 16:30:31 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Server created on 192.168.0.112:55451
2018-12-26 16:30:31 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-26 16:30:31 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering BlockManager BlockManagerId(driver, 192.168.0.112, 55451, None)
2018-12-26 16:30:31 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering block manager 192.168.0.112:55451 with 900.6 MB RAM, BlockManagerId(driver, 192.168.0.112, 55451, None)
2018-12-26 16:30:31 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registered BlockManager BlockManagerId(driver, 192.168.0.112, 55451, None)
2018-12-26 16:30:31 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Initialized BlockManager: BlockManagerId(driver, 192.168.0.112, 55451, None)
2018-12-26 16:30:31 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@35f8a9d3{/metrics/json,null,AVAILABLE}
2018-12-26 16:32:09 [ INFO ] - [ org.apache.curator.framework.imps.CuratorFrameworkImpl.start(CuratorFrameworkImpl.java:223) ] Starting
2018-12-26 16:32:09 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT
2018-12-26 16:32:09 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:host.name=windows10.microdone.cn
2018-12-26 16:32:09 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.version=1.8.0_171
2018-12-26 16:32:09 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.vendor=Oracle Corporation
2018-12-26 16:32:09 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.home=C:\Program Files\Java\jdk1.8.0_171\jre
2018-12-26 16:32:09 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.class.path=C:\Program Files\Java\jdk1.8.0_171\jre\lib\charsets.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\deploy.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\access-bridge-64.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\cldrdata.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\dnsns.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\jaccess.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\jfxrt.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\localedata.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\nashorn.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunec.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunjce_provider.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunmscapi.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunpkcs11.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\zipfs.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\javaws.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jce.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jfr.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jfxswt.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jsse.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\management-agent.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\plugin.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\resources.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\rt.jar;D:\springbootworkspace\spark\target\classes;D:\Repository\org\scala-lang\scala-library\2.11.8\scala-library-2.11.8.jar;D:\Repository\org\apache\spark\spark-core_2.11\2.1.0\spark-core_2.11-2.1.0.jar;D:\Repository\org\apache\avro\avro-mapred\1.7.7\avro-mapred-1.7.7-hadoop2.jar;D:\Repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7.jar;D:\Repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7-tests.jar;D:\Repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;D:\Repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;D:\Repository\com\twitter\chill_2.11\0.8.0\chill_2.11-0.8.0.jar;D:\Repository\com\esotericsoftware\kryo-shaded\3.0.3\kryo-shaded-3.0.3.jar;D:\Repository\com\esotericsoftware\minlog\1.3.0\minlog-1.3.0.jar;D:\Repository\org\objenesis\objenesis\2.1\objenesis-2.1.jar;D:\Repository\com\twitter\chill-java\0.8.0\chill-java-0.8.0.jar;D:\Repository\org\apache\xbean\xbean-asm5-shaded\4.4\xbean-asm5-shaded-4.4.jar;D:\Repository\org\apache\spark\spark-launcher_2.11\2.1.0\spark-launcher_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-network-common_2.11\2.1.0\spark-network-common_2.11-2.1.0.jar;D:\Repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;D:\Repository\com\fasterxml\jackson\core\jackson-annotations\2.6.5\jackson-annotations-2.6.5.jar;D:\Repository\org\apache\spark\spark-network-shuffle_2.11\2.1.0\spark-network-shuffle_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-unsafe_2.11\2.1.0\spark-unsafe_2.11-2.1.0.jar;D:\Repository\net\java\dev\jets3t\jets3t\0.7.1\jets3t-0.7.1.jar;D:\Repository\commons-codec\commons-codec\1.3\commons-codec-1.3.jar;D:\Repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;D:\Repository\org\apache\curator\curator-recipes\2.4.0\curator-recipes-2.4.0.jar;D:\Repository\org\apache\curator\curator-framework\2.4.0\curator-framework-2.4.0.jar;D:\Repository\com\google\guava\guava\14.0.1\guava-14.0.1.jar;D:\Repository\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;D:\Repository\org\apache\commons\commons-lang3\3.5\commons-lang3-3.5.jar;D:\Repository\org\apache\commons\commons-math3\3.4.1\commons-math3-3.4.1.jar;D:\Repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;D:\Repository\org\slf4j\slf4j-api\1.7.16\slf4j-api-1.7.16.jar;D:\Repository\org\slf4j\jul-to-slf4j\1.7.16\jul-to-slf4j-1.7.16.jar;D:\Repository\org\slf4j\jcl-over-slf4j\1.7.16\jcl-over-slf4j-1.7.16.jar;D:\Repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;D:\Repository\org\slf4j\slf4j-log4j12\1.7.16\slf4j-log4j12-1.7.16.jar;D:\Repository\com\ning\compress-lzf\1.0.3\compress-lzf-1.0.3.jar;D:\Repository\org\xerial\snappy\snappy-java\1.1.2.6\snappy-java-1.1.2.6.jar;D:\Repository\net\jpountz\lz4\lz4\1.3.0\lz4-1.3.0.jar;D:\Repository\org\roaringbitmap\RoaringBitmap\0.5.11\RoaringBitmap-0.5.11.jar;D:\Repository\commons-net\commons-net\2.2\commons-net-2.2.jar;D:\Repository\org\json4s\json4s-jackson_2.11\3.2.11\json4s-jackson_2.11-3.2.11.jar;D:\Repository\org\json4s\json4s-core_2.11\3.2.11\json4s-core_2.11-3.2.11.jar;D:\Repository\org\json4s\json4s-ast_2.11\3.2.11\json4s-ast_2.11-3.2.11.jar;D:\Repository\com\thoughtworks\paranamer\paranamer\2.6\paranamer-2.6.jar;D:\Repository\org\scala-lang\scalap\2.11.0\scalap-2.11.0.jar;D:\Repository\org\scala-lang\scala-compiler\2.11.0\scala-compiler-2.11.0.jar;D:\Repository\org\glassfish\jersey\core\jersey-client\2.22.2\jersey-client-2.22.2.jar;D:\Repository\javax\ws\rs\javax.ws.rs-api\2.0.1\javax.ws.rs-api-2.0.1.jar;D:\Repository\org\glassfish\hk2\hk2-api\2.4.0-b34\hk2-api-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\hk2-utils\2.4.0-b34\hk2-utils-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\external\aopalliance-repackaged\2.4.0-b34\aopalliance-repackaged-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\external\javax.inject\2.4.0-b34\javax.inject-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\hk2-locator\2.4.0-b34\hk2-locator-2.4.0-b34.jar;D:\Repository\org\javassist\javassist\3.18.1-GA\javassist-3.18.1-GA.jar;D:\Repository\org\glassfish\jersey\core\jersey-common\2.22.2\jersey-common-2.22.2.jar;D:\Repository\javax\annotation\javax.annotation-api\1.2\javax.annotation-api-1.2.jar;D:\Repository\org\glassfish\jersey\bundles\repackaged\jersey-guava\2.22.2\jersey-guava-2.22.2.jar;D:\Repository\org\glassfish\hk2\osgi-resource-locator\1.0.1\osgi-resource-locator-1.0.1.jar;D:\Repository\org\glassfish\jersey\core\jersey-server\2.22.2\jersey-server-2.22.2.jar;D:\Repository\org\glassfish\jersey\media\jersey-media-jaxb\2.22.2\jersey-media-jaxb-2.22.2.jar;D:\Repository\javax\validation\validation-api\1.1.0.Final\validation-api-1.1.0.Final.jar;D:\Repository\org\glassfish\jersey\containers\jersey-container-servlet\2.22.2\jersey-container-servlet-2.22.2.jar;D:\Repository\org\glassfish\jersey\containers\jersey-container-servlet-core\2.22.2\jersey-container-servlet-core-2.22.2.jar;D:\Repository\io\netty\netty-all\4.0.42.Final\netty-all-4.0.42.Final.jar;D:\Repository\io\netty\netty\3.8.0.Final\netty-3.8.0.Final.jar;D:\Repository\com\clearspring\analytics\stream\2.7.0\stream-2.7.0.jar;D:\Repository\io\dropwizard\metrics\metrics-core\3.1.2\metrics-core-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-jvm\3.1.2\metrics-jvm-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-json\3.1.2\metrics-json-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-graphite\3.1.2\metrics-graphite-3.1.2.jar;D:\Repository\com\fasterxml\jackson\core\jackson-databind\2.6.5\jackson-databind-2.6.5.jar;D:\Repository\com\fasterxml\jackson\core\jackson-core\2.6.5\jackson-core-2.6.5.jar;D:\Repository\com\fasterxml\jackson\module\jackson-module-scala_2.11\2.6.5\jackson-module-scala_2.11-2.6.5.jar;D:\Repository\org\scala-lang\scala-reflect\2.11.7\scala-reflect-2.11.7.jar;D:\Repository\com\fasterxml\jackson\module\jackson-module-paranamer\2.6.5\jackson-module-paranamer-2.6.5.jar;D:\Repository\org\apache\ivy\ivy\2.4.0\ivy-2.4.0.jar;D:\Repository\oro\oro\2.0.8\oro-2.0.8.jar;D:\Repository\net\razorvine\pyrolite\4.13\pyrolite-4.13.jar;D:\Repository\net\sf\py4j\py4j\0.10.4\py4j-0.10.4.jar;D:\Repository\org\apache\spark\spark-tags_2.11\2.1.0\spark-tags_2.11-2.1.0.jar;D:\Repository\org\scalatest\scalatest_2.11\2.2.6\scalatest_2.11-2.2.6.jar;D:\Repository\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;D:\Repository\org\spark-project\spark\unused\1.0.0\unused-1.0.0.jar;D:\Repository\org\apache\spark\spark-streaming_2.11\2.1.0\spark-streaming_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-sql_2.11\2.1.0\spark-sql_2.11-2.1.0.jar;D:\Repository\com\univocity\univocity-parsers\2.2.1\univocity-parsers-2.2.1.jar;D:\Repository\org\apache\spark\spark-sketch_2.11\2.1.0\spark-sketch_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-catalyst_2.11\2.1.0\spark-catalyst_2.11-2.1.0.jar;D:\Repository\org\codehaus\janino\janino\3.0.0\janino-3.0.0.jar;D:\Repository\org\codehaus\janino\commons-compiler\3.0.0\commons-compiler-3.0.0.jar;D:\Repository\org\antlr\antlr4-runtime\4.5.3\antlr4-runtime-4.5.3.jar;D:\Repository\org\apache\parquet\parquet-column\1.8.1\parquet-column-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-common\1.8.1\parquet-common-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-encoding\1.8.1\parquet-encoding-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-hadoop\1.8.1\parquet-hadoop-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-format\2.3.0-incubating\parquet-format-2.3.0-incubating.jar;D:\Repository\org\apache\parquet\parquet-jackson\1.8.1\parquet-jackson-1.8.1.jar;D:\Repository\org\apache\hadoop\hadoop-client\2.6.5\hadoop-client-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-common\2.6.5\hadoop-common-2.6.5.jar;D:\Repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;D:\Repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;D:\Repository\commons-io\commons-io\2.4\commons-io-2.4.jar;D:\Repository\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;D:\Repository\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;D:\Repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\Repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;D:\Repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;D:\Repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;D:\Repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;D:\Repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;D:\Repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;D:\Repository\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;D:\Repository\org\apache\hadoop\hadoop-auth\2.6.5\hadoop-auth-2.6.5.jar;D:\Repository\org\apache\httpcomponents\httpclient\4.2.5\httpclient-4.2.5.jar;D:\Repository\org\apache\httpcomponents\httpcore\4.2.4\httpcore-4.2.4.jar;D:\Repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;D:\Repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;D:\Repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;D:\Repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;D:\Repository\org\apache\curator\curator-client\2.6.0\curator-client-2.6.0.jar;D:\Repository\org\htrace\htrace-core\3.0.4\htrace-core-3.0.4.jar;D:\Repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;D:\Repository\org\tukaani\xz\1.0\xz-1.0.jar;D:\Repository\org\apache\hadoop\hadoop-hdfs\2.6.5\hadoop-hdfs-2.6.5.jar;D:\Repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;D:\Repository\xerces\xercesImpl\2.9.1\xercesImpl-2.9.1.jar;D:\Repository\xml-apis\xml-apis\1.3.04\xml-apis-1.3.04.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.6.5\hadoop-mapreduce-client-app-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.6.5\hadoop-mapreduce-client-common-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-client\2.6.5\hadoop-yarn-client-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-server-common\2.6.5\hadoop-yarn-server-common-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.6.5\hadoop-mapreduce-client-shuffle-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-api\2.6.5\hadoop-yarn-api-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.6.5\hadoop-mapreduce-client-core-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-common\2.6.5\hadoop-yarn-common-2.6.5.jar;D:\Repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;D:\Repository\javax\xml\stream\stax-api\1.0-2\stax-api-1.0-2.jar;D:\Repository\javax\activation\activation\1.1\activation-1.1.jar;D:\Repository\javax\servlet\servlet-api\2.5\servlet-api-2.5.jar;D:\Repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;D:\Repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;D:\Repository\org\codehaus\jackson\jackson-jaxrs\1.9.13\jackson-jaxrs-1.9.13.jar;D:\Repository\org\codehaus\jackson\jackson-xc\1.9.13\jackson-xc-1.9.13.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.6.5\hadoop-mapreduce-client-jobclient-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-annotations\2.6.5\hadoop-annotations-2.6.5.jar;D:\Repository\org\apache\kafka\kafka-clients\0.8.2.2\kafka-clients-0.8.2.2.jar;D:\Repository\org\apache\kafka\kafka_2.11\0.8.2.2\kafka_2.11-0.8.2.2.jar;D:\Repository\org\scala-lang\modules\scala-xml_2.11\1.0.2\scala-xml_2.11-1.0.2.jar;D:\Repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;D:\Repository\net\sf\jopt-simple\jopt-simple\3.2\jopt-simple-3.2.jar;D:\Repository\org\scala-lang\modules\scala-parser-combinators_2.11\1.0.2\scala-parser-combinators_2.11-1.0.2.jar;D:\Repository\com\101tec\zkclient\0.3\zkclient-0.3.jar;D:\Repository\mysql\mysql-connector-java\5.1.38\mysql-connector-java-5.1.38.jar;D:\Repository\org\apache\spark\spark-streaming-kafka-0-8_2.11\2.1.0\spark-streaming-kafka-0-8_2.11-2.1.0.jar;D:\Repository\org\apache\zookeeper\zookeeper\3.4.10\zookeeper-3.4.10.jar;D:\Repository\jline\jline\0.9.94\jline-0.9.94.jar;D:\developTools\IntelliJ IDEA 2018.2.3\lib\idea_rt.jar
2018-12-26 16:32:09 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_171\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;D:\developTools\Git\cmd;D:\developTools\svn\bin;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\scala\bin;C:\Users\junmei02\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk1.8.0_171\bin;D:\developTools\apache-maven-3.5.2\bin;D:\developTools\mysql-5.6.27-winx64\bin;D:\developTools\Git\cmd;D:\hadoop\hadoop-common-2.2.0-bin-master\bin;D:\hadoop\hbase-1.2.6\bin;C:\Program Files (x86)\scala\bin;D:\bigdata\zookeeper-3.4.10\bin;;.
2018-12-26 16:32:09 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.io.tmpdir=C:\Users\junmei02\AppData\Local\Temp\
2018-12-26 16:32:09 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.compiler=<NA>
2018-12-26 16:32:09 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.name=Windows 10
2018-12-26 16:32:09 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.arch=amd64
2018-12-26 16:32:09 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.version=10.0
2018-12-26 16:32:09 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.name=junmei02
2018-12-26 16:32:09 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.home=C:\Users\junmei02
2018-12-26 16:32:09 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.dir=D:\springbootworkspace\spark
2018-12-26 16:32:09 [ INFO ] - [ org.apache.zookeeper.ZooKeeper.<init>(ZooKeeper.java:438) ] Initiating client connection, connectString=127.0.0.1:2181 sessionTimeout=10000 watcher=org.apache.curator.ConnectionState@2034b64c
2018-12-26 16:32:09 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:1032) ] Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2018-12-26 16:32:09 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$SendThread.primeConnection(ClientCnxn.java:876) ] Socket connection established to 127.0.0.1/127.0.0.1:2181, initiating session
2018-12-26 16:32:09 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$SendThread.onConnected(ClientCnxn.java:1299) ] Session establishment complete on server 127.0.0.1/127.0.0.1:2181, sessionid = 0x167e991b4b60006, negotiated timeout = 10000
2018-12-26 16:32:09 [ INFO ] - [ org.apache.curator.framework.state.ConnectionStateManager.postState(ConnectionStateManager.java:194) ] State change: CONNECTED
2018-12-26 16:32:09 [ WARN ] - [ org.apache.curator.framework.state.ConnectionStateManager.processEvents(ConnectionStateManager.java:212) ] There are no ConnectionStateListeners registered.
2018-12-26 16:32:10 [ INFO ] - [ org.apache.zookeeper.ZooKeeper.close(ZooKeeper.java:684) ] Session: 0x167e991b4b60006 closed
2018-12-26 16:32:10 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:519) ] EventThread shut down for session: 0x167e991b4b60006
2018-12-26 16:32:11 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Running Spark version 2.1.0
2018-12-26 16:32:12 [ ERROR ] - [ org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:396) ] Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2373)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2373)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2373)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:837)
	at org.apache.spark.streaming.StreamingContext.<init>(StreamingContext.scala:84)
	at org.apache.spark.streaming.api.java.JavaStreamingContext.<init>(JavaStreamingContext.scala:138)
	at com.zqg.StreamKafka.KafkaSparkStreamingWithZookeeperoffset.main(KafkaSparkStreamingWithZookeeperoffset.java:67)
2018-12-26 16:32:12 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing view acls to: junmei02
2018-12-26 16:32:12 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing modify acls to: junmei02
2018-12-26 16:32:12 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing view acls groups to: 
2018-12-26 16:32:12 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing modify acls groups to: 
2018-12-26 16:32:12 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(junmei02); groups with view permissions: Set(); users  with modify permissions: Set(junmei02); groups with modify permissions: Set()
2018-12-26 16:32:12 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'sparkDriver' on port 55520.
2018-12-26 16:32:12 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering MapOutputTracker
2018-12-26 16:32:12 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering BlockManagerMaster
2018-12-26 16:32:12 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-26 16:32:12 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] BlockManagerMasterEndpoint up
2018-12-26 16:32:12 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Created local directory at C:\Users\junmei02\AppData\Local\Temp\blockmgr-a2b46aa5-470a-4933-828e-51e1bc98fd59
2018-12-26 16:32:12 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] MemoryStore started with capacity 900.6 MB
2018-12-26 16:32:12 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering OutputCommitCoordinator
2018-12-26 16:32:12 [ INFO ] - [ org.spark_project.jetty.util.log.Log.initialized(Log.java:186) ] Logging initialized @4518ms
2018-12-26 16:32:12 [ INFO ] - [ org.spark_project.jetty.server.Server.doStart(Server.java:327) ] jetty-9.2.z-SNAPSHOT
2018-12-26 16:32:12 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@5f8890c2{/jobs,null,AVAILABLE}
2018-12-26 16:32:12 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@607b2792{/jobs/json,null,AVAILABLE}
2018-12-26 16:32:12 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@7f9e1534{/jobs/job,null,AVAILABLE}
2018-12-26 16:32:12 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@138a7441{/jobs/job/json,null,AVAILABLE}
2018-12-26 16:32:12 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@81ff872{/stages,null,AVAILABLE}
2018-12-26 16:32:12 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@31611954{/stages/json,null,AVAILABLE}
2018-12-26 16:32:12 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@3e598df9{/stages/stage,null,AVAILABLE}
2018-12-26 16:32:12 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@7e31ce0f{/stages/stage/json,null,AVAILABLE}
2018-12-26 16:32:12 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@99a65d3{/stages/pool,null,AVAILABLE}
2018-12-26 16:32:12 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@3088660d{/stages/pool/json,null,AVAILABLE}
2018-12-26 16:32:12 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@42cc13a0{/storage,null,AVAILABLE}
2018-12-26 16:32:12 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@32fdec40{/storage/json,null,AVAILABLE}
2018-12-26 16:32:12 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@6813a331{/storage/rdd,null,AVAILABLE}
2018-12-26 16:32:12 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@1bd81830{/storage/rdd/json,null,AVAILABLE}
2018-12-26 16:32:12 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@39ab59f8{/environment,null,AVAILABLE}
2018-12-26 16:32:12 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@64e92d61{/environment/json,null,AVAILABLE}
2018-12-26 16:32:12 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@111610e6{/executors,null,AVAILABLE}
2018-12-26 16:32:12 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@4ad4936c{/executors/json,null,AVAILABLE}
2018-12-26 16:32:12 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@29d37757{/executors/threadDump,null,AVAILABLE}
2018-12-26 16:32:12 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@4fcc529{/executors/threadDump/json,null,AVAILABLE}
2018-12-26 16:32:12 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@25cc7470{/static,null,AVAILABLE}
2018-12-26 16:32:12 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@4beddc56{/,null,AVAILABLE}
2018-12-26 16:32:12 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@79b663b3{/api,null,AVAILABLE}
2018-12-26 16:32:12 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@1b812421{/jobs/job/kill,null,AVAILABLE}
2018-12-26 16:32:12 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@5d28bcd5{/stages/stage/kill,null,AVAILABLE}
2018-12-26 16:32:12 [ INFO ] - [ org.spark_project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:266) ] Started ServerConnector@1f27c7f0{HTTP/1.1}{0.0.0.0:4040}
2018-12-26 16:32:12 [ INFO ] - [ org.spark_project.jetty.server.Server.doStart(Server.java:379) ] Started @4669ms
2018-12-26 16:32:12 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'SparkUI' on port 4040.
2018-12-26 16:32:12 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Bound SparkUI to 0.0.0.0, and started at http://192.168.0.112:4040
2018-12-26 16:32:12 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Starting executor ID driver on host localhost
2018-12-26 16:32:12 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55541.
2018-12-26 16:32:12 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Server created on 192.168.0.112:55541
2018-12-26 16:32:12 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-26 16:32:12 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering BlockManager BlockManagerId(driver, 192.168.0.112, 55541, None)
2018-12-26 16:32:12 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering block manager 192.168.0.112:55541 with 900.6 MB RAM, BlockManagerId(driver, 192.168.0.112, 55541, None)
2018-12-26 16:32:12 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registered BlockManager BlockManagerId(driver, 192.168.0.112, 55541, None)
2018-12-26 16:32:12 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Initialized BlockManager: BlockManagerId(driver, 192.168.0.112, 55541, None)
2018-12-26 16:32:12 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@48ea2003{/metrics/json,null,AVAILABLE}
2018-12-26 16:46:22 [ INFO ] - [ org.apache.curator.framework.imps.CuratorFrameworkImpl.start(CuratorFrameworkImpl.java:223) ] Starting
2018-12-26 16:46:22 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT
2018-12-26 16:46:22 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:host.name=windows10.microdone.cn
2018-12-26 16:46:22 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.version=1.8.0_171
2018-12-26 16:46:22 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.vendor=Oracle Corporation
2018-12-26 16:46:22 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.home=C:\Program Files\Java\jdk1.8.0_171\jre
2018-12-26 16:46:22 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.class.path=C:\Program Files\Java\jdk1.8.0_171\jre\lib\charsets.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\deploy.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\access-bridge-64.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\cldrdata.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\dnsns.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\jaccess.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\jfxrt.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\localedata.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\nashorn.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunec.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunjce_provider.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunmscapi.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunpkcs11.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\zipfs.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\javaws.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jce.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jfr.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jfxswt.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jsse.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\management-agent.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\plugin.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\resources.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\rt.jar;D:\springbootworkspace\spark\target\classes;D:\Repository\org\scala-lang\scala-library\2.11.8\scala-library-2.11.8.jar;D:\Repository\org\apache\spark\spark-core_2.11\2.1.0\spark-core_2.11-2.1.0.jar;D:\Repository\org\apache\avro\avro-mapred\1.7.7\avro-mapred-1.7.7-hadoop2.jar;D:\Repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7.jar;D:\Repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7-tests.jar;D:\Repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;D:\Repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;D:\Repository\com\twitter\chill_2.11\0.8.0\chill_2.11-0.8.0.jar;D:\Repository\com\esotericsoftware\kryo-shaded\3.0.3\kryo-shaded-3.0.3.jar;D:\Repository\com\esotericsoftware\minlog\1.3.0\minlog-1.3.0.jar;D:\Repository\org\objenesis\objenesis\2.1\objenesis-2.1.jar;D:\Repository\com\twitter\chill-java\0.8.0\chill-java-0.8.0.jar;D:\Repository\org\apache\xbean\xbean-asm5-shaded\4.4\xbean-asm5-shaded-4.4.jar;D:\Repository\org\apache\spark\spark-launcher_2.11\2.1.0\spark-launcher_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-network-common_2.11\2.1.0\spark-network-common_2.11-2.1.0.jar;D:\Repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;D:\Repository\com\fasterxml\jackson\core\jackson-annotations\2.6.5\jackson-annotations-2.6.5.jar;D:\Repository\org\apache\spark\spark-network-shuffle_2.11\2.1.0\spark-network-shuffle_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-unsafe_2.11\2.1.0\spark-unsafe_2.11-2.1.0.jar;D:\Repository\net\java\dev\jets3t\jets3t\0.7.1\jets3t-0.7.1.jar;D:\Repository\commons-codec\commons-codec\1.3\commons-codec-1.3.jar;D:\Repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;D:\Repository\org\apache\curator\curator-recipes\2.4.0\curator-recipes-2.4.0.jar;D:\Repository\org\apache\curator\curator-framework\2.4.0\curator-framework-2.4.0.jar;D:\Repository\com\google\guava\guava\14.0.1\guava-14.0.1.jar;D:\Repository\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;D:\Repository\org\apache\commons\commons-lang3\3.5\commons-lang3-3.5.jar;D:\Repository\org\apache\commons\commons-math3\3.4.1\commons-math3-3.4.1.jar;D:\Repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;D:\Repository\org\slf4j\slf4j-api\1.7.16\slf4j-api-1.7.16.jar;D:\Repository\org\slf4j\jul-to-slf4j\1.7.16\jul-to-slf4j-1.7.16.jar;D:\Repository\org\slf4j\jcl-over-slf4j\1.7.16\jcl-over-slf4j-1.7.16.jar;D:\Repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;D:\Repository\org\slf4j\slf4j-log4j12\1.7.16\slf4j-log4j12-1.7.16.jar;D:\Repository\com\ning\compress-lzf\1.0.3\compress-lzf-1.0.3.jar;D:\Repository\org\xerial\snappy\snappy-java\1.1.2.6\snappy-java-1.1.2.6.jar;D:\Repository\net\jpountz\lz4\lz4\1.3.0\lz4-1.3.0.jar;D:\Repository\org\roaringbitmap\RoaringBitmap\0.5.11\RoaringBitmap-0.5.11.jar;D:\Repository\commons-net\commons-net\2.2\commons-net-2.2.jar;D:\Repository\org\json4s\json4s-jackson_2.11\3.2.11\json4s-jackson_2.11-3.2.11.jar;D:\Repository\org\json4s\json4s-core_2.11\3.2.11\json4s-core_2.11-3.2.11.jar;D:\Repository\org\json4s\json4s-ast_2.11\3.2.11\json4s-ast_2.11-3.2.11.jar;D:\Repository\com\thoughtworks\paranamer\paranamer\2.6\paranamer-2.6.jar;D:\Repository\org\scala-lang\scalap\2.11.0\scalap-2.11.0.jar;D:\Repository\org\scala-lang\scala-compiler\2.11.0\scala-compiler-2.11.0.jar;D:\Repository\org\glassfish\jersey\core\jersey-client\2.22.2\jersey-client-2.22.2.jar;D:\Repository\javax\ws\rs\javax.ws.rs-api\2.0.1\javax.ws.rs-api-2.0.1.jar;D:\Repository\org\glassfish\hk2\hk2-api\2.4.0-b34\hk2-api-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\hk2-utils\2.4.0-b34\hk2-utils-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\external\aopalliance-repackaged\2.4.0-b34\aopalliance-repackaged-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\external\javax.inject\2.4.0-b34\javax.inject-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\hk2-locator\2.4.0-b34\hk2-locator-2.4.0-b34.jar;D:\Repository\org\javassist\javassist\3.18.1-GA\javassist-3.18.1-GA.jar;D:\Repository\org\glassfish\jersey\core\jersey-common\2.22.2\jersey-common-2.22.2.jar;D:\Repository\javax\annotation\javax.annotation-api\1.2\javax.annotation-api-1.2.jar;D:\Repository\org\glassfish\jersey\bundles\repackaged\jersey-guava\2.22.2\jersey-guava-2.22.2.jar;D:\Repository\org\glassfish\hk2\osgi-resource-locator\1.0.1\osgi-resource-locator-1.0.1.jar;D:\Repository\org\glassfish\jersey\core\jersey-server\2.22.2\jersey-server-2.22.2.jar;D:\Repository\org\glassfish\jersey\media\jersey-media-jaxb\2.22.2\jersey-media-jaxb-2.22.2.jar;D:\Repository\javax\validation\validation-api\1.1.0.Final\validation-api-1.1.0.Final.jar;D:\Repository\org\glassfish\jersey\containers\jersey-container-servlet\2.22.2\jersey-container-servlet-2.22.2.jar;D:\Repository\org\glassfish\jersey\containers\jersey-container-servlet-core\2.22.2\jersey-container-servlet-core-2.22.2.jar;D:\Repository\io\netty\netty-all\4.0.42.Final\netty-all-4.0.42.Final.jar;D:\Repository\io\netty\netty\3.8.0.Final\netty-3.8.0.Final.jar;D:\Repository\com\clearspring\analytics\stream\2.7.0\stream-2.7.0.jar;D:\Repository\io\dropwizard\metrics\metrics-core\3.1.2\metrics-core-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-jvm\3.1.2\metrics-jvm-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-json\3.1.2\metrics-json-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-graphite\3.1.2\metrics-graphite-3.1.2.jar;D:\Repository\com\fasterxml\jackson\core\jackson-databind\2.6.5\jackson-databind-2.6.5.jar;D:\Repository\com\fasterxml\jackson\core\jackson-core\2.6.5\jackson-core-2.6.5.jar;D:\Repository\com\fasterxml\jackson\module\jackson-module-scala_2.11\2.6.5\jackson-module-scala_2.11-2.6.5.jar;D:\Repository\org\scala-lang\scala-reflect\2.11.7\scala-reflect-2.11.7.jar;D:\Repository\com\fasterxml\jackson\module\jackson-module-paranamer\2.6.5\jackson-module-paranamer-2.6.5.jar;D:\Repository\org\apache\ivy\ivy\2.4.0\ivy-2.4.0.jar;D:\Repository\oro\oro\2.0.8\oro-2.0.8.jar;D:\Repository\net\razorvine\pyrolite\4.13\pyrolite-4.13.jar;D:\Repository\net\sf\py4j\py4j\0.10.4\py4j-0.10.4.jar;D:\Repository\org\apache\spark\spark-tags_2.11\2.1.0\spark-tags_2.11-2.1.0.jar;D:\Repository\org\scalatest\scalatest_2.11\2.2.6\scalatest_2.11-2.2.6.jar;D:\Repository\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;D:\Repository\org\spark-project\spark\unused\1.0.0\unused-1.0.0.jar;D:\Repository\org\apache\spark\spark-streaming_2.11\2.1.0\spark-streaming_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-sql_2.11\2.1.0\spark-sql_2.11-2.1.0.jar;D:\Repository\com\univocity\univocity-parsers\2.2.1\univocity-parsers-2.2.1.jar;D:\Repository\org\apache\spark\spark-sketch_2.11\2.1.0\spark-sketch_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-catalyst_2.11\2.1.0\spark-catalyst_2.11-2.1.0.jar;D:\Repository\org\codehaus\janino\janino\3.0.0\janino-3.0.0.jar;D:\Repository\org\codehaus\janino\commons-compiler\3.0.0\commons-compiler-3.0.0.jar;D:\Repository\org\antlr\antlr4-runtime\4.5.3\antlr4-runtime-4.5.3.jar;D:\Repository\org\apache\parquet\parquet-column\1.8.1\parquet-column-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-common\1.8.1\parquet-common-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-encoding\1.8.1\parquet-encoding-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-hadoop\1.8.1\parquet-hadoop-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-format\2.3.0-incubating\parquet-format-2.3.0-incubating.jar;D:\Repository\org\apache\parquet\parquet-jackson\1.8.1\parquet-jackson-1.8.1.jar;D:\Repository\org\apache\hadoop\hadoop-client\2.6.5\hadoop-client-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-common\2.6.5\hadoop-common-2.6.5.jar;D:\Repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;D:\Repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;D:\Repository\commons-io\commons-io\2.4\commons-io-2.4.jar;D:\Repository\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;D:\Repository\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;D:\Repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\Repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;D:\Repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;D:\Repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;D:\Repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;D:\Repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;D:\Repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;D:\Repository\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;D:\Repository\org\apache\hadoop\hadoop-auth\2.6.5\hadoop-auth-2.6.5.jar;D:\Repository\org\apache\httpcomponents\httpclient\4.2.5\httpclient-4.2.5.jar;D:\Repository\org\apache\httpcomponents\httpcore\4.2.4\httpcore-4.2.4.jar;D:\Repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;D:\Repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;D:\Repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;D:\Repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;D:\Repository\org\apache\curator\curator-client\2.6.0\curator-client-2.6.0.jar;D:\Repository\org\htrace\htrace-core\3.0.4\htrace-core-3.0.4.jar;D:\Repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;D:\Repository\org\tukaani\xz\1.0\xz-1.0.jar;D:\Repository\org\apache\hadoop\hadoop-hdfs\2.6.5\hadoop-hdfs-2.6.5.jar;D:\Repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;D:\Repository\xerces\xercesImpl\2.9.1\xercesImpl-2.9.1.jar;D:\Repository\xml-apis\xml-apis\1.3.04\xml-apis-1.3.04.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.6.5\hadoop-mapreduce-client-app-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.6.5\hadoop-mapreduce-client-common-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-client\2.6.5\hadoop-yarn-client-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-server-common\2.6.5\hadoop-yarn-server-common-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.6.5\hadoop-mapreduce-client-shuffle-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-api\2.6.5\hadoop-yarn-api-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.6.5\hadoop-mapreduce-client-core-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-common\2.6.5\hadoop-yarn-common-2.6.5.jar;D:\Repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;D:\Repository\javax\xml\stream\stax-api\1.0-2\stax-api-1.0-2.jar;D:\Repository\javax\activation\activation\1.1\activation-1.1.jar;D:\Repository\javax\servlet\servlet-api\2.5\servlet-api-2.5.jar;D:\Repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;D:\Repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;D:\Repository\org\codehaus\jackson\jackson-jaxrs\1.9.13\jackson-jaxrs-1.9.13.jar;D:\Repository\org\codehaus\jackson\jackson-xc\1.9.13\jackson-xc-1.9.13.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.6.5\hadoop-mapreduce-client-jobclient-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-annotations\2.6.5\hadoop-annotations-2.6.5.jar;D:\Repository\org\apache\kafka\kafka-clients\0.8.2.2\kafka-clients-0.8.2.2.jar;D:\Repository\org\apache\kafka\kafka_2.11\0.8.2.2\kafka_2.11-0.8.2.2.jar;D:\Repository\org\scala-lang\modules\scala-xml_2.11\1.0.2\scala-xml_2.11-1.0.2.jar;D:\Repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;D:\Repository\net\sf\jopt-simple\jopt-simple\3.2\jopt-simple-3.2.jar;D:\Repository\org\scala-lang\modules\scala-parser-combinators_2.11\1.0.2\scala-parser-combinators_2.11-1.0.2.jar;D:\Repository\com\101tec\zkclient\0.3\zkclient-0.3.jar;D:\Repository\mysql\mysql-connector-java\5.1.38\mysql-connector-java-5.1.38.jar;D:\Repository\org\apache\spark\spark-streaming-kafka-0-8_2.11\2.1.0\spark-streaming-kafka-0-8_2.11-2.1.0.jar;D:\Repository\org\apache\zookeeper\zookeeper\3.4.10\zookeeper-3.4.10.jar;D:\Repository\jline\jline\0.9.94\jline-0.9.94.jar;D:\developTools\IntelliJ IDEA 2018.2.3\lib\idea_rt.jar
2018-12-26 16:46:22 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_171\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;D:\developTools\Git\cmd;D:\developTools\svn\bin;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\scala\bin;C:\Users\junmei02\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk1.8.0_171\bin;D:\developTools\apache-maven-3.5.2\bin;D:\developTools\mysql-5.6.27-winx64\bin;D:\developTools\Git\cmd;D:\hadoop\hadoop-common-2.2.0-bin-master\bin;D:\hadoop\hbase-1.2.6\bin;C:\Program Files (x86)\scala\bin;D:\bigdata\zookeeper-3.4.10\bin;;.
2018-12-26 16:46:22 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.io.tmpdir=C:\Users\junmei02\AppData\Local\Temp\
2018-12-26 16:46:22 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.compiler=<NA>
2018-12-26 16:46:22 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.name=Windows 10
2018-12-26 16:46:22 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.arch=amd64
2018-12-26 16:46:22 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:os.version=10.0
2018-12-26 16:46:22 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.name=junmei02
2018-12-26 16:46:22 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.home=C:\Users\junmei02
2018-12-26 16:46:22 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:user.dir=D:\springbootworkspace\spark
2018-12-26 16:46:22 [ INFO ] - [ org.apache.zookeeper.ZooKeeper.<init>(ZooKeeper.java:438) ] Initiating client connection, connectString=127.0.0.1:2181 sessionTimeout=10000 watcher=org.apache.curator.ConnectionState@2034b64c
2018-12-26 16:46:22 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:1032) ] Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2018-12-26 16:46:22 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$SendThread.primeConnection(ClientCnxn.java:876) ] Socket connection established to 127.0.0.1/127.0.0.1:2181, initiating session
2018-12-26 16:46:22 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$SendThread.onConnected(ClientCnxn.java:1299) ] Session establishment complete on server 127.0.0.1/127.0.0.1:2181, sessionid = 0x167e9ae198b0001, negotiated timeout = 10000
2018-12-26 16:46:22 [ INFO ] - [ org.apache.curator.framework.state.ConnectionStateManager.postState(ConnectionStateManager.java:194) ] State change: CONNECTED
2018-12-26 16:46:22 [ WARN ] - [ org.apache.curator.framework.state.ConnectionStateManager.processEvents(ConnectionStateManager.java:212) ] There are no ConnectionStateListeners registered.
2018-12-26 16:46:22 [ INFO ] - [ org.apache.zookeeper.ZooKeeper.close(ZooKeeper.java:684) ] Session: 0x167e9ae198b0001 closed
2018-12-26 16:46:22 [ INFO ] - [ org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:519) ] EventThread shut down for session: 0x167e9ae198b0001
2018-12-26 16:46:23 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Running Spark version 2.1.0
2018-12-26 16:46:23 [ ERROR ] - [ org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:396) ] Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2373)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2373)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2373)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:837)
	at org.apache.spark.streaming.StreamingContext.<init>(StreamingContext.scala:84)
	at org.apache.spark.streaming.api.java.JavaStreamingContext.<init>(JavaStreamingContext.scala:138)
	at com.zqg.StreamKafka.KafkaSparkStreamingWithZookeeperoffset.main(KafkaSparkStreamingWithZookeeperoffset.java:67)
2018-12-26 16:46:23 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing view acls to: junmei02
2018-12-26 16:46:23 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing modify acls to: junmei02
2018-12-26 16:46:23 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing view acls groups to: 
2018-12-26 16:46:23 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Changing modify acls groups to: 
2018-12-26 16:46:23 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(junmei02); groups with view permissions: Set(); users  with modify permissions: Set(junmei02); groups with modify permissions: Set()
2018-12-26 16:46:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'sparkDriver' on port 55910.
2018-12-26 16:46:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering MapOutputTracker
2018-12-26 16:46:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering BlockManagerMaster
2018-12-26 16:46:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-26 16:46:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] BlockManagerMasterEndpoint up
2018-12-26 16:46:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Created local directory at C:\Users\junmei02\AppData\Local\Temp\blockmgr-32ae460c-c9fb-450d-878b-26be086fef79
2018-12-26 16:46:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] MemoryStore started with capacity 900.6 MB
2018-12-26 16:46:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering OutputCommitCoordinator
2018-12-26 16:46:24 [ INFO ] - [ org.spark_project.jetty.util.log.Log.initialized(Log.java:186) ] Logging initialized @3381ms
2018-12-26 16:46:24 [ INFO ] - [ org.spark_project.jetty.server.Server.doStart(Server.java:327) ] jetty-9.2.z-SNAPSHOT
2018-12-26 16:46:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@c827db{/jobs,null,AVAILABLE}
2018-12-26 16:46:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@377c68c6{/jobs/json,null,AVAILABLE}
2018-12-26 16:46:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@538cd0f2{/jobs/job,null,AVAILABLE}
2018-12-26 16:46:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@238ad8c{/jobs/job/json,null,AVAILABLE}
2018-12-26 16:46:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@430fa4ef{/stages,null,AVAILABLE}
2018-12-26 16:46:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@1761de10{/stages/json,null,AVAILABLE}
2018-12-26 16:46:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@22df874e{/stages/stage,null,AVAILABLE}
2018-12-26 16:46:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@654c1a54{/stages/stage/json,null,AVAILABLE}
2018-12-26 16:46:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@5bdaf2ce{/stages/pool,null,AVAILABLE}
2018-12-26 16:46:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@42d236fb{/stages/pool/json,null,AVAILABLE}
2018-12-26 16:46:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@1ce93c18{/storage,null,AVAILABLE}
2018-12-26 16:46:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@19f21b6b{/storage/json,null,AVAILABLE}
2018-12-26 16:46:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@1532c619{/storage/rdd,null,AVAILABLE}
2018-12-26 16:46:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@46044faa{/storage/rdd/json,null,AVAILABLE}
2018-12-26 16:46:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@1358b28e{/environment,null,AVAILABLE}
2018-12-26 16:46:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@1a78dacd{/environment/json,null,AVAILABLE}
2018-12-26 16:46:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@19f9d595{/executors,null,AVAILABLE}
2018-12-26 16:46:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@7de4a01f{/executors/json,null,AVAILABLE}
2018-12-26 16:46:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@2bfeb1ef{/executors/threadDump,null,AVAILABLE}
2018-12-26 16:46:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@778ca8ef{/executors/threadDump/json,null,AVAILABLE}
2018-12-26 16:46:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@208e9ef6{/static,null,AVAILABLE}
2018-12-26 16:46:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@78b236a0{/,null,AVAILABLE}
2018-12-26 16:46:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@261d8190{/api,null,AVAILABLE}
2018-12-26 16:46:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@34448e6c{/jobs/job/kill,null,AVAILABLE}
2018-12-26 16:46:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@60e9df3c{/stages/stage/kill,null,AVAILABLE}
2018-12-26 16:46:24 [ INFO ] - [ org.spark_project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:266) ] Started ServerConnector@32fdec40{HTTP/1.1}{0.0.0.0:4040}
2018-12-26 16:46:24 [ INFO ] - [ org.spark_project.jetty.server.Server.doStart(Server.java:379) ] Started @3529ms
2018-12-26 16:46:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'SparkUI' on port 4040.
2018-12-26 16:46:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Bound SparkUI to 0.0.0.0, and started at http://192.168.0.112:4040
2018-12-26 16:46:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Starting executor ID driver on host localhost
2018-12-26 16:46:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55931.
2018-12-26 16:46:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Server created on 192.168.0.112:55931
2018-12-26 16:46:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-26 16:46:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering BlockManager BlockManagerId(driver, 192.168.0.112, 55931, None)
2018-12-26 16:46:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registering block manager 192.168.0.112:55931 with 900.6 MB RAM, BlockManagerId(driver, 192.168.0.112, 55931, None)
2018-12-26 16:46:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Registered BlockManager BlockManagerId(driver, 192.168.0.112, 55931, None)
2018-12-26 16:46:24 [ INFO ] - [ org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54) ] Initialized BlockManager: BlockManagerId(driver, 192.168.0.112, 55931, None)
2018-12-26 16:46:24 [ INFO ] - [ org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744) ] Started o.s.j.s.ServletContextHandler@1869f114{/metrics/json,null,AVAILABLE}
2018-12-26 16:46:25 [ ERROR ] - [ org.apache.spark.internal.Logging$class.logError(Logging.scala:70) ] ArrayBuffer(org.apache.spark.SparkException: Couldn't find leader offsets for Set())
2018-12-26 16:46:25 [ ERROR ] - [ org.apache.spark.internal.Logging$class.logError(Logging.scala:91) ] Error generating jobs for time 1545813985000 ms
org.apache.spark.SparkException: ArrayBuffer(org.apache.spark.SparkException: Couldn't find leader offsets for Set())
	at org.apache.spark.streaming.kafka.DirectKafkaInputDStream.latestLeaderOffsets(DirectKafkaInputDStream.scala:133)
	at org.apache.spark.streaming.kafka.DirectKafkaInputDStream.compute(DirectKafkaInputDStream.scala:158)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1$$anonfun$apply$7.apply(DStream.scala:341)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1$$anonfun$apply$7.apply(DStream.scala:341)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1.apply(DStream.scala:340)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1.apply(DStream.scala:340)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:415)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1.apply(DStream.scala:335)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1.apply(DStream.scala:333)
	at scala.Option.orElse(Option.scala:289)
	at org.apache.spark.streaming.dstream.DStream.getOrCompute(DStream.scala:330)
	at org.apache.spark.streaming.dstream.TransformedDStream$$anonfun$6.apply(TransformedDStream.scala:42)
	at org.apache.spark.streaming.dstream.TransformedDStream$$anonfun$6.apply(TransformedDStream.scala:42)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.immutable.List.map(List.scala:285)
	at org.apache.spark.streaming.dstream.TransformedDStream.compute(TransformedDStream.scala:42)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1$$anonfun$apply$7.apply(DStream.scala:341)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1$$anonfun$apply$7.apply(DStream.scala:341)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1.apply(DStream.scala:340)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1.apply(DStream.scala:340)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:415)
	at org.apache.spark.streaming.dstream.TransformedDStream.createRDDWithLocalProperties(TransformedDStream.scala:65)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1.apply(DStream.scala:335)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1.apply(DStream.scala:333)
	at scala.Option.orElse(Option.scala:289)
	at org.apache.spark.streaming.dstream.DStream.getOrCompute(DStream.scala:330)
	at org.apache.spark.streaming.dstream.FlatMappedDStream.compute(FlatMappedDStream.scala:36)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1$$anonfun$apply$7.apply(DStream.scala:341)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1$$anonfun$apply$7.apply(DStream.scala:341)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1.apply(DStream.scala:340)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1.apply(DStream.scala:340)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:415)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1.apply(DStream.scala:335)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1.apply(DStream.scala:333)
	at scala.Option.orElse(Option.scala:289)
	at org.apache.spark.streaming.dstream.DStream.getOrCompute(DStream.scala:330)
	at org.apache.spark.streaming.dstream.MappedDStream.compute(MappedDStream.scala:36)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1$$anonfun$apply$7.apply(DStream.scala:341)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1$$anonfun$apply$7.apply(DStream.scala:341)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1.apply(DStream.scala:340)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1.apply(DStream.scala:340)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:415)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1.apply(DStream.scala:335)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1.apply(DStream.scala:333)
	at scala.Option.orElse(Option.scala:289)
	at org.apache.spark.streaming.dstream.DStream.getOrCompute(DStream.scala:330)
	at org.apache.spark.streaming.dstream.ForEachDStream.generateJob(ForEachDStream.scala:48)
	at org.apache.spark.streaming.DStreamGraph$$anonfun$1.apply(DStreamGraph.scala:117)
	at org.apache.spark.streaming.DStreamGraph$$anonfun$1.apply(DStreamGraph.scala:116)
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:104)
	at org.apache.spark.streaming.DStreamGraph.generateJobs(DStreamGraph.scala:116)
	at org.apache.spark.streaming.scheduler.JobGenerator$$anonfun$3.apply(JobGenerator.scala:249)
	at org.apache.spark.streaming.scheduler.JobGenerator$$anonfun$3.apply(JobGenerator.scala:247)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.streaming.scheduler.JobGenerator.generateJobs(JobGenerator.scala:247)
	at org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:183)
	at org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:89)
	at org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:88)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
2018-12-26 16:49:27 [ INFO ] - [ org.apache.curator.framework.imps.CuratorFrameworkImpl.start(CuratorFrameworkImpl.java:223) ] Starting
2018-12-26 16:49:27 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT
2018-12-26 16:49:27 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:host.name=windows10.microdone.cn
2018-12-26 16:49:27 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.version=1.8.0_171
2018-12-26 16:49:27 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.vendor=Oracle Corporation
2018-12-26 16:49:27 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.home=C:\Program Files\Java\jdk1.8.0_171\jre
2018-12-26 16:49:27 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.class.path=C:\Program Files\Java\jdk1.8.0_171\jre\lib\charsets.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\deploy.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\access-bridge-64.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\cldrdata.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\dnsns.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\jaccess.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\jfxrt.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\localedata.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\nashorn.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunec.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunjce_provider.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunmscapi.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\sunpkcs11.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\ext\zipfs.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\javaws.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jce.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jfr.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jfxswt.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\jsse.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\management-agent.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\plugin.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\resources.jar;C:\Program Files\Java\jdk1.8.0_171\jre\lib\rt.jar;D:\springbootworkspace\spark\target\classes;D:\Repository\org\scala-lang\scala-library\2.11.8\scala-library-2.11.8.jar;D:\Repository\org\apache\spark\spark-core_2.11\2.1.0\spark-core_2.11-2.1.0.jar;D:\Repository\org\apache\avro\avro-mapred\1.7.7\avro-mapred-1.7.7-hadoop2.jar;D:\Repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7.jar;D:\Repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7-tests.jar;D:\Repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;D:\Repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;D:\Repository\com\twitter\chill_2.11\0.8.0\chill_2.11-0.8.0.jar;D:\Repository\com\esotericsoftware\kryo-shaded\3.0.3\kryo-shaded-3.0.3.jar;D:\Repository\com\esotericsoftware\minlog\1.3.0\minlog-1.3.0.jar;D:\Repository\org\objenesis\objenesis\2.1\objenesis-2.1.jar;D:\Repository\com\twitter\chill-java\0.8.0\chill-java-0.8.0.jar;D:\Repository\org\apache\xbean\xbean-asm5-shaded\4.4\xbean-asm5-shaded-4.4.jar;D:\Repository\org\apache\spark\spark-launcher_2.11\2.1.0\spark-launcher_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-network-common_2.11\2.1.0\spark-network-common_2.11-2.1.0.jar;D:\Repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;D:\Repository\com\fasterxml\jackson\core\jackson-annotations\2.6.5\jackson-annotations-2.6.5.jar;D:\Repository\org\apache\spark\spark-network-shuffle_2.11\2.1.0\spark-network-shuffle_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-unsafe_2.11\2.1.0\spark-unsafe_2.11-2.1.0.jar;D:\Repository\net\java\dev\jets3t\jets3t\0.7.1\jets3t-0.7.1.jar;D:\Repository\commons-codec\commons-codec\1.3\commons-codec-1.3.jar;D:\Repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;D:\Repository\org\apache\curator\curator-recipes\2.4.0\curator-recipes-2.4.0.jar;D:\Repository\org\apache\curator\curator-framework\2.4.0\curator-framework-2.4.0.jar;D:\Repository\com\google\guava\guava\14.0.1\guava-14.0.1.jar;D:\Repository\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;D:\Repository\org\apache\commons\commons-lang3\3.5\commons-lang3-3.5.jar;D:\Repository\org\apache\commons\commons-math3\3.4.1\commons-math3-3.4.1.jar;D:\Repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;D:\Repository\org\slf4j\slf4j-api\1.7.16\slf4j-api-1.7.16.jar;D:\Repository\org\slf4j\jul-to-slf4j\1.7.16\jul-to-slf4j-1.7.16.jar;D:\Repository\org\slf4j\jcl-over-slf4j\1.7.16\jcl-over-slf4j-1.7.16.jar;D:\Repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;D:\Repository\org\slf4j\slf4j-log4j12\1.7.16\slf4j-log4j12-1.7.16.jar;D:\Repository\com\ning\compress-lzf\1.0.3\compress-lzf-1.0.3.jar;D:\Repository\org\xerial\snappy\snappy-java\1.1.2.6\snappy-java-1.1.2.6.jar;D:\Repository\net\jpountz\lz4\lz4\1.3.0\lz4-1.3.0.jar;D:\Repository\org\roaringbitmap\RoaringBitmap\0.5.11\RoaringBitmap-0.5.11.jar;D:\Repository\commons-net\commons-net\2.2\commons-net-2.2.jar;D:\Repository\org\json4s\json4s-jackson_2.11\3.2.11\json4s-jackson_2.11-3.2.11.jar;D:\Repository\org\json4s\json4s-core_2.11\3.2.11\json4s-core_2.11-3.2.11.jar;D:\Repository\org\json4s\json4s-ast_2.11\3.2.11\json4s-ast_2.11-3.2.11.jar;D:\Repository\com\thoughtworks\paranamer\paranamer\2.6\paranamer-2.6.jar;D:\Repository\org\scala-lang\scalap\2.11.0\scalap-2.11.0.jar;D:\Repository\org\scala-lang\scala-compiler\2.11.0\scala-compiler-2.11.0.jar;D:\Repository\org\glassfish\jersey\core\jersey-client\2.22.2\jersey-client-2.22.2.jar;D:\Repository\javax\ws\rs\javax.ws.rs-api\2.0.1\javax.ws.rs-api-2.0.1.jar;D:\Repository\org\glassfish\hk2\hk2-api\2.4.0-b34\hk2-api-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\hk2-utils\2.4.0-b34\hk2-utils-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\external\aopalliance-repackaged\2.4.0-b34\aopalliance-repackaged-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\external\javax.inject\2.4.0-b34\javax.inject-2.4.0-b34.jar;D:\Repository\org\glassfish\hk2\hk2-locator\2.4.0-b34\hk2-locator-2.4.0-b34.jar;D:\Repository\org\javassist\javassist\3.18.1-GA\javassist-3.18.1-GA.jar;D:\Repository\org\glassfish\jersey\core\jersey-common\2.22.2\jersey-common-2.22.2.jar;D:\Repository\javax\annotation\javax.annotation-api\1.2\javax.annotation-api-1.2.jar;D:\Repository\org\glassfish\jersey\bundles\repackaged\jersey-guava\2.22.2\jersey-guava-2.22.2.jar;D:\Repository\org\glassfish\hk2\osgi-resource-locator\1.0.1\osgi-resource-locator-1.0.1.jar;D:\Repository\org\glassfish\jersey\core\jersey-server\2.22.2\jersey-server-2.22.2.jar;D:\Repository\org\glassfish\jersey\media\jersey-media-jaxb\2.22.2\jersey-media-jaxb-2.22.2.jar;D:\Repository\javax\validation\validation-api\1.1.0.Final\validation-api-1.1.0.Final.jar;D:\Repository\org\glassfish\jersey\containers\jersey-container-servlet\2.22.2\jersey-container-servlet-2.22.2.jar;D:\Repository\org\glassfish\jersey\containers\jersey-container-servlet-core\2.22.2\jersey-container-servlet-core-2.22.2.jar;D:\Repository\io\netty\netty-all\4.0.42.Final\netty-all-4.0.42.Final.jar;D:\Repository\io\netty\netty\3.8.0.Final\netty-3.8.0.Final.jar;D:\Repository\com\clearspring\analytics\stream\2.7.0\stream-2.7.0.jar;D:\Repository\io\dropwizard\metrics\metrics-core\3.1.2\metrics-core-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-jvm\3.1.2\metrics-jvm-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-json\3.1.2\metrics-json-3.1.2.jar;D:\Repository\io\dropwizard\metrics\metrics-graphite\3.1.2\metrics-graphite-3.1.2.jar;D:\Repository\com\fasterxml\jackson\core\jackson-databind\2.6.5\jackson-databind-2.6.5.jar;D:\Repository\com\fasterxml\jackson\core\jackson-core\2.6.5\jackson-core-2.6.5.jar;D:\Repository\com\fasterxml\jackson\module\jackson-module-scala_2.11\2.6.5\jackson-module-scala_2.11-2.6.5.jar;D:\Repository\org\scala-lang\scala-reflect\2.11.7\scala-reflect-2.11.7.jar;D:\Repository\com\fasterxml\jackson\module\jackson-module-paranamer\2.6.5\jackson-module-paranamer-2.6.5.jar;D:\Repository\org\apache\ivy\ivy\2.4.0\ivy-2.4.0.jar;D:\Repository\oro\oro\2.0.8\oro-2.0.8.jar;D:\Repository\net\razorvine\pyrolite\4.13\pyrolite-4.13.jar;D:\Repository\net\sf\py4j\py4j\0.10.4\py4j-0.10.4.jar;D:\Repository\org\apache\spark\spark-tags_2.11\2.1.0\spark-tags_2.11-2.1.0.jar;D:\Repository\org\scalatest\scalatest_2.11\2.2.6\scalatest_2.11-2.2.6.jar;D:\Repository\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;D:\Repository\org\spark-project\spark\unused\1.0.0\unused-1.0.0.jar;D:\Repository\org\apache\spark\spark-streaming_2.11\2.1.0\spark-streaming_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-sql_2.11\2.1.0\spark-sql_2.11-2.1.0.jar;D:\Repository\com\univocity\univocity-parsers\2.2.1\univocity-parsers-2.2.1.jar;D:\Repository\org\apache\spark\spark-sketch_2.11\2.1.0\spark-sketch_2.11-2.1.0.jar;D:\Repository\org\apache\spark\spark-catalyst_2.11\2.1.0\spark-catalyst_2.11-2.1.0.jar;D:\Repository\org\codehaus\janino\janino\3.0.0\janino-3.0.0.jar;D:\Repository\org\codehaus\janino\commons-compiler\3.0.0\commons-compiler-3.0.0.jar;D:\Repository\org\antlr\antlr4-runtime\4.5.3\antlr4-runtime-4.5.3.jar;D:\Repository\org\apache\parquet\parquet-column\1.8.1\parquet-column-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-common\1.8.1\parquet-common-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-encoding\1.8.1\parquet-encoding-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-hadoop\1.8.1\parquet-hadoop-1.8.1.jar;D:\Repository\org\apache\parquet\parquet-format\2.3.0-incubating\parquet-format-2.3.0-incubating.jar;D:\Repository\org\apache\parquet\parquet-jackson\1.8.1\parquet-jackson-1.8.1.jar;D:\Repository\org\apache\hadoop\hadoop-client\2.6.5\hadoop-client-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-common\2.6.5\hadoop-common-2.6.5.jar;D:\Repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;D:\Repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;D:\Repository\commons-io\commons-io\2.4\commons-io-2.4.jar;D:\Repository\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;D:\Repository\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;D:\Repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\Repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;D:\Repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;D:\Repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;D:\Repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;D:\Repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;D:\Repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;D:\Repository\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;D:\Repository\org\apache\hadoop\hadoop-auth\2.6.5\hadoop-auth-2.6.5.jar;D:\Repository\org\apache\httpcomponents\httpclient\4.2.5\httpclient-4.2.5.jar;D:\Repository\org\apache\httpcomponents\httpcore\4.2.4\httpcore-4.2.4.jar;D:\Repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;D:\Repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;D:\Repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;D:\Repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;D:\Repository\org\apache\curator\curator-client\2.6.0\curator-client-2.6.0.jar;D:\Repository\org\htrace\htrace-core\3.0.4\htrace-core-3.0.4.jar;D:\Repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;D:\Repository\org\tukaani\xz\1.0\xz-1.0.jar;D:\Repository\org\apache\hadoop\hadoop-hdfs\2.6.5\hadoop-hdfs-2.6.5.jar;D:\Repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;D:\Repository\xerces\xercesImpl\2.9.1\xercesImpl-2.9.1.jar;D:\Repository\xml-apis\xml-apis\1.3.04\xml-apis-1.3.04.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.6.5\hadoop-mapreduce-client-app-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.6.5\hadoop-mapreduce-client-common-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-client\2.6.5\hadoop-yarn-client-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-server-common\2.6.5\hadoop-yarn-server-common-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.6.5\hadoop-mapreduce-client-shuffle-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-api\2.6.5\hadoop-yarn-api-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.6.5\hadoop-mapreduce-client-core-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-yarn-common\2.6.5\hadoop-yarn-common-2.6.5.jar;D:\Repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;D:\Repository\javax\xml\stream\stax-api\1.0-2\stax-api-1.0-2.jar;D:\Repository\javax\activation\activation\1.1\activation-1.1.jar;D:\Repository\javax\servlet\servlet-api\2.5\servlet-api-2.5.jar;D:\Repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;D:\Repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;D:\Repository\org\codehaus\jackson\jackson-jaxrs\1.9.13\jackson-jaxrs-1.9.13.jar;D:\Repository\org\codehaus\jackson\jackson-xc\1.9.13\jackson-xc-1.9.13.jar;D:\Repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.6.5\hadoop-mapreduce-client-jobclient-2.6.5.jar;D:\Repository\org\apache\hadoop\hadoop-annotations\2.6.5\hadoop-annotations-2.6.5.jar;D:\Repository\org\apache\kafka\kafka-clients\0.8.2.2\kafka-clients-0.8.2.2.jar;D:\Repository\org\apache\kafka\kafka_2.11\0.8.2.2\kafka_2.11-0.8.2.2.jar;D:\Repository\org\scala-lang\modules\scala-xml_2.11\1.0.2\scala-xml_2.11-1.0.2.jar;D:\Repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;D:\Repository\net\sf\jopt-simple\jopt-simple\3.2\jopt-simple-3.2.jar;D:\Repository\org\scala-lang\modules\scala-parser-combinators_2.11\1.0.2\scala-parser-combinators_2.11-1.0.2.jar;D:\Repository\com\101tec\zkclient\0.3\zkclient-0.3.jar;D:\Repository\mysql\mysql-connector-java\5.1.38\mysql-connector-java-5.1.38.jar;D:\Repository\org\apache\spark\spark-streaming-kafka-0-8_2.11\2.1.0\spark-streaming-kafka-0-8_2.11-2.1.0.jar;D:\Repository\org\apache\zookeeper\zookeeper\3.4.10\zookeeper-3.4.10.jar;D:\Repository\jline\jline\0.9.94\jline-0.9.94.jar;D:\developTools\IntelliJ IDEA 2018.2.3\lib\idea_rt.jar
2018-12-26 16:49:28 [ INFO ] - [ org.apache.zookeeper.Environment.logEnv(Environment.java:100) ] Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_171\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;D:\developTools\Git\cmd;D:\developTools\svn\bin;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\scala\bin;C:\Users\junmei02\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk1.8.0_171\bin;D:\developTools\apache-maven-3.5.2\bin;D:\developTools\mysql-5.6.27-winx64\bin;D:\developTools\Git\cmd;D:\hadoop\hadoop-common-2.2.0-bin-master\bin;D:\hadoop\hbase-1.2.6\bin;C:\Program Files (x86)\scala\bin;D:\bigdata\zookeeper-3.4.10\bin;;.
